<script async src="https://cse.google.com/cse.js?cx=e5aef4d5c058203d2"></script>
<div class="gcse-search"></div>
<h4>ソフト関連</h4>
<p><strong>Deep Blue</strong></p>
<p>1996年に<a class="keyword" href="http://d.hatena.ne.jp/keyword/IBM">IBM</a>が開発</p>
<p>チェスの世界チャンピオン<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AC%A5%EA">ガリ</a>ル・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A5%B9%A5%D1%A5%ED%A5%D5">カスパロフ</a>に勝利</p>
<p>力任せの探索</p>
<p>10～14手先を読む</p>
<p> </p>
<p><strong>Bonkras</strong></p>
<p>将棋ソフトウェア</p>
<p>2011年　世界コンピュータ将棋選手権で優勝</p>
<p>2012年　将棋電脳戦</p>
<p>現在はPuella αと解明</p>
<p> </p>
<p><strong>Ponanza</strong></p>
<p>将棋ソフトウェア</p>
<p>山本一成らが開発</p>
<p>2012　電脳トーナメントを制する</p>
<p>2015 　世界コンピュータ将棋選手権で優勝</p>
<p> </p>
<p><strong>sharpchess</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A1%BC%A5%D7%A5%F3%A5%BD%A1%BC%A5%B9">オープンソース</a>のチェスソフトウェア</p>
<p> </p>
<p><strong>Deep Dream</strong></p>
<p>2015 年　 <a class="keyword" href="http://d.hatena.ne.jp/keyword/google">google</a> 社</p>
<p>通常の画像をまるで夢に出てくるかのような不思議な画像に変換して表示するプログラム</p>
<p> </p>
<p><strong>Tay</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%A4%A5%AF%A5%ED%A5%BD%A5%D5%A5%C8">マイクロソフト</a>の対話型ボット</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C4%A5%A4%A5%C3%A5%BF%A1%BC">ツイッター</a>を利用</p>
<p>不適切な調教によりやらかした</p>
<p> </p>
<blockquote><strong>AlexNet</strong><br />2012年のILSVRCで<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C8%A5%ED%A5%F3%A5%C8%C2%E7%B3%D8">トロント大学</a>のジェフリー・ヒントン率いるチームが使用し、2位以下に圧倒的な差をつけて優勝したネットワーク。8層。調整するパラメータは60,000,000にものぼる。 </blockquote>
<p>→Alex Krizhevsky</p>
<p>　5個のcovolutional層と3個のpooling層が存在</p>
<p>　"stride of 4"</p>
<p> </p>
<blockquote>
<p><strong>ResNet</strong><br />2015年のILSVRCで優勝。152層。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Microsoft">Microsoft</a>のチームが開発。これまで以上に層を深くできるようにスキップ構造を導入した。</p>
</blockquote>
<p><span style="color: #d32f2f;">→スキップ構造＝<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%BB%A5%D7%A5%B7%A5%E7%A5%F3">インセプション</a>（inception）モジュールの導入</span></p>
<p>→出力を「入力」と「入力からの差分」の和として<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%C7%A5%EA%A5%F3%A5%B0">モデリング</a>した</p>
<p>→求めたい関数と入力のと差である残差を学習するようにした</p>
<p> </p>
<p>→CNNでは沢山の層を重ねた結果、学習に用いられるパラメータの数が膨大となり、学習が上手く進まないという問題が生じていた。ResNetは入力層から出力層まで伝播する値と入力層の値を足し合わせたモデルで、入力層まで、勾配値がきちんと伝わり、 深い構造（1000層）でも学習が可能となった。2015 年の ILSVRC で人間の成績を上回る成果をあげた</p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/Microsoft">Microsoft</a> Research(現<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a> AI Research)のKaiming He</p>
<p> </p>
<blockquote>
<p><strong>VGG16</strong><br />2014年のILSVRCでGoogLeNetに劣らない性能を誇ったオックスフォード大学のチームのCNN。16層。GoogLeNetには及ばなかったが、シンプルなネットワークなので技術者に好んで使われる。</p>
</blockquote>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a></p>
<p>※VGGnetともいう？</p>
<p> </p>
<p><strong>STRIPS</strong></p>
<p>前提条件、行動、結果の3つの組み合わせで記述する</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>が自律的に行動計画を作成する技術であるプランニングで有名</p>
<p> </p>
<p><strong>SHRDLU</strong></p>
<p>テリーウィノグラード</p>
<p>積み木の世界</p>
<p>物体の動かし方をプランニングできた言える</p>
<p> </p>
<p><strong>LeNet</strong></p>
<p>1998にヤンルカン氏が発表したCNNの原型</p>
<p>多層CNNに<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>法を適用した手法</p>
<p> </p>
<p><strong>WaveNet</strong></p>
<p>音声生成でブレイクスルー</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/google">google</a> Deep mindが2016年に開発</p>
<p>RNNではなくCNNを用いている</p>
<p> </p>
<p><strong>ライブラリなど</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/OpenCV">OpenCV</a>：画像に特化</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A1%BC%A5%D7%A5%F3%A5%BD%A1%BC%A5%B9">オープンソース</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>エンジン</p>
<p>Julius：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>システムの開発・研究のための<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A1%BC%A5%D7%A5%F3%A5%BD%A1%BC%A5%B9">オープンソース</a>の高性能な汎用大語彙連続<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>エンジン</p>
<p>OpenNLP：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>のためのツールセット</p>
<p> </p>
<h4>画像処理</h4>
<p><strong>R-CNN(Regional CNN)</strong></p>
<p>関心領域（ROI）の切り出し　→ CNNを呼び出す</p>
<p><span style="color: #d32f2f;">ROIきりだしにはCNNはではない従来手法を使ったので時間がかかる</span></p>
<p>※ROI：見たい領域、どこに識別するかという領域</p>
<p>↓</p>
<p><strong>高速RCNN</strong></p>
<p>切り出しの画像認識を同時に行う</p>
<p>→faster RCNN：ほぼ実時間で処理が可能。動画認識にCNNを使えるようになった</p>
<p> ↓</p>
<p><strong>物体検出（画像検出）</strong></p>
<p>画像内に含まれるとある物体を取り囲むような<span style="color: #d32f2f;">ボックスを推定する</span>タスクを行うもの</p>
<p><span style="color: #d32f2f;">2014：R-CNN</span></p>
<p><span style="color: #d32f2f;">2015：Faster R-CNN</span></p>
<p><span style="color: #d32f2f;">2016：YOLO(You only look once)</span></p>
<p><span style="color: #d32f2f;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/SSD">SSD</a>(single shot detector)</span></p>
<blockquote>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/herumo/20200701/20200701192204.png" alt="f:id:herumo:20200701192204p:plain" title="f:id:herumo:20200701192204p:plain" class="hatena-fotolife" itemprop="image" width="354" /></p>
<p><a href="http://incubit.co.jp/blog/3532#:~:text=Semantic%20Segmentation%20%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%82%8B%E7%94%BB%E5%83%8F,%E4%BB%98%E3%81%91%E3%81%97%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82">自動運転にも応用される精緻な画像認識技術、「画像セグメンテーション」とは？事例を交えてわかりやすく解説｜株式会社インキュビット</a></p>
</blockquote>
<p> </p>
<p><strong>物体セグメンテーション（画像セグメンテーション）</strong></p>
<p><span style="color: #d32f2f;">対象</span>とする物体とその周囲の<span style="color: #d32f2f;">背景</span>を<span style="color: #d32f2f;">境界まで切り分ける</span>ようなタスクを行うもの</p>
<p>  </p>
<p><span style="color: #d32f2f;">特徴はFCN (Fully Convolutional Network/完全畳み込みネットワーク)</span></p>
<p>※画素ごとに判別している、だったかな？</p>
<p>CVPR 2015, PAMI 2016で発表</p>
<p>Semantic Segmentation手法</p>
<p>全ての層が畳み込み層</p>
<p>入力画像の画<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%C7%BF%F4">素数</a>だけ出力層が必要</p>
<p> 縦画素×横画<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%C7%BF%F4">素数</a>×カテゴリー数</p>
<p> </p>
<p>特徴量から画像を生成する際はCNNと逆の操作を行う</p>
<p>畳み込み層→逆畳み込み層</p>
<p>プーリング層→アンプーリング層</p>
<p>アンサンプリングにより解像度を復元</p>
<blockquote>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/herumo/20200701/20200701192243.png" alt="f:id:herumo:20200701192243p:plain" title="f:id:herumo:20200701192243p:plain" class="hatena-fotolife" itemprop="image" /></p>
<p><a href="http://incubit.co.jp/blog/3532#:~:text=Semantic%20Segmentation%20%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%82%8B%E7%94%BB%E5%83%8F,%E4%BB%98%E3%81%91%E3%81%97%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82">自動運転にも応用される精緻な画像認識技術、「画像セグメンテーション」とは？事例を交えてわかりやすく解説｜株式会社インキュビット</a></p>
</blockquote>
<p> </p>
<p>画像セグメンテーションは2種類</p>
<p>1つは，個別の物体を区別する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%B9%A5%BF%A5%F3%A5%B9">インスタンス</a>セグメンテーション（Instance-aware Segmentation）</p>
<p>（上で言えばcowを1~4に区別される）</p>
<p>もう一つは，同一クラスの物体であれば個を区別しないSemantic Segmentation（セマンティックセグメンテーション） </p>
<p> </p>
<p><strong>画像キャプション</strong></p>
<p>画像内に表示されている女性を認識し,「青い服を着て<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%DE%A1%BC%A5%C8%A5%D5%A5%A9%A5%F3">スマートフォン</a>をいじっている」などのように<span style="color: #d32f2f;">その対象が何をしているかを表示</span>させること</p>
<p>画像をCNNに入力し、そこから得られた特徴をLSTMに入力することで生成</p>
<p>CNNとRNNと組み合わせ</p>
<blockquote>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/herumo/20200702/20200702070110.png" alt="f:id:herumo:20200702070110p:plain" title="f:id:herumo:20200702070110p:plain" class="hatena-fotolife" itemprop="image" width="447" /></p>
<p><a href="https://qiita.com/oreyutarover/items/6eb0e12ba0d169a480df">日本語による画像キャプション自動生成AIを作ったので丁寧に解説します！ - Qiita</a></p>
</blockquote>
<p>   </p>
<p><strong>画像分類</strong></p>
<blockquote>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/herumo/20200701/20200701192124.png" alt="f:id:herumo:20200701192124p:plain" title="f:id:herumo:20200701192124p:plain" class="hatena-fotolife" itemprop="image" width="436" /></p>
<p><a href="http://incubit.co.jp/blog/3532#:~:text=Semantic%20Segmentation%20%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%82%8B%E7%94%BB%E5%83%8F,%E4%BB%98%E3%81%91%E3%81%97%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82">自動運転にも応用される精緻な画像認識技術、「画像セグメンテーション」とは？事例を交えてわかりやすく解説｜株式会社インキュビット</a></p>
</blockquote>
<p>この画像は何を示しているのか？という操作をすること </p>
<p> </p>
<p> </p>
<p><strong>動画認識</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Spatio">Spatio</a>-temporal ConvNet </p>
<p>動画の10フレームをCNNに入力し、行動認識</p>
<p> </p>
<p>Two-stream CNN</p>
<p>Spatial stream ConvNet：フレーム画像を認識</p>
<p>Temporal stream ConvNet：動きの情報を認識</p>
<p> </p>
<p>動画デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>：Kinetics <a class="keyword" href="http://d.hatena.ne.jp/keyword/DeepMind">DeepMind</a></p>
<p>→Inflated 3D ConvNet （I3D）</p>
<p>　肺がん診断AI：人間の専門家に匹敵 or 上回る精度</p>
<p> </p>
<p> </p>
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a></h4>
<p><strong>End to End <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a></strong></p>
<p>音響特徴量から音素,音素から文字列,文字列から単語列に直接変換して<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a>を学習するアプローチ</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は入力から出力を一括で行うことができるEnd to End learning</p>
<p>従来の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>はステップ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%A4%A5%B9">バイス</a>テップの処理が必要だった</p>
<p>（音声波形→音素→文字→文字列→単語→単語列）</p>
<p> </p>
<p><strong>音素状態認識</strong></p>
<p>音声の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%FE%C7%C8%BF%F4%A5%B9%A5%DA%A5%AF%A5%C8%A5%EB">周波数スペクトル</a>,すなわち音響特徴量をインプットとして,音素状態のカテゴリに分類する</p>
<p> </p>
<p><strong>雑音・残響抑圧</strong></p>
<p>音声を認識したい対象とそれ以外の雑音に分離する</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%B9%E7%C0%AE">音声合成</a></strong></p>
<p><span style="color: #4d5156; font-family: arial, sans-serif; font-size: 14px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">人間の音声を人工的に作り出すこと</span></p>
<p> </p>
<p><strong style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a></strong></p>
<p><span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">自然</span>言語<span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">処理などにおいて、<span style="color: #d32f2f;">文の品詞や統語構造、単語と単語、文書と文書などの関係性について定式化したもののこと</span>である。 </span><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a><span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">は、多くの場合は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%FD%B7%D7%B3%D8">統計学</a>的な観点から数式などを用いて確率的に定められる。</span></p>
<p>確率を精密に設定することにより人間が用いる言語は理論上モデル化できる。</p>
<p> </p>
<p><span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;"> 代表的な</span><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a><span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">としては、Nグラム</span>モデル<span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">、隠れマルコフ</span>モデル<span style="color: #222222; font-family: arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">、最大<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%C8%A5%ED%A5%D4%A1%BC">エントロピー</a></span>モデル</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B1%A3%A4%EC%A5%DE%A5%EB%A5%B3%A5%D5%A5%E2%A5%C7%A5%EB">隠れマルコフモデル</a>（HMM）</strong></p>
<p>1990年代の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a></p>
<p>音自体を判別するための音響モデル </p>
<p>HMM+DNNの組み合わせがよい結果を出す </p>
<p> </p>
<p><strong>GMM</strong></p>
<p> </p>
<p> </p>
<p><strong>Nグラム法</strong></p>
<p>1990年代の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a></p>
<p>語と語のつながりを判別する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a></p>
<p> </p>
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a></h4>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>、画像説明文生成→できる</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF">構文解析</a>、意味解析→精度向上はしているが、、、</p>
<p>文脈解析、常識推論→実用的な精度は見込めない</p>
<p> </p>
<p><strong>word2vec</strong></p>
<p> トマスミコロフ</p>
<p>記号をベクトルとして表現することにより、ベクトル間の関係や距離として単語の意味を表現しようとするモデル</p>
<p>「王様」ー「男性」＋「女性」＝「女王」</p>
<p>単語埋め込みモデル、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%AF%A5%C8%A5%EB%B6%F5%B4%D6%A5%E2%A5%C7%A5%EB">ベクトル空間モデル</a>とも呼ばれる</p>
<p> </p>
<p>スキップグラム（Skip-gram）単語を与えて周辺の単語を予測</p>
<p>CBOW：単語を与えてある単語を予測</p>
<p> </p>
<p><strong>fastText</strong></p>
<p>トマスミコロフ</p>
<p>単語の表現に文字の情報も含める</p>
<p>学習に要する時間が短い</p>
<p> </p>
<p><strong>ELMo</strong></p>
<p>アレンインスティチュート</p>
<p>文章表現を得るモデル</p>
<p> </p>
<p><strong>bag-of-words</strong></p>
<p>文章に単語が含まれているかどうかを考えてテキストデータを数値化（ベクトル化）</p>
<p><a href="https://www.pytry3g.com/entry/2018/03/21/181514">Bag of Wordsについて書いてみる - どん底から這い上がるまでの記録</a></p>
<p> </p>
<p><strong>Ngram</strong></p>
<p>単語単位で区切った<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>とことなり、Ngramでは任意の連続したN文字単位で区切</p>
<p> </p>
<p><strong>TF-IDF</strong></p>
<p>Term Frequency(TF)</p>
<p>Inverse Document Frequency(IDF)</p>
<p>文書の中から、その文書の特徴語を抽出する時に使う</p>
<p><span style="color: #d32f2f;">単語の重要度を特徴量にする</span></p>
<p>いくつかの文書があったときに、それらに出てくる単語とその頻度(Frequency)から、<br />ある文書にとって重要な単語はなんなのかというのを数値化</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a> </strong></p>
<p>文法的な情報の注記の無い<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC">自然言語</a>のテキストデータ（文）から、対象言語の文法や、辞書と呼ばれる単語の品詞等の情報にもとづき、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>（Morpheme, おおまかにいえば、<span style="color: #d32f2f;">言語で意味を持つ最小単位）の列に分割</span>し、それぞれの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>の品詞等を判別する作業</p>
<p> </p>
<p><strong>制限ボルツマンマシン（ＲＢＭ）</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>で使用される</p>
<p> </p>
<h4>自動運転</h4>
<p>米国<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CD%A5%D0%A5%C0">ネバダ</a>州では自動運転の走行や運転免許が許可制にて認められた</p>
<p> </p>
<p> </p>
<h4>ドローン</h4>
<blockquote>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F4%B9%D4%B6%D8%BB%DF%B6%F5%B0%E8">飛行禁止空域</a><br />・空港周辺<br />・150m以上の上空<br />・人家の集中地域（DID)</p>
<p>飛行ルール<br />・日中のこと<br />・距離の確保を行うこと<br />・催しを行っている場所は飛行禁止<br />・危険物輸送の禁止<br />・物件投下の禁止</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%F1%C5%DA%B8%F2%C4%CC%BE%CA">国土交通省</a>への申請で許可を受ければ飛ばすことができる。守らないと50万円以下の罰金。ルールは総重量(バッテリー等本体以外の重量含む)が200g未満の場合は対象外。</p>
</blockquote>
<p> →夜間の禁止</p>
<p>　人口集中地区の上空・イベントなど大勢の人が集まる場所での飛行禁止</p>
<p>　ひと・ものから30m未満の飛行は承認が必要</p>
<p>→<span style="color: #333333; font-family: YakuHanJPs, 'noto sans japanese', 'ヒラギノ角ゴ pron w3', 'hiragino kaku gothic pron', 游ゴシック, YuGothic, メイリオ, Meiryo, Verdana, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">風速が5m/s以下のコンディションでなければ飛行はできない</span></p>
<p>→<span style="color: #333333; font-family: YakuHanJPs, 'noto sans japanese', 'ヒラギノ角ゴ pron w3', 'hiragino kaku gothic pron', 游ゴシック, YuGothic, メイリオ, Meiryo, Verdana, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">風速と速度の和が7m/s以下とすること</span></p>
<p>→国会議事堂や<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%E2%B3%D5%C1%ED%CD%FD%C2%E7%BF%C3">内閣総理大臣</a>官邸、外国公館、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%B6%BB%D2%CE%CF">原子力</a>事業所の周辺地域は「小型<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%B5%BF%CD">無人</a>機等の飛行禁止法」により<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F4%B9%D4%B6%D8%BB%DF%B6%F5%B0%E8">飛行禁止空域</a></p>
<p><a href="https://viva-drone.com/restriction-for-drone-use-in-japan/">きっとあなたも間違えている。国内ドローン規制3つの落とし穴</a></p>
<p> </p>
<p> </p>
<h4>セキュリティ関連</h4>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%D1%A5%E0%A5%E1%A1%BC%A5%EB">スパムメール</a>判別</strong></p>
<p>LSTM, ナイーブ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a></p>
<p> </p>
<p><strong>Adversarial Examples</strong></p>
<p>AIへの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B5%A5%A4%A5%D0%A1%BC%B9%B6%B7%E2">サイバー攻撃</a></p>
<p>Evasion attack : 難読化（暗号化，画像ベース）<br />Poisoning attack : 訓練データの操作，ラベルの反転</p>
<p> </p>
<p> </p>
<h4>AIを作るうえでのあれこれ</h4>
<blockquote> <span style="font-weight: bold;">フレーム問題</span><br />無限にある可能性からの探査には無限の時間がかかってしまう問題。このフレーム問題を克服したAIを強いAI(汎用AI)、克服できないAIを弱いAI(特化型AI)と呼ぶ</blockquote>
<p> →有限の情報処理能力では、現実の問題を解くのは難しい</p>
<p> </p>
<p><strong>強いAI, 弱いAI</strong></p>
<p>汎化AI, 特化AI</p>
<p>ジョンサール</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%E6%B9%F1%B8%EC%A4%CE%C9%F4%B2%B0">中国語の部屋</a></p>
<p> </p>
<p><strong>身体性・身体知</strong></p>
<p>AIが現実世界における抽象概念を理解し、知識処理を行うために必要なこと</p>
<p>→身体性を通じた高レベルの身体知を獲得し、</p>
<p>→次に身体知を通じて言語の意味理解を促し、抽象概念・知識処理へいたる</p>
<p>※ロボット研究から生まれた概念だったような？人間は五感をはじめとしてセンサーだらけの自律体でいろいろな情報から複雑な関係性を学習できるですが、ロボットは限られたセンサーしかもたないですし</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>研究</strong></p>
<p>抽象概念や知識理解に辿り着くための方針は3つある</p>
<p> </p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a> 社・<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a> 社</p>
<p>→言語データによる RNN や映像データからの概念・知識理解を目指す</p>
<p>UC Berkeley</p>
<p>→実世界を対象に研究を進め,知識理解を目指す</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/DeepMind">DeepMind</a> 社</p>
<p>→オンライン空間上でできることをターゲットにするして,知識理解を目指す</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>研究の変遷</strong></p>
<p>パターン処理 -&gt; 記号処理 -&gt; 知識の蓄積</p>
<p> </p>
<h4>学習方法</h4>
<p><strong>表現学習</strong></p>
<p>ローデータからコンピュータが自動的に事象を識別するための特徴量を学習する一連の技術</p>
<p>CNNがこれにあたるはず。特徴量学習とか言われているときもあるような</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>学習</strong></p>
<p>いくつかの関連するタスクにおける学習の内容を共有する事によってそれぞれのタスクにおける予測精度を向上させる学習方法</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%BF%CD%CD%C2%CE">多様体</a>学習</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%BF%CD%CD%C2%CE">多様体</a>上に分布しているようなデータ構造のデータを学習する一連の手法</p>
<blockquote>
<p style="box-sizing: border-box; margin: 2em 0px 1em; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: bold; font-stretch: inherit; line-height: 1.4; font-family: 游ゴシック, YuGothic, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', Verdana, メイリオ, Meiryo, Osaka, 'ＭＳ Ｐゴシック', 'MS PGothic', sans-serif; font-size: 18px; vertical-align: baseline; color: #383838; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"><span id="i-35" style="box-sizing: border-box; margin: 0px; padding: 0px; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-size: 18px; vertical-align: baseline;">勾配降下法</span></p>
<p style="box-sizing: border-box; margin: 0px 0px 1.6em; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; line-height: 1.6; font-family: 游ゴシック, YuGothic, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', Verdana, メイリオ, Meiryo, Osaka, 'ＭＳ Ｐゴシック', 'MS PGothic', sans-serif; font-size: 16px; vertical-align: baseline; color: #383838; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;">勾配情報を利用して重みを増加させるか減少させるかを決める。学習率がハイパーパラメータ。</p>
<p style="box-sizing: border-box; margin: 0px 0px 1.6em; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; line-height: 1.6; font-family: 游ゴシック, YuGothic, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', Verdana, メイリオ, Meiryo, Osaka, 'ＭＳ Ｐゴシック', 'MS PGothic', sans-serif; font-size: 16px; vertical-align: baseline; color: #383838; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;">逐次学習（オンライン学習）の場合は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B3%CE%CE%A8%C5%AA%B8%FB%C7%DB%B9%DF%B2%BC%CB%A1">確率的勾配降下法</a>(<a class="keyword" href="http://d.hatena.ne.jp/keyword/SGD">SGD</a>)、ミニバッチ学習の場合はミニバッチ勾配降下法と呼ぶ。</p>
</blockquote>
<p> →オンライン学習とはひとつのサンプルだけを利用する手法</p>
<p>1. 重みとバイアスを初期化</p>
<p>2. データ（ミニバッチ）をネットワークに入力し出力を得る</p>
<p>3. ネットワークの出力と正解ラベルとの誤差を計算</p>
<p>4. 誤差を減らすように重み（バイアス）を修正</p>
<p>5. 最適な重みやバイアスになるまで繰り返す</p>
<p> </p>
<p>バッチ学習：全データを用いて学習</p>
<p>　　　　　　計算処理に時間がかかる</p>
<p>　　　　　　<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C7%B5%DE%B9%DF%B2%BC%CB%A1">最急降下法</a></p>
<p>オンライン学習：ひとつのサンプリングごとに学習</p>
<p>　　　　　　　　収束するまで学習データを何週もする</p>
<p>　　　　　　　　計算処理は早いが、ノイズやはずれ値の影響を受けやすい</p>
<p>　　　　　　　　<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B3%CE%CE%A8%C5%AA%B8%FB%C7%DB%B9%DF%B2%BC%CB%A1">確率的勾配降下法</a>(<a class="keyword" href="http://d.hatena.ne.jp/keyword/SGD">SGD</a>)</p>
<p>ミニバッチ学習：折衷案で、よく用いられる</p>
<p>　　　　　　　　幾つかのデー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>に分けて、それぞれの塊ごとに学習する</p>
<p><a href="https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95">確率的勾配降下法 - Wikipedia</a></p>
<p> </p>
<p><strong>AdaBoost</strong></p>
<p><a href="https://qiita.com/kibinag0/items/2e6740c58c1f2d2e119e">機械学習⑤ アダブースト (AdaBoost) まとめ - Qiita</a></p>
<p> </p>
<p><strong>モメンタム</strong></p>
<p>以前に適用した勾配の方向を現在のパラメータ更新にも影響させる</p>
<p>※坂を下っていくのが勾配降下法なら、坂を下る際の加速度を加味するイメージ</p>
<p>↓</p>
<p><strong>AdaGrad</strong></p>
<p>モメンタムの欠点を解決したのがAdaGrad</p>
<p>すでに大きく更新されたパラメータほど更新量（学習率）を減らす</p>
<p>一度更新量が飽和した重みはもう更新されないという欠点がある</p>
<p>※一度大きな坂を下り、緩やかな坂を体験すると、次の坂に差し掛かっても降下できない</p>
<p>↓</p>
<p><strong>RMSprop</strong></p>
<p>AdaGradの発展</p>
<p>指数<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%DC%C6%B0%CA%BF%B6%D1">移動平均</a>を蓄積することによってAdaGradの問題を解決した</p>
<p>※上記、二度目の坂では最初の坂の勾配情報を無視して学習を進めることが可能</p>
<p>↓</p>
<p><strong>Adam</strong></p>
<p>RMSpropの発展</p>
<p> </p>
<p><strong>Adadelta</strong></p>
<p>RMSpropの発展</p>
<p> 次元のミスマッチを解消</p>
<p> </p>
<p><strong>RMSpropGraves </strong></p>
<p>手書き文字認識で使われる</p>
<p><a href="https://qiita.com/ZoneTsuyoshi/items/8ef6fa1e154d176e25b8">深層学習の最適化アルゴリズム - Qiita</a></p>
<p> </p>
<p><strong>学習率</strong></p>
<p>学習率が過度に大きいとコスト関数の高い局所的最適解から抜け出せなくなることがある</p>
<p>学習率が大きいと収束は速いがコスト関数の最終的な値が高い</p>
<p>学習率が小さいと収束は遅いが最終的にはより最適解に近いパラメータになるため,コスト関数は小さな値に収束する.</p>
<p>  </p>
<p><strong>最小二乗法</strong></p>
<p>モデルの予測値と実データの差が最小になるような係数パラメータを求める方法</p>
<p>符号を考えなくてよくなり計算がしやすくなる→二乗するから</p>
<p>はずれ値に弱い</p>
<p> <br /><strong>ファインチューニング</strong></p>
<p>既存のモデルの一部を利用して新たなモデルを解くために再学習する手法</p>
<p><span style="color: #d32f2f;">学習済みモデルの最終出力層を付け替えるが、入力層に近い部分と出力層のパラメータも変更</span></p>
<p>例えば、犬と猫と人間を分類するモデルを柴犬と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B4%A1%BC%A5%EB%A5%C7%A5%F3%A5%EC%A5%C8%A5%EA%A5%D0%A1%BC">ゴールデンレトリバー</a>を分類するモデルに変更するなどのように学習済みモデルと比べて全く異なるモデルへと学習することができるようになる</p>
<p><a href="https://note.com/matsukoutennis/n/n1f8d422b3e7a">転移学習とファインチューニングの違い｜Zono｜note</a></p>
<p>※事前学習との比較のときとは扱われ方が違うような？ 本質的には同じようだが</p>
<p> </p>
<p><strong>転移学習</strong></p>
<p>学習済みモデルの<span style="color: #d32f2f;">最終出力層だけ</span>を付け替えて、自分のデータを学習させ新しいモデルを作成するということで出力層のパラメータだけ変更する</p>
<p>例えば、犬と猫と人間を分類するモデルを犬と猫のデータで再学習させることで犬と猫を分類するモデルを作ることができる</p>
<p> </p>
<p><strong>蒸留</strong></p>
<p>大きなNNなどの入出力をより小さなネットワークに学習させる技術</p>
<p>生徒モデルを単独で学習させるより<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を緩和する効果がある</p>
<p>メリット：モデルの精度向上、訓練の効率化、敵対的攻撃（Adversarial Attack）に対する防御</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B5%A5%DD%A1%BC%A5%C8%A5%D9%A5%AF%A5%BF%A1%BC%A5%DE%A5%B7%A5%F3">サポートベクターマシン</a>）</strong></p>
<p>各クラスの最も近いデータの距離を最大化することで係数パラメータを得る方法</p>
<p>マージンの最大化がコンセプト</p>
<p>線形分離不可能なデータのマージンを最大化するためのスラック関数</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>境界を得られるようにするための<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%CB%A1">カーネル法</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB">カーネル</a>関数）</p>
<p>→データをあえて高次元に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>することで、その<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>後の空間で線形分類できるようにする</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%CB%A1">カーネル法</a>の計算量を大幅に削減するための<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%A5%C8%A5%EA%A5%C3%A5%AF">カーネルトリック</a></p>
<p> </p>
<p><strong>主成分分析</strong></p>
<p>線形</p>
<p>次元削減</p>
<p>寄与率が各成分の重要度</p>
<p>主成分が各成分の意味</p>
<p> </p>
<p> <strong>ロジスティック回帰</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>という関数をモデルの出力に用いる </p>
<p>→数式上の表現は単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>とまったく同じになる</p>
<p>→線形分類しかできない</p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の一種</p>
<p>→尤度関数が目的関数</p>
<p>→対数オッズと呼ばれる値を予測し、正規化して結果を確率として解釈</p>
<p> </p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C7%CC%E0%BF%E4%C4%EA">最尤推定</a>法</strong></p>
<p><span style="color: #d32f2f;">ある係数パラメータが与えられたときに,モデルが実データを予測する確率（尤度）</span>を最大化するような係数パラメータを求める方法</p>
<p> </p>
<p><strong>残差</strong></p>
<p>モデルによって出力された値と実際の測定値の誤差</p>
<p>残差を用いて係数パラメータを推定する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>が最小二乗法と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C7%CC%E0%BF%E4%C4%EA">最尤推定</a>法</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a>（大脳皮質の動きを模倣）</strong></p>
<p>主成分分析(PCA)</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%C8%CE%A9%C0%AE%CA%AC%CA%AC%C0%CF">独立成分分析</a></p>
<p>自己符号化器</p>
<p><span style="color: #000000; font-family: メイリオ, Meiryo, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', 'ＭＳ Ｐゴシック', sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>ー分析</span></p>
<p><span style="color: #000000; font-family: メイリオ, Meiryo, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', 'ＭＳ Ｐゴシック', sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">自己組織化マップ</span></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a>（小脳の働きを模倣）</strong></p>
<p>k近傍法</p>
<p>主成分分析（PCA）</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a></strong></p>
<p>エージェントが環境に対して行動を行うと、報酬と状態が環境から返ってくる</p>
<p>報酬を最大化するように学習する</p>
<p> </p>
<p>エージェント：行動を学習する</p>
<p>環境：エージェントが行動を加える対象</p>
<p>状態：環境が今どうなっているかをあらわす</p>
<p> </p>
<p>時間がかかる</p>
<p> </p>
<p>マルチエージェント応用</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>：Ｑ学習</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>を使った<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a></p>
<p>　　　行動価値関数の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B4%D8%BF%F4%B6%E1%BB%F7">関数近似</a>に畳み込み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>を用いた手法</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED%CB%A1">モンテカルロ法</a></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED%CB%A1">モンテカルロ法</a></strong></p>
<p>ゲーム終盤でコンピュータがランダムに手をさし続けて終局させて勝率が高い選択肢を選ぶ</p>
<p> </p>
<p><strong>Mini-Max法</strong></p>
<p>ゲームボードの戦略を立てるときに自分が指すときにスコアが最大に、相手が指すときにスコアが最小になるように戦略を立てる方法</p>
<p> </p>
<p>αカット：スコアが最小のものを選ぶ過程＝相手の選択肢を考える上ですでに選択したスコアよりも大きいノードが現れた時点でその先に繋がるノードの探索をやめてしまう</p>
<p>βカット：αカットの逆。自分の選択肢を考える上で不利になるものはその先まで探索しない</p>
<p> </p>
<p><strong>行動価値関数</strong></p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">ある状態である行動を行うことの「価値」を表す関数</span></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>では最適行動価値関数をとることを目指して学習を行う</p>
<p>→Q学習：<span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">試しに何度もやってデータ集めて、期待値に収束させる</span></p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>：<span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">最適行動価値関数を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>を使った近似関数で求める</span></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>における工夫</strong></p>
<p>Experience Replay：時系列で並んでいるinputデータを順々に使って学習を進めると、inputデータ間の時系列の特徴に影響を受けてしまうため、ランダムにデータを取り出して学習させる</p>
<p>Fixed Target Q-Network：<span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">正解データ(target)と見立てている部分の値は一つ前の</span><span id="MathJax-Element-81-Frame" class="MathJax" style="box-sizing: inherit; display: inline-block; font-style: normal; font-weight: 400; line-height: normal; font-size: 16px; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: 0px; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: 100%; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; vertical-align: text-top; color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-variant-ligatures: normal; font-variant-caps: normal; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: #ffffff; position: relative;" tabindex="0" role="presentation" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;"><nobr aria-hidden="true" style="box-sizing: inherit; transition: none 0s ease 0s; border: 0px; padding: 0px; margin: 0px; max-width: none; max-height: none; min-width: 0px; min-height: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; white-space: nowrap !important;"><span id="MathJax-Span-1235" class="math" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline-block; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; width: 0.595em;" role="math"><span style="box-sizing: inherit; transition: none 0s ease 0s; display: inline-block; position: relative; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; width: 0.488em; height: 0px; font-size: 18.56px;"><span style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: absolute; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; clip: rect(1.511em, 1000.49em, 2.535em, -999.997em); top: -2.368em; left: 0.003em;"><span id="MathJax-Span-1236" class="mrow" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;"><span id="MathJax-Span-1237" class="mi" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; font-family: MathJax_Math-italic;">θ</span></span></span></span></span></nobr><span class="MJX_Assistive_MathML" style="box-sizing: inherit; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); position: static; padding: 0px; border: 0px; height: 1px !important; width: 1px !important; overflow: hidden !important; display: inline; transition: none 0s ease 0s; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">を使って計算しています。（</span><span id="MathJax-Element-82-Frame" class="MathJax" style="box-sizing: inherit; display: inline-block; font-style: normal; font-weight: 400; line-height: normal; font-size: 16px; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: 0px; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: 100%; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; vertical-align: text-top; color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-variant-ligatures: normal; font-variant-caps: normal; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: #ffffff; position: relative;" tabindex="0" role="presentation" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;"><span class="MJX_Assistive_MathML" style="box-sizing: inherit; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); position: static; padding: 0px; border: 0px; height: 1px !important; width: 1px !important; overflow: hidden !important; display: inline; transition: none 0s ease 0s; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>θ</mi><mo>−</mo></msup></math></span></span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">とする）</span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">しかし、１回の学習ごとに毎回</span><span id="MathJax-Element-83-Frame" class="MathJax" style="box-sizing: inherit; display: inline-block; font-style: normal; font-weight: 400; line-height: normal; font-size: 16px; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: 0px; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: 100%; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; vertical-align: text-top; color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-variant-ligatures: normal; font-variant-caps: normal; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: #ffffff; position: relative;" tabindex="0" role="presentation" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;"><span class="MJX_Assistive_MathML" style="box-sizing: inherit; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); position: static; padding: 0px; border: 0px; height: 1px !important; width: 1px !important; overflow: hidden !important; display: inline; transition: none 0s ease 0s; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>θ</mi><mo>−</mo></msup></math></span></span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">を更新すると、正解も毎回変わるため、どこに近づけたらいいのかわからない状態になります。そのため、</span><span id="MathJax-Element-84-Frame" class="MathJax" style="box-sizing: inherit; display: inline-block; font-style: normal; font-weight: 400; line-height: normal; font-size: 16px; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: 0px; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: 100%; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; vertical-align: text-top; color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-variant-ligatures: normal; font-variant-caps: normal; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: #ffffff; position: relative;" tabindex="0" role="presentation" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;"><span class="MJX_Assistive_MathML" style="box-sizing: inherit; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); position: static; padding: 0px; border: 0px; height: 1px !important; width: 1px !important; overflow: hidden !important; display: inline; transition: none 0s ease 0s; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>θ</mi><mo>−</mo></msup></math></span></span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">は、一定の期間ごとに</span><span id="MathJax-Element-85-Frame" class="MathJax" style="box-sizing: inherit; display: inline-block; font-style: normal; font-weight: 400; line-height: normal; font-size: 16px; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: 0px; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: 100%; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; vertical-align: text-top; color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-variant-ligatures: normal; font-variant-caps: normal; orphans: 2; widows: 2; -webkit-text-stroke-width: 0px; background-color: #ffffff; position: relative;" tabindex="0" role="presentation" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;"><nobr aria-hidden="true" style="box-sizing: inherit; transition: none 0s ease 0s; border: 0px; padding: 0px; margin: 0px; max-width: none; max-height: none; min-width: 0px; min-height: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; white-space: nowrap !important;"><span id="MathJax-Span-1253" class="math" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline-block; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; width: 0.595em;" role="math"><span style="box-sizing: inherit; transition: none 0s ease 0s; display: inline-block; position: relative; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; width: 0.488em; height: 0px; font-size: 18.56px;"><span style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: absolute; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; clip: rect(1.511em, 1000.49em, 2.535em, -999.997em); top: -2.368em; left: 0.003em;"><span id="MathJax-Span-1254" class="mrow" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;"><span id="MathJax-Span-1255" class="mi" style="box-sizing: inherit; transition: none 0s ease 0s; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none; font-family: MathJax_Math-italic;">θ</span></span></span></span></span></nobr><span class="MJX_Assistive_MathML" style="box-sizing: inherit; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); position: static; padding: 0px; border: 0px; height: 1px !important; width: 1px !important; overflow: hidden !important; display: inline; transition: none 0s ease 0s; margin: 0px; vertical-align: 0px; line-height: normal; text-decoration: none;" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">で更新するようにします。</span></p>
<p>報酬のclipping：</p>
<p> </p>
<p><strong>ロボット・ロボティクス</strong></p>
<p>一連の動作の組み合わせと捕らえて学習（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%EC%B5%A4%C4%CC%B4%D3">一気通貫</a>学習）</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>による試行錯誤</p>
<p> </p>
<p><strong>アンサンブル学習</strong></p>
<p>複数の学習器を組み合わせて予測する手法</p>
<p>これにより全体の汎化性能をあげることができる</p>
<p> </p>
<p><strong>スタッキング</strong></p>
<p>アンサンブル学習の一つで、モデルを積み上げて性能を向上させる手法</p>
<p><span style="color: #333333; font-family: 'Century Gothic', Arial, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', メイリオ, Meiryo, 'ＭＳ Ｐゴシック', sans-serif; font-size: 14px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">Stacked generalization</span></p>
<p>複雑だが精度が高い</p>
<p><a href="https://mathwords.net/stacking">スタッキング(stacked generalization)の発想とやり方 - 具体例で学ぶ数学</a></p>
<p> </p>
<p><strong>バギング</strong></p>
<p>アンサンブル学習の一つで、複数のモデルを別々に学習させ、各モデルの平均や多数決によって最終的な判断をする手法</p>
<p>ブートストラップを使う</p>
<p>ランダムフォレストとかが当てはまる</p>
<p><a href="https://mathwords.net/bagging">バギングの意味と、ブースティングとの違い - 具体例で学ぶ数学</a></p>
<p><span style="color: #d32f2f;">並列処理ができるので時間をかけずにそこそこ精度の高いモデルを作る</span></p>
<p> </p>
<p><strong>ブースティング</strong></p>
<p>バギングのように弱学習器を独立に作るのではなく、1つずつ順番に弱学習器を構成していく</p>
<p>その際、k 個目に作った弱学習器をもとに（弱点を補うように）k+1 個目の弱学習器を構成する</p>
<p>ブースティングの具体例としては、AdaBoost、XGBoost、LightGBM、CatBoost</p>
<p><span style="color: #d32f2f;">直列処理なので、時間はかかるが高い精度が得られる</span></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>学習</strong></p>
<p>同時に複数の識別問題に対応できるように学習する手法</p>
<p>最初から複数の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3">ドメイン</a>の課題を解くためのモデルを設定する</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>の深層学習では各課題の重み付き和が損失関数になる</p>
<p> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>学習の成功にとって望ましい条件は、複数の課題間で共通する因子や有用な特徴、局所解をもっていること</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%C3%A5%D4%A5%F3%A5%B0">マッピング</a></strong></p>
<p>順序を持つ文字列のカテゴリーデータの場合、対応する数値を辞書型データで用意して数値に変換する手法</p>
<p> </p>
<p><strong>ワンホット<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%B3%A1%BC%A5%C7%A5%A3%A5%F3%A5%B0">エンコーディング</a></strong></p>
<p>順序を持たない場合、各変数に対応したダミー変数を新たに作り出す</p>
<p>one-hot-encoding</p>
<p> </p>
<blockquote class="twitter-tweet">
<p dir="ltr" lang="ja">解決いたしました！！<br /><br />神々しい解説↓ <a href="https://t.co/AFYmGFsf0N">pic.twitter.com/AFYmGFsf0N</a></p>
— meer@G検定対策なう (@812_meer) <a href="https://twitter.com/812_meer/status/1278654320460705792?ref_src=twsrc%5Etfw">July 2, 2020</a></blockquote>
<p>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<p> </p>
<p><strong>欠損値がある場合の処理</strong></p>
<p>リストワイズ法</p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">→欠損のある行をすべて削除</span></p>
<p>ペアワイズ法</p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">→欠損の少ない列を使用することにし、特定の行を取り出してから欠損を削除</span></p>
<p>回帰補完</p>
<p>→欠損しているある特徴量と相関が強い他の特徴量が存在している場合</p>
<p>平均補完</p>
<p>→平均値を入れる</p>
<p> </p>
<p>ステップワイズ法</p>
<p>→欠損値処理ではない。「ステップワイズ法（逐次選択法）」は、統計ソフトが自動的に説明変数を１個ずつ入れたり出したりして、適合度の良いモデルを選択する方法</p>
<p>  </p>
<h4>デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a></h4>
<p>MNIST：手書き文字、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%E1%A5%EA">アメリ</a>カの国立標準技術研究所</p>
<p>ImageNet：インターネットから集めて分類した画像、1400万枚、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%D5%A5%A9%A1%BC%A5%C9%C2%E7%B3%D8">スタンフォード大学</a></p>
<p>CIFAR-10：物体カラー写真、初心者向けの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%C8%A5%EA%A5%A2%A5%EB">チュートリアル</a>などで使用</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Youtube">Youtube</a>-8M：動画のデー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>、800万本</p>
<p>VOC2012、MSCOCO：</p>
<p> </p>
<p><strong>学習済みモデル</strong></p>
<p><a href="https://qiita.com/ishida330/items/6e66323dfd56205fbe80">【2019/4月更新】学習済みの様々なディープラーニング・モデルをメチャ簡単に利用できる！ Model Asset Exchange(MAX)をご紹介します - Qiita</a></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%EC%A1%BC%A5%E0%A5%EF%A1%BC%A5%AF">フレームワーク</a></strong></p>
<p><span style="color: #d32f2f;">設定ファイルを使う：Cafe, CNTK</span></p>
<p>→モデルの定義がテキストで設定でき,簡単に学習を開始させることが出来るというメリットがある.一方で,ループ構造をもつような RNN など,複雑なモデルを扱う際には,モデルの定義を記述することは難しくなる傾向にある</p>
<p> </p>
<p><span style="color: #d32f2f;">プログラム：TensorFlow, Chainer</span></p>
<p>→一度書き方を覚えてしまえば,複雑なモデルでも比較的簡単に記述することが出来るが,モデルは,それぞれの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%EC%A1%BC%A5%E0%A5%EF%A1%BC%A5%AF">フレームワーク</a>固有の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BD%A1%BC%A5%B9%A5%B3%A1%BC%A5%C9">ソースコード</a>で出来上がるため,モデルが使用しているソフトウェアに依存してしまうという問題がある</p>
<p> </p>
<p>define-and-run：cafe</p>
<p>define-by-run：Chainer, py-torch, tensorflow, mxnet</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a></strong></p>
<p>重み更新の際に、重みが更新された回数</p>
<p>一回の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>に用いるサンプル数はバッチサイズと呼ばれる</p>
<p> </p>
<p><strong>エポック</strong></p>
<p>訓練データを繰り返し学習したときの、その回数</p>
<p> </p>
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>あれこれ</h4>
<p><strong>NN</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の学習には損失関数（コスト関数）の最適化により行われる</p>
<p>ロジスティック回帰、単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>、多層<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>、がこれにあたる（畳み込んでない） </p>
<p> </p>
<p><strong>損失関数</strong></p>
<p>回帰問題→平均二乗誤差関数</p>
<p>分類問題→交差<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%C8%A5%ED%A5%D4%A1%BC">エントロピー</a>誤差関数</p>
<p>※分類に使うランダムフォレストの不純度が<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%C8%A5%ED%A5%D4%A1%BC">エントロピー</a>だったような</p>
<p>分布を直接学習→KL <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C0%A5%A4%A5%D0%A1%BC%A5%B8%A5%A7%A5%F3%A5%B9">ダイバージェンス</a></p>
<p> </p>
<p><strong>損失関数、コスト関数、誤差関数の違い</strong></p>
<p>損失関数＝誤差関数</p>
<p>損失関数＋正規化項＝コスト関数</p>
<p><a href="https://qiita.com/kakiuchis/items/5cfe52e6f75dd75f96e7">目的関数、コスト関数、誤差関数、損失関数いろいろあるけど、なにが違うのかを検討 - Qiita</a></p>
<p> </p>
<p><strong>CNNのコンセプト</strong></p>
<p>CNNは人間の視覚野の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%C0%B7%D0%BA%D9%CB%A6">神経細胞</a>を模倣</p>
<p>単純型細胞（Ｓ細胞）：画像の濃淡パターン（特徴）を検出</p>
<p>複雑型細胞（Ｃ細胞）：物体の位置が変動しても同一の物体であるとみなす</p>
<p>→ネオコグニトロン（福島邦彦）</p>
<p> </p>
<p><strong>CNNとNNの違い</strong></p>
<p>画像全体のうちある一定範囲ごとに演算を行い、その範囲ごとに特徴量を計算</p>
<p>はじめは単純な特徴を拾い上げ、より後の畳み込み層になると複雑で抽象的な特徴を拾う</p>
<p>これにより汎化性能が高まる</p>
<p>一定範囲ごとに読み込んでいるので特徴がどこにあっても検出できる（位置不変性、移動不変性）</p>
<p>※画像が回転すると検出が苦手で（回転不変性がない）、拡大縮小にも弱い</p>
<p><a href="https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html">定番のConvolutional Neural Networkをゼロから理解する - DeepAge</a></p>
<p>学習に必要なパラメータが多い</p>
<p>計算量が多い</p>
<p>より複雑な関数を近似できる</p>
<p>結果の解釈や説明ができない（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D6%A5%E9%A5%C3%A5%AF%A5%DC%A5%C3%A5%AF%A5%B9">ブラックボックス</a>） </p>
<p> </p>
<p><strong>Global Average Pooling</strong></p>
<p>ひとつの特徴マップにひとつのクラスを対応させる</p>
<p>CNNの手法の一つで全結合層を用いずにこれを使う</p>
<p> </p>
<p>1980年代には<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>学習が提案されていたが、多くの層を持った学習をすることはできなかった</p>
<p>→勾配消失問題</p>
<p>→層の数が多いとNNの学習の目的関数は多くの最小値を持ち、適切な結合の重みの初期値の設定が難しかった</p>
<p> </p>
<p><strong>勾配消失問題への対処法</strong></p>
<p>いくつかあるが、、、</p>
<p>事前学習：勾配消失問題はモデルのパラメータの初期値に対して依存する。モデルを事前学習させることで安定した学習が可能となり、勾配消失問題を克服できると考えられる</p>
<p>ReLU関数を使う：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値が0以上の場合はそのままの値、0以下の場合は0となる。<br />この性質により<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>の際に、重みが小さくなるのを防ぐことができる</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>法のときに起こる問題</strong></p>
<p>勾配消失問題：誤差がどんどん小さくなっていき学習が収束しない問題</p>
<p>勾配爆発問題：誤差が大きくなっていき学習が収束しない問題</p>
<p> </p>
<p><strong>活性化関数</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/tanh">tanh</a>関数（双曲線<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C0%DC">正接</a>関数）→ReLU関数のほうが勾配消失問題が起こりづらい</p>
<p>ReLU（Rectified Linear Unit）／ランプ関数／正規化線形関数</p>
<p>Maxout→複数の線形関係の中で最大値を利用</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a></p>
<p>ステップ関数（Step function、単位ステップ関数：Unit step function）→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値が常に0なのでほとんどのNNでは使用されない。単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>の出力層で用いられる</p>
<p> </p>
<p><strong>重み共有、局所的受容野</strong></p>
<p><a href="https://qiita.com/hiyoko9t/items/f426cba38b6ca1a7aa2b">カプセルネットワークはニューラルネットワークを超えるか。 - Qiita</a></p>
<p>パラメータ数：全結合層＞畳み込み層</p>
<p>重み共有によって有用な特徴量を画像の一によって大きく変化させない</p>
<p> </p>
<p><strong>DNN</strong></p>
<p>CNNの層を深くしたものがDNN</p>
<p>学習するべきパラメータ数が膨大となるため、処理の高速化が必要</p>
<p>2012年に提案された分散並列技術であるDistBelif（<a class="keyword" href="http://d.hatena.ne.jp/keyword/google">google</a>が開発した深層分散学習の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%EC%A1%BC%A5%E0%A5%EF%A1%BC%A5%AF">フレームワーク</a>）や<a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a>が利用されてきた</p>
<p> </p>
<p><strong>内部共変量シフト</strong></p>
<p>（DNNにおいて、）ある層の入力がそれより下層の学習が進むにつれて変化し、学習がとまってしまう</p>
<p>大規模なNNの学習が困難となる原因</p>
<p>→対策としてバッチ正規化（2015）がある</p>
<p>　出力値の分布の偏りを抑制する</p>
<p>　各層で出力を正規化することで、層が深くなっても入力の分布の変化が少なくなる</p>
<p> </p>
<p><strong>CNNによる画像処理</strong></p>
<p>パディング：出力画像のサイズを調整するために元の画像の周りを固定の値で埋める</p>
<p>→ゼロで埋めるときは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BC%A5%ED%A5%D1%A5%C7%A5%A3%A5%F3%A5%B0">ゼロパディング</a>など</p>
<p>プーリング：最大プーリング、平均プーリング、Lpプーリング（周りの値をp乗し、その<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%B8%BD%E0%CA%D0%BA%B9">標準偏差</a>をとる）</p>
<p> </p>
<p><strong>ハイパーパラメータのチューニング</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a>最適化：過去の試験結果から次に行う範囲を確率分布を用いて計算する手法</p>
<p> </p>
<p><strong>リカレント<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>（RNN）</strong></p>
<p>ネットワークの入力層のひとつ前に学習で用いた隠れ層（中間層）のジョウタイを与える回帰構造を兼ね備えている</p>
<p>前の単語や文の情報が引き継がれて、隠れ層で過去のデータを保持できるようになっている</p>
<p>時間軸に沿って深いネットワーク構造を持つため、勾配消失問題が起こりやすい</p>
<p>ネットワークにループ構造を持つため、中間層が一層であっても勾配消失問題が起きてしまう</p>
<p>→手書き文字認識に利用</p>
<p><a href="http://ds9.jaist.ac.jp:8080/ResearchData/sub/99/kobayashi/node5.html">http://ds9.jaist.ac.jp:8080/ResearchData/sub/99/kobayashi/node5.html</a></p>
<blockquote>
<h4 style="box-sizing: border-box; margin: 2em 0px 1em; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: bold; font-stretch: inherit; line-height: 1.4; font-family: 游ゴシック, YuGothic, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', Verdana, メイリオ, Meiryo, Osaka, 'ＭＳ Ｐゴシック', 'MS PGothic', sans-serif; font-size: 18px; vertical-align: baseline; color: #383838; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"><span id="ElmanNet" style="box-sizing: border-box; margin: 0px; padding: 0px; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-size: 18px; vertical-align: baseline;">ElmanNet</span></h4>
<p style="box-sizing: border-box; margin: 0px 0px 1.6em; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; line-height: 1.6; font-family: 游ゴシック, YuGothic, 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', Verdana, メイリオ, Meiryo, Osaka, 'ＭＳ Ｐゴシック', 'MS PGothic', sans-serif; font-size: 16px; vertical-align: baseline; color: #383838; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;">JordanNetと並ぶ初期の有力なRNNの一種。</p>
</blockquote>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>に利用</p>
<p> </p>
<blockquote>
<p><strong>LSTMのゲート</strong><br />LSTMには以下の3つのゲートがあり、ゲートの開け閉めによって信号の重み付け（全開1、全閉0、その中間）をしている。<br />・忘却ゲート<br />・入力ゲート<br />・出力ゲート  </p>
</blockquote>
<p> →ユルゲン・シュミットフーバーと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B1%A5%D7%A5%E9%A1%BC">ケプラー</a>大学のゼップ・ホフレイターの提案</p>
<p>→各ゲートでの情報の取捨選択はシグモイド曲線を使う</p>
<p>→RNNとの違いで最も目につくのはメモリセルと呼ばれる中間層の状態を保持するパラメータ。メモリセルは、いくつかの次元をもち、時刻経過とともに変化する性質 </p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>や画像からのキャプション生成などに応用</p>
<p> </p>
<p><strong>BPTT</strong></p>
<p>RNNのときの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>をこう呼ぶ</p>
<p> </p>
<p><strong>LDA(Latent Dirichlet Allocation)</strong></p>
<p>トピックモデルの１種</p>
<p>文書がどのようなトピックから構成されているかを推論するモデル</p>
<p><br />推論するパラメータは以下</p>
<p>トピック分布：文書ごとのトピック構成比率<br />単語分布：トピックごとの単語比率</p>
<p> </p>
<p><strong>CNNとRNN</strong></p>
<p>CNN：データに潜む空間的構造をモデル化する</p>
<p>RNN：時間的構造をモデル化する</p>
<p> </p>
<p><strong>GRU</strong></p>
<p>ゲート付き回帰型ユニット</p>
<p>更新ゲートと忘却ゲート</p>
<p>LSTMに似ているが、小さなデー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>ではより高い精度を示す</p>
<p>一方でLSTMのほうが強力である </p>
<p> </p>
<p> <strong>音声処理</strong></p>
<p>時系列データなのでリカレント<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>（RNN）が最適と考えられていたが、<span style="color: #d32f2f;">音声処理の分野ではオートエンコーダ</span>が非常に高い精度を記録している </p>
<p> </p>
<p><strong>オートエンコーダ(Auto Encoder・自己符号化器)</strong></p>
<p>三層NNにおいて、入力層と出力層に同じデータを用いる学習方法</p>
<p>入力データと一致するデータを出力することを目的とする<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a></p>
<p>→積層オートエンコーダでは最後にロジスティック回帰層を足すことで供しあり学習になる</p>
<p>エンコーダ（特徴抽出機）と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0">デコーダ</a>（生成器）をもつ</p>
<p>ジェフリーヒントンが提唱</p>
<p>活性化関数に恒等<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>を用いた場合の 3 層の自己符号化器は主成分分析（ＰＣＡ）と同様の結果を返す</p>
<p>オートエンコーダを多層化するとDNNと同様に勾配消失問題が生じるため、複雑な内部表現を得ることが困難であったため、2006年にヒントンは単層の自己符号化器に分割し、入力層から繰り返し学習させる層ごとの貪欲法を積層自己符号化器に適用することで、汎用的なオート<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%B3%A1%BC%A5%C0%A1%BC">エンコーダー</a>の利用を可能とした</p>
<p> </p>
<p><strong>オートエンコーダの利用例</strong></p>
<p>次元削減に用いられる</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>の事前学習</p>
<p>ノイズ除去</p>
<p>異常検知</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF%A5%EA%A5%F3%A5%B0">クラスタリング</a></p>
<p>データ生成（VAE）</p>
<p><a href="https://jp.mathworks.com/discovery/autoencoder.html">オートエンコーダ/自己符号化器 - MATLAB &amp; Simulink</a></p>
<p> </p>
<p><strong>積層オートエンコーダ</strong></p>
<p>オートエンコーダを積み重ね、最後にロジスティック回帰層を付加する</p>
<p>事前学習→ファインチューニングの工程がある</p>
<p> </p>
<p>入力層に近い層から順番に学習させる（＝事前学習）という逐次的な方法を取っている</p>
<p>最後にロジスティック回帰層を足して、全体で学習する（これをファインチューニングという）</p>
<p><br /><strong>ファインチューニング</strong></p>
<p>既存のモデルの一部を利用して新たなモデルを解くために再学習する手法</p>
<p>ネットワーク全体への<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a></p>
<p> </p>
<p>学習済みモデルの最終出力層を付け替えるが、入力層に近い部分と出力層のパラメータも変更</p>
<p>例えば、犬と猫と人間を分類するモデルを柴犬と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B4%A1%BC%A5%EB%A5%C7%A5%F3%A5%EC%A5%C8%A5%EA%A5%D0%A1%BC">ゴールデンレトリバー</a>を分類するモデルに変更するなどのように学習済みモデルと比べて全く異なるモデルへと学習することができるようになる</p>
<p><a href="https://note.com/matsukoutennis/n/n1f8d422b3e7a">転移学習とファインチューニングの違い｜Zono｜note</a></p>
<p> </p>
<p> <strong>「深層信念ネットワーク」（Deep Belief Network）</strong></p>
<p>DNNの一種で<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a></p>
<p>オートエンコーダに制限つきボルツマンマシンrestricted boltzmann machineを事前学習として利用</p>
<p> </p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>による表現の獲得の例として、インターネット上の動画から切り出した画像を入力し、猫の概念を生成したという<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>の研究が有名</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は素性の再利用と抽象的な概念（あるいは不変量）の獲得が可能ことがわかる</p>
<p> </p>
<p><strong>VAE</strong></p>
<p>変分自己符号化器 (VAE; variational autoencoder)</p>
<p>変分オートエンコーダ</p>
<p>平均や分散などを求める生成モデル</p>
<p> </p>
<p>VAEはGANに比べて安定した学習ができ, Flowと異なり潜在変数を低次元に落とすことができるので扱いやすく解釈性が高い</p>
<p>一方で、生成画像がぼやけがちで、尤度の計算ができない</p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">誤差逆伝搬でVAEを学習させることができないので、reparametrization <a class="keyword" href="http://d.hatena.ne.jp/keyword/trick">trick</a>を使用する</span></p>
<p>通常のオートエンコーダとの大きな違いは、入力データを圧縮して得られる特徴ベクトル（潜在変数）を確率変数として扱う部分</p>
<p><a href="https://qiita.com/shionhonda/items/e2cf9fe93ae1034dd771">深層生成モデルを巡る旅(2): VAE - Qiita</a></p>
<p> </p>
<p><strong>生成モデル</strong></p>
<p>データの特徴を抽出して学習し、実在しないデータを生成</p>
<p>変分オートエンコーダ</p>
<p>ボルツマンマシン</p>
<p>GAN</p>
<p>GANはより鮮明な画像の生成が可能</p>
<p> </p>
<p><strong>GAN</strong></p>
<p>生成敵対ネットワーク</p>
<p>画像生成に用いられる</p>
<p>画像生成器→画像識別器をだますような画像を出力</p>
<p>画像識別器→画像生成器から出力された画像と本物の画像とを分類</p>
<p>ANは学習時に不安定になるケースが見られ、意味をなさない画像を生成したり、生成データの種類が偏るなどが課題</p>
<p>教師なし（ラベルなし）学習</p>
<p> </p>
<p><strong>DCGAN（Deap Convolutional GAN）</strong></p>
<p>ランダムな数値の入力値をもとに画像生成を行う</p>
<p>GANとの違いは、GeneratorとDiscriminatorそれぞれのネットワークに全結合層ではなく、畳み込み層(と転置畳み込み層)を使用している点<br />GANの学習が安定しない問題に対して、Batch Normalization (バッチ正規化)の導入や、活性化関数にReLUだけでなく<a class="keyword" href="http://d.hatena.ne.jp/keyword/tanh">tanh</a>, Leaky ReLUを使用している</p>
<p> </p>
<p><strong>自己組織化マップ(Self-Organizing Map: SOM)</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A3%A5%F3%A5%E9%A5%F3%A5%C9">フィンランド</a>の研究者，T. Kohonenの発明した<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>の一種である．SOM は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a>を行う位相保存<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>(topology preserving mapping) の一種である</p>
<p> </p>
<p><strong>確定的モデルと確率的モデル</strong></p>
<blockquote>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/herumo/20200702/20200702193209.png" alt="f:id:herumo:20200702193209p:plain" title="f:id:herumo:20200702193209p:plain" class="hatena-fotolife" itemprop="image" width="452" /></p>
<p><a href="https://jsai-deeplearning.github.io/support/20151031-index.pdf">https://jsai-deeplearning.github.io/support/20151031-index.pdf</a></p>
</blockquote>
<p>確率的モデル ：モデルの中に含まれる変数のうち、１つ以上が確率的に変動する確率変数であるモデル</p>
<p>確定的モデル：予測を行なうときのモデルの中の数式に含まれる変数が確率的な変動を示さないで、確定しているモデル</p>
<p>  </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a></strong></p>
<p><span style="color: #282828; font-family: 游ゴシック体, YuGothic, 游ゴシック, 'Yu Gothic', メイリオ, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; float: none; display: inline !important;">L1、L2<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>を用いた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>モデルは</span>損失関数とパラメータの値の和を最小にするパラメータを学習する</p>
<p>パラメータの和を評価することでパラメータが大きくなるのを防ぐ</p>
<p>これによりモデルが<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>しないようにしている</p>
<p>汎化誤差を下げるために用いられることが多い</p>
<p> <a href="https://ai-trend.jp/basic-study/neural-network/regularization/">正則化の種類と目的 L1正則化 L2正則化について | AVILEN AI Trend</a></p>
<p> </p>
<blockquote>
<p>LASSO<br />Least Absolute Shrinkage and Selection Operator。L1ノルムという制約条件を与える<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>手法。パラメータのスパース推定を行う。 </p>
</blockquote>
<p>→ラッソ</p>
<p>→幾つかのパラメータを０（スパース）にする</p>
<p>→スパースであるとは、値のほとんどが0であること</p>
<p>→特定のデータの重みを0にする</p>
<p><span style="color: #212121; font-family: Lato, sans-serif; font-size: 14.6667px; font-style: normal; font-variant-ligatures: none; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre-wrap; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; float: none; display: inline !important;">→モデルに必要な情報を取捨選択してくれる</span> </p>
<p>→次元圧縮に使う（※<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を防がないわけではないはず）</p>
<p> </p>
<blockquote>
<p>Ridge<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a><br />L2<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項を使って説明変数の影響が大きくなり過ぎないようにする<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>。 </p>
</blockquote>
<p>→スパースにはならず、パラメータの大きさに応じてゼロに近づける</p>
<p>→汎化された滑らかなモデルを得ることができる</p>
<p>→パラメータのノルムにペナルティを課す</p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を防ぐ</p>
<p>→損失関数にパラメータの二乗ノルムを加えるとL2<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>になる</p>
<p>→荷重減衰：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>の重みパラメータwに対して、|w|2が大きくなり過ぎないように制約を与える</p>
<p>→重要でないパラメータを0に近づける</p>
<p><a href="https://itstudio.co/2020/02/13/9779/">RidgeとLasso | IT工房｜AI入門とWeb開発</a></p>
<p> </p>
<p><strong>Elastic Net</strong></p>
<p>LassoとEidgeの中間</p>
<p>  </p>
<p><strong>重みの制約</strong><br />ネットワークの自由度が高いと、過適合が起こりやすい<br />そこで、学習時に重みの自由度を制限する<br />これを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>という</p>
<p> </p>
<p><strong>正規化</strong></p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">データに対して何らかの計算を行い、全てのデータが0～1の間の大きさにすること</span></p>
<p> </p>
<p><strong>バッチ正規化</strong></p>
<p>一部の層の出力を正規化する</p>
<p> </p>
<p><strong>局所<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%F3%A5%C8%A5%E9">コントラ</a>スト正規化</strong></p>
<p>減算正規化と除算正規化の処理</p>
<p>画像処理の分野においては前処理として行われる</p>
<p> </p>
<p><strong>白色化</strong></p>
<p>各成分を互いに無相関にし、平均を 0、分散を 1 にする</p>
<p> </p>
<p><strong>グレースケール化</strong></p>
<p>画像を白黒画像に変換</p>
<p> </p>
<p><strong>平滑化</strong></p>
<p>細かいノイズの影響を除去</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%B9%A5%C8%A5%B0%A5%E9%A5%E0">ヒストグラム</a>平均</strong></p>
<p>画素ごとの明るさをスケーリングする</p>
<p> </p>
<p><strong>標準化</strong> </p>
<p>平均が0かつ分散を1にする</p>
<p> </p>
<p><strong>正規化に関する工夫</strong></p>
<p>正規化（標準化）しても層を伝播することで崩れていくという課題に対しては重みの初期値を工夫するというアプローチがとられた</p>
<p>→初期値の最適値はわからない</p>
<p>→乱数にネットワークの大きさに合わせた適当な係数をかけることで、データの分布が崩れにくい初期値がいくつか考えられた</p>
<p>→<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>に対してはXavierの初期値、ReLU関数に対してはHeの初期値がよい</p>
<p>  </p>
<h4>単語</h4>
<p><strong>再現率</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%B6%CD%DB%C0%AD">偽陽性</a>（False positive, FP）を減らす</p>
<p>全ての陽性サンプルを母数として、実際に陽性であることを見抜けたサンプル数を分子にする</p>
<p>→検出率というと分かりやすい</p>
<p>疾病判定に使われる</p>
<p> </p>
<p><strong>適合率</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%B6%B1%A2%C0%AD">偽陰性</a>（False negative, FN）を減らす</p>
<p>陽性であると判断したサンプル数を母数として、実際に陽性であったサンプル数を分子にする</p>
<p>リコメンドシステムなどに使われる</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/F%C3%CD">F値</a></strong></p>
<p>適合率と再現率の調和平均</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/MLP">MLP</a></strong></p>
<p>多重<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>な分離が可能になった</p>
<p><span style="color: #202122; font-family: sans-serif; font-size: 15.104px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">Multilayer perceptron</span></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>分離問題</strong></p>
<p>単純な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>で起こる</p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>になると分離できない←<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DF%A5%F3%A5%B9">ミンス</a>キーが指摘していた</p>
<p>多層にすることで解決</p>
<p> </p>
<p><strong>A/Bテスト</strong></p>
<p>ウェブサイトのより良いデザインの識別などに用いられる手法</p>
<p>異なるデザインや機能を備えたAとBをランダムに顧客に試してもらいよりよいものを識別する</p>
<p> </p>
<p><strong>パターンマッチング</strong></p>
<p>あるデータが、どのようなパターンに属しているか or 特定のパターンが出現するかを特定する手法</p>
<p> </p>
<p><strong>逆問題</strong></p>
<p>出力から入力を推定する問題や、入出力の関係性を解き明かす問題</p>
<p>（対義語）順問題</p>
<p> </p>
<p><strong>よい表現</strong></p>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は観測データの説明要因を捉え、人間の知識では気がつくことができない共通点を捉えることができる。これをよい表現という。</p>
<p>「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の父」の一人、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E8%A5%B7%A5%E5%A5%A2">ヨシュア</a>・ベンジオは良い表現に共通する世界に関する多くの一般的な事前知識として幾つかを提唱している（下記）</p>
<p><span style="color: #333333; font-family: -apple-system, 'Segoe UI', 'Helvetica Neue', 'Hiragino Kaku Gothic ProN', メイリオ, meiryo, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; float: none; display: inline !important;">-滑らかさ</span></p>
<p>-複数の説明要因</p>
<p>-<span style="color: #d32f2f;">説明要因の階層的構造</span></p>
<p>-半<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a></p>
<p>-<span style="color: #d32f2f;">タスク間の共通要因</span></p>
<p>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%BF%CD%CD%C2%CE">多様体</a></p>
<p>-自然な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>化</p>
<p>-時間的空間的一貫性<br />-スパース性（データの分布のまばらさ）<br />-<span style="color: #d32f2f;">要因の依存の単純性</span></p>
<p><span style="color: #d32f2f;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は赤字のものに着目している</span>。これらの事前知識を適切に活用できるのであれば、表現学習は必ずしも層の多い<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の形をしていなくてもよい</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a></strong></p>
<p>分散技術を用いたアプリケーション</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a></strong></p>
<p>並列処理を行うためのプログラミングモデル</p>
<p> </p>
<p> </p>
<p><strong>醜いア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%EB">ヒル</a>の子の定理</strong></p>
<p>認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似</p>
<p>特徴を選択しなければ表現の類似度に基づく分類は不可能である</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%B8%A5%A2%A5%F3">ベイジアン</a>ネットワーク</strong></p>
<p><a href="http://www.msi.co.jp/userconf/2018/pdf/muc18_401_2_1.pdf">http://www.msi.co.jp/userconf/2018/pdf/muc18_401_2_1.pdf</a></p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BB%A5%DE%A5%F3%A5%C6%A5%A3%A5%C3%A5%AF%A5%A6%A5%A7%A5%D6">セマンティックウェブ</a></strong></p>
<p>情報リソースに意味を付与することで、コンピュータで高度な意味処理を実現する</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a></strong></p>
<p>概念もしくは構成要素の体系化</p>
<p>語彙やその意味、それらの関係性を他の人と共有できるように、明確な約束事として定義しておくときに用いられるもの</p>
<p> </p>
<p><strong>ヘビーウェイト<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a></strong></p>
<p>対象世界の知識をどのように記述すべきかを哲学的にしっかり考えて行うもの</p>
<p>-cycプロジェクト</p>
<p> </p>
<p><strong>ライトウェイト<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a></strong></p>
<p>効率を重視し、とにかくコンピュータにデータを読み込ませてできる限り自動的に行うもの</p>
<p>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A1%BC%A5%BF%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">データマイニング</a>、ウェブマイニング</p>
<p> </p>
<p><strong>協調ベースフィルタリング</strong></p>
<p>購買履歴</p>
<p> </p>
<p><strong>内容ベースフィルタリング</strong></p>
<p>アイテムの特徴</p>
<p> </p>
<p><strong>知識獲得の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DC%A5%C8%A5%EB%A5%CD%A5%C3%A5%AF">ボトルネック</a></strong></p>
<p>人間が持っている一般常識が膨大で、それらの知識を全て扱うことは極めて困難</p>
<p>コンピュータが知識を獲得することの難しさを知識獲得の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DC%A5%C8%A5%EB%A5%CD%A5%C3%A5%AF">ボトルネック</a>と呼ぶ</p>
<p> </p>
<p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></strong></p>
<p>1970：ルールベース<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></p>
<p>1990：統計的<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></p>
<p>2016：ニューラル<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></p>
<p> </p>
<h4>各国の政策</h4>
<p><strong>LAWS</strong></p>
<p>AI殺傷平気 </p>
<p>いまだ現存しない</p>
<p> </p>
<p><strong>ア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%ED%A5%DE">シロマ</a>AI原則</strong></p>
<p>LAWSによる軍拡競争は避けるべきである</p>
<p>FLI（ス<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%A3%A1%BC">ティー</a>ブンホーキング、イーロンマスクも賛同者）が2017に発表</p>
<p> </p>
<p> </p>
<p> </p>
<blockquote class="twitter-tweet">
<p dir="ltr" lang="ja">G検定まで2日<br /><br />各国の経済成長戦略<br />日本 : 新産業構造ビジョン<br />イギリス : RAS 2020 戦略<br />ドイツ : デジタル戦略2025<br />中国 : インターネットプラスAI3年行動実施<br /><br />製造業のデジタル戦略<br />ドイツ : インダストリー4.0<br />中国 : 中国製造2025<a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a></p>
— モブ@aiエンジニア (@mobwin_) <a href="https://twitter.com/mobwin_/status/1278365528516485121?ref_src=twsrc%5Etfw">July 1, 2020</a></blockquote>
<p>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<h4> </h4>
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C4%A5%A4%A5%C3%A5%BF%A1%BC">ツイッター</a>拾い物</h4>
<p> <blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>　6-6<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>は行動の結果としての報酬を最大化するように学習する<br><br>・入出力がペアになってるわけではないので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a>とは異なる<br><br>・深層学習を組み込んだ深層<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>により研究が活発化している<br><br>かの有名なアルファ碁は<br>これを利用してます！<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1270571320724447232?ref_src=twsrc%5Etfw">2020年6月10日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>　7-2<br><br>・word2vecは、単語をベクトルとして扱う手法<br><br>・word2vecに触発され、fastTextや<br>ELMoなどの文字の情報を含める手法が誕生した<br><br>・CNNと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a>を組み合わせると<br>画像脚注付けが可能にる<br><br>・RNNはニューラル<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0%A5%DE%A5%B7%A5%F3">チューリングマシン</a>にも応用されている<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1271001573372510208?ref_src=twsrc%5Etfw">2020年6月11日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>　7-3<br><br>・RNNの聴覚、音声分野の応用に<br>Wavenetがある<br><br>・Wavenetは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%B9%E7%C0%AE">音声合成</a>の<br>両方を行うことができる<br><br>・合成された音声は、既存の手法より人間に近いものとなっている<br><br>7-3は2ページしかないので短めですね<br>んー、自分で実装したい...<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1271298905192325126?ref_src=twsrc%5Etfw">2020年6月12日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>　7-4<br><br>・アルファ碁は碁盤認識にCNN、<br>次の手の選択に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED">モンテカルロ</a>木探索を用いる<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>の改善には方策ベース、行動価値関数ベース、モデルベースがある<br><br>・意思決定行動を改善する手法も上述と似ており、全部入れるとRAINBOWモデルとなる<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1272046283130200066?ref_src=twsrc%5Etfw">2020年6月14日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-1<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は不良品検出、予兆検知、バラ積み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D4%A5%C3%A5%AD%A5%F3%A5%B0">ピッキング</a>などに<br>も応用されている<br><br>・不良品検出では、不良品のデータは僅かであるから、良品から学習して、異常検知アプローチを用いて不良品を検出する<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1272369994429390849?ref_src=twsrc%5Etfw">2020年6月15日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-2<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%B5%BF%CD">無人</a>自動走行による移動サービスを2020年に、高速道路でのトラック隊列走行を早ければ2022年に商業化することを目指す取り組みがある<br><br>・そのためには、実証実験の実施や<br>法整備が不可欠<br><br>・他にも、ロボットタクシーの計画もある<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1273210421646782465?ref_src=twsrc%5Etfw">2020年6月17日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-3<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%E2%BB%EB%B6%C0">内視鏡</a>画像診断などの診断支援にも用いられる<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%CF%CC%F4">創薬</a>の分野でも開発コストの削減や高速化に役立っている<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B2%A5%CE%A5%E0%B2%F2%C0%CF">ゲノム解析</a>にも応用して患者の特性に合わせた治療が試みられている<br><br>・説明責任が問われる分野への適用には課題あり<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1273449692119003137?ref_src=twsrc%5Etfw">2020年6月18日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-4<br><br>・今後、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BE%AF%BB%D2%B9%E2%CE%F0%B2%BD">少子高齢化</a>により介護職員への負担が予想されるため、その軽減に<br><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>が用いられている<br><br>・着衣介助などだけでなく、介護初心者に対する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%C1%A5%F3">コーチン</a>グにも応用されている<br><br>・介護者の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%B4%CD%FD%C5%AA">心理的</a>負担の軽減にも貢献している<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1273822676432216064?ref_src=twsrc%5Etfw">2020年6月19日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-5<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>はインフラ領域に様々な形で応用されている<br>(コン<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%EA%A1%BC%A5%C8">クリート</a>ひび割れ検出、舗装道路損傷判断、橋梁内部の損傷推定、送電線点検、トンネル切羽、廃棄物選別など)<br><br>・他にも、防犯や監視にも応用されている<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1275635335091720192?ref_src=twsrc%5Etfw">2020年6月24日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-6<br><br>・タクシー需要予測にオートエンコーダ系技術が応用されている<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>による<br>来店者情報把握で人員やディスプレイを最適化する試みがある<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%B5%BF%CD">無人</a>コンビニ実現に向けた取り組みがある<br><br>・双腕型マルチモーダルロボットが<br>開発されている<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1275760509996765184?ref_src=twsrc%5Etfw">2020年6月24日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  8-7<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は<br><br>物流(物流画像判別など)、<br><br>農業(収穫・仕分け支援、<br>農薬散布の最適化)、<br><br>金融(不正取引検知など)、<br><br>学習(先生の声、<br>黒板の文字の検索対象化など)、<br><br>インターネットサービス(ユーザコメント分析など)<br><br>にも応用されている<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1275999655495561216?ref_src=twsrc%5Etfw">2020年6月25日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a> 9-1<br><br>・法は人の行為や技術開発を制約することがある一方で、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%CE%A5%D9%A1%BC%A5%B7%A5%E7%A5%F3">イノベーション</a>の自由を支えている<br><br>・倫理は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%CE%A5%D9%A1%BC%A5%B7%A5%E7%A5%F3">イノベーション</a>を阻害するものと捉えられがちだが、現在のAIにまつわる倫理の議論は多様化する<br>「価値」に関することが多い<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1276356242072432641?ref_src=twsrc%5Etfw">2020年6月26日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  9-2<br><br>・プロダクトを考える際には、<br><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>を使うことが<br>目的化しないように気をつける。<br><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>の方がいいことも多々ある。<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%A4%A1%A6%A5%C7%A5%B6%A5%A4%A5%F3">バイ・デザイン</a>(開発段階からプライバシーやセキュリティの観点を考慮する)ことで価値を設計として埋め込む<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1276731673288167424?ref_src=twsrc%5Etfw">2020年6月27日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a> 9-3<br><br>・データを使う際には、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%F8%BA%EE%B8%A2%CB%A1">著作権法</a>、<br><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D4%C0%B5%B6%A5%C1%E8%CB%C9%BB%DF%CB%A1">不正競争防止法</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C4%BF%CD%BE%F0%CA%F3%CA%DD%B8%EE%CB%A1">個人情報保護法</a>などの制約に留意する<br><br>・契約を結ぶときには、役割と責任を明確にする<br><br>・デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>に潜在する偏り<br>(現実世界の偏り、データベースに登録されていない情報がある、など)に留意する<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1277442507173814272?ref_src=twsrc%5Etfw">2020年6月29日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  9-4<br><br>・データを加工する際にはプライバシーに配慮する(特徴量を抽出して元データは速やかに破棄するなど)<br><br>・目標間の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C8%A5%EC%A1%BC%A5%C9%A5%AA%A5%D5">トレードオフ</a>(透明性とセキュリティなど)は優先順位をつける<br><br>・ハッキングや<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D4%C0%B5%A5%A2%A5%AF%A5%BB%A5%B9">不正アクセス</a>の可能性も踏まえ、「絶対安全」は無いと心得る<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1277897398434447360?ref_src=twsrc%5Etfw">2020年6月30日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  9-5<br><br>・プロダクトは、知的財産として守られなければならず、知的財産法が整備されている<br><br>・データを集めた当初とは違う目的で使用する際には再び本人の同意が必要で、法に触れないとしても倫理的な配慮も必要<br><br>・AIの予期しない振る舞いには注意を払う<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1278166024949391360?ref_src=twsrc%5Etfw">2020年7月1日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  9-6<br><br>・クライシスマネジメントでは、<br>想定される危機について考察し続けるほか、「防災訓練」をしておくことも大切<br><br>・対応策は社会にアピールする他、プロダクトデザインに反映することが大事<br><br>これで最後です！<br>見てくれた皆様<br>ありがとうございました！<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1278527125553737728?ref_src=twsrc%5Etfw">2020年7月2日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>  6-7<br><br>・深層学習は、画像などの識別タスクだけでなく生成タスクにも用いられる<br><br>・VAEは、データの空間分布を統計分布に変換してデータ生成に用いる<br><br>・GANは、画像を生成する側(ジェネレーター)とそれを識別する側(ディスクリミネーター)を競わせて学習する<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1270642535312977920?ref_src=twsrc%5Etfw">2020年6月10日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p><blockquote data-conversation="none" class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr"><a href="https://twitter.com/hashtag/G%E6%A4%9C%E5%AE%9A?src=hash&amp;ref_src=twsrc%5Etfw">#G検定</a>　7-1<br><br>・一般画像認識の手段にR-CNNがある(画像の切り出しは非CNN)<br><br>・fastRCNNは切り出しもCNN。<br>他にもfasterRCNN、YOLO、<a class="keyword" href="http://d.hatena.ne.jp/keyword/SSD">SSD</a>などがある<br><br>・セマンティックセグメンテーションは画素単位で識別する<br><br>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%B9%A5%BF%A5%F3%A5%B9">インスタンス</a>セグメンテーションは物体ごとに識別する<a href="https://twitter.com/hashtag/%E9%A7%86%E3%81%91%E5%87%BA%E3%81%97%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%A8%E7%B9%8B%E3%81%8C%E3%82%8A%E3%81%9F%E3%81%84?src=hash&amp;ref_src=twsrc%5Etfw">#駆け出しエンジニアと繋がりたい</a></p>&mdash; ユウキ@東大生×プログラミング×AI (@No1Yuki33937424) <a href="https://twitter.com/No1Yuki33937424/status/1270916829318270976?ref_src=twsrc%5Etfw">2020年6月11日</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </p>
<p> </p>
<p> </p>