<script async src="https://cse.google.com/cse.js?cx=e5aef4d5c058203d2"></script>
<div class="gcse-search"></div>
    <div class="entry-content">

    <h1 id="ディープラーニングG検定"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>G検定</h1>

<p>last update : 2020/10/27</p>

<ul class="table-of-contents">
    <li><a href="#ディープラーニングG検定">ディープラーニングG検定</a><ul>
            <li><a href="#はじめに">はじめに</a></li>
            <li><a href="#１人工知能AIとは人工知能の定義">１．📘人工知能（AI）とは（人工知能の定義）</a><ul>
                    <li><a href="#AIの定義">AIの定義</a></li>
                    <li><a href="#人工知能レベル">人工知能レベル</a></li>
                    <li><a href="#AI効果">AI効果</a></li>
                    <li><a href="#ロボットとの違い">ロボットとの違い</a></li>
                    <li><a href="#歴史">歴史</a><ul>
                            <li><a href="#-ENIAC">✅ 💻ENIAC</a></li>
                            <li><a href="#-ダートマス会議">✅ ダートマス会議</a></li>
                            <li><a href="#-第１次AIブーム">✅ 第１次AIブーム</a></li>
                            <li><a href="#-第２次AIブーム">✅ 第２次AIブーム</a></li>
                            <li><a href="#-第３次AIブーム">✅ 第３次AIブーム</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#２人工知能をめぐる動向">２．📘人工知能をめぐる動向</a><ul>
                    <li><a href="#2-1探索推論">2-1.📘探索・推論</a><ul>
                            <li><a href="#-探索木">✅ 探索木</a></li>
                            <li><a href="#-ハノイの塔">✅ ハノイの塔</a></li>
                            <li><a href="#-ロボットの行動計画">✅ ロボットの行動計画</a></li>
                            <li><a href="#-ボードゲーム">✅ ボードゲーム</a></li>
                            <li><a href="#-コスト">✅ コスト</a></li>
                            <li><a href="#-Mini-Max法">✅ Mini-Max法</a></li>
                            <li><a href="#-α-β法">✅ α-β法</a></li>
                            <li><a href="#-モンテカルロ法">✅ モンテカルロ法</a></li>
                        </ul>
                    </li>
                    <li><a href="#2-2知識表現">2-2.📘知識表現</a><ul>
                            <li><a href="#-ELIZAイライザ">✅ 💻ELIZA（イライザ）</a><ul>
                                    <li><a href="#-イライザ効果">✓ イライザ効果</a></li>
                                </ul>
                            </li>
                            <li><a href="#-エキスパートシステム">✅ 💻エキスパートシステム</a><ul>
                                    <li><a href="#-DENDRAL">✓ 💻DENDRAL</a></li>
                                    <li><a href="#-マイシンMYCIN">✓ 💻マイシン（MYCIN）</a></li>
                                </ul>
                            </li>
                            <li><a href="#-意味ネットワーク">✅ 意味ネットワーク</a></li>
                            <li><a href="#-Cycプロジェクト">✅ Cycプロジェクト</a></li>
                            <li><a href="#-オントロジーontology">✅ オントロジー（ontology）</a><ul>
                                    <li><a href="#-セマンティックウェブ">✓ セマンティックウェブ</a></li>
                                    <li><a href="#-ヘビーウェイトオントロジー重量オントロジー">✓ ヘビーウェイトオントロジー（重量オントロジー）</a></li>
                                    <li><a href="#-ライトウェイトオントロジー軽量オントロジー">✓ ライトウェイトオントロジー（軽量オントロジー）</a></li>
                                </ul>
                            </li>
                            <li><a href="#-ワトソン">✅ 💻ワトソン</a></li>
                            <li><a href="#-東ロボくん">✅ 💻東ロボくん</a></li>
                        </ul>
                    </li>
                    <li><a href="#2-3機械学習">2-3.📘機械学習</a><ul>
                            <li><a href="#-レコメンデーションシステム">✅ 💻レコメンデーションシステム</a></li>
                        </ul>
                    </li>
                    <li><a href="#2-4深層学習ディープラーニング">2-4.📘深層学習（ディープラーニング）</a><ul>
                            <li><a href="#-SuperVision">✅ 💻SuperVision</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#３人工知能分野の問題">３．📘人工知能分野の問題</a><ul>
                    <li><a href="#3-1トイプロブレムおもちゃの問題">3-1.📘トイプロブレム（おもちゃの問題）</a></li>
                    <li><a href="#3-2フレーム問題">3-2.📘フレーム問題</a></li>
                    <li><a href="#3-3強いAI弱いAI">3-3.📘強いAI・弱いAI</a><ul>
                            <li><a href="#-汎用AI特化型AI">✅ 汎用AI、特化型AI</a></li>
                            <li><a href="#-中国語の部屋">✅ 中国語の部屋</a></li>
                            <li><a href="#-ロジャーペンローズ">✅ 🎩ロジャー・ペンローズ</a></li>
                        </ul>
                    </li>
                    <li><a href="#3-4身体性">3-4.📘身体性</a></li>
                    <li><a href="#3-5シンボルグラウンディング問題">3-5.📘シンボルグラウンディング問題</a><ul>
                            <li><a href="#-知識獲得のボトルネック">✅ 知識獲得のボトルネック</a></li>
                            <li><a href="#-ニューラル機械翻訳">✅ ニューラル機械翻訳</a><ul>
                                    <li><a href="#-seq2seq">✓ seq2seq：</a></li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                    <li><a href="#3-6特徴量設計">3-6.📘特徴量設計</a></li>
                    <li><a href="#3-7チューリングテスト">3-7.📘チューリングテスト</a><ul>
                            <li><a href="#-ローブナーコンテスト">✅ ローブナーコンテスト</a></li>
                        </ul>
                    </li>
                    <li><a href="#3-8シンギュラリティ技術的特異点">3-8.📘シンギュラリティ（技術的特異点）</a><ul>
                            <li><a href="#-収穫加速の法則">✓ 収穫加速の法則</a></li>
                            <li><a href="#-シンギュラリティに関する発言等">✓ シンギュラリティに関する発言等</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
    </li>
    <li><a href="#４機械学習の具体的手法">４．📘機械学習の具体的手法</a><ul>
            <li><a href="#4-1代表的な手法">4-1.📘代表的な手法</a><ul>
                    <li><a href="#-教師あり学習">✅ 教師あり学習</a><ul>
                            <li><a href="#-回帰問題">✓ 回帰問題</a></li>
                            <li><a href="#-単回帰分析重回帰分析">✓ 単回帰分析・重回帰分析</a></li>
                            <li><a href="#-重回帰分析の注意事項">✓ 重回帰分析の注意事項</a></li>
                            <li><a href="#-分類問題">✓ 分類問題</a></li>
                        </ul>
                    </li>
                    <li><a href="#-教師なし学習">✅ 教師なし学習</a><ul>
                            <li><a href="#-k-means法">✓ k-means法</a></li>
                            <li><a href="#-主成分分析PCA">✓ 主成分分析（PCA）</a></li>
                        </ul>
                    </li>
                    <li><a href="#-強化学習">✅ 強化学習</a></li>
                </ul>
            </li>
            <li><a href="#4-2データの扱い">4-2.📘データの扱い</a><ul>
                    <li><a href="#-欠損値処理">✅ 欠損値処理</a><ul>
                            <li><a href="#-リストワイズ法">✓ リストワイズ法</a></li>
                            <li><a href="#-回帰補完">✓ 回帰補完</a></li>
                        </ul>
                    </li>
                    <li><a href="#-カテゴリデータ">✅ カテゴリデータ</a><ul>
                            <li><a href="#-マッピング">✓ マッピング</a></li>
                            <li><a href="#-ワンホットエンコーディング">✓ ワンホットエンコーディング</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#4-3応用評価指標">4-3.📘応用・評価指標</a><ul>
                    <li><a href="#-混同行列">✅ 混同行列</a></li>
                    <li><a href="#-オーバーフィッティングアンダーフィッティング">✅ オーバーフィッティング、アンダーフィッティング</a></li>
                    <li><a href="#-正則化">✅ 正則化</a></li>
                </ul>
            </li>
        </ul>
    </li>
    <li><a href="#５ディープラーニングの概要">５．📘ディープラーニングの概要</a><ul>
            <li><a href="#5-1ニューラルネットワークとディープラーニング">5-1.📘ニューラルネットワークとディープラーニング</a><ul>
                    <li><a href="#-単純パーセプトロン">✅ 単純パーセプトロン</a></li>
                    <li><a href="#-多層パーセプトロン">✅ 多層パーセプトロン</a></li>
                    <li><a href="#-ディープラーニング">✅ ディープラーニング</a></li>
                    <li><a href="#-用語">✅ 用語</a></li>
                </ul>
            </li>
            <li><a href="#5-2既存のニューラルネットワークにおける問題">5-2.📘既存のニューラルネットワークにおける問題</a></li>
            <li><a href="#5-3ディープラーニングのアプローチ">5-3.📘ディープラーニングのアプローチ</a><ul>
                    <li><a href="#-オートエンコーダautoencoder自己符号化器">✅ オートエンコーダ（autoencoder、自己符号化器）</a></li>
                    <li><a href="#-積層オートエンコーダ">✅ 積層オートエンコーダ</a></li>
                    <li><a href="#-ファインチューニング">✅ ファインチューニング</a></li>
                    <li><a href="#-深層信念ネットワーク参考">✅ 深層信念ネットワーク（参考）</a></li>
                    <li><a href="#-現状">✅ 現状</a></li>
                </ul>
            </li>
            <li><a href="#5-4CPU-と-GPU">5-4.📘CPU と GPU</a><ul>
                    <li><a href="#-CPU">✅ CPU</a></li>
                    <li><a href="#-GPU">✅ GPU</a></li>
                </ul>
            </li>
            <li><a href="#5-5ディープラーニングにおけるデータ量">5-5.📘ディープラーニングにおけるデータ量</a><ul>
                    <li><a href="#-バーニーおじさんのルール">✅ バーニーおじさんのルール</a></li>
                    <li><a href="#-次元の呪い">✅ 次元の呪い</a></li>
                    <li><a href="#-その他の機械学習に関する定理">✅ その他の機械学習に関する定理</a></li>
                </ul>
            </li>
            <li><a href="#ディープラーニングのフレームワーク">ディープラーニングのフレームワーク</a></li>
            <li><a href="#ヨシュアベンジオ">🎩ヨシュア・ベンジオ</a></li>
        </ul>
    </li>
    <li><a href="#６ディープラーニングの手法">６．📘ディープラーニングの手法</a><ul>
            <li><a href="#6-1活性化関数">6-1.📘活性化関数</a><ul>
                    <li><a href="#-tanh関数ハイパボリックタンジェント関数双曲線正接関数">✅ tanh関数（ハイパボリックタンジェント関数）：双曲線正接関数</a></li>
                    <li><a href="#-ReLU関数Rectified-Linear-Unit正規化線形関数">✅ ReLU関数（Rectified Linear Unit）：正規化線形関数</a></li>
                    <li><a href="#-過学習">✅ 過学習</a></li>
                </ul>
            </li>
            <li><a href="#6-2学習率の最適化">6-2.📘学習率の最適化</a><ul>
                    <li><a href="#-勾配降下法">✅ 勾配降下法</a></li>
                    <li><a href="#-勾配降下法の問題と改善">✅ 勾配降下法の問題と改善</a><ul>
                            <li><a href="#-モーメンタムMomentum慣性">✓ モーメンタム（Momentum、慣性）</a></li>
                            <li><a href="#-AdaGrad">✓ AdaGrad</a></li>
                            <li><a href="#-Adadelta">✓ Adadelta</a></li>
                            <li><a href="#-RMSprop">✓ RMSprop</a></li>
                            <li><a href="#-Adam">✓ Adam</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#6-3更なるテクニック">6-3.📘更なるテクニック</a><ul>
                    <li><a href="#-ドロップアウト">✅ ドロップアウト</a></li>
                    <li><a href="#-early-stopping">✅ early stopping</a></li>
                    <li><a href="#-データの正規化重みの初期化">✅ データの正規化・重みの初期化</a><ul>
                            <li><a href="#-データの正規化">✓ データの正規化</a></li>
                            <li><a href="#-重みの初期化">✓ 重みの初期化</a></li>
                            <li><a href="#-ベイズ最適化">✓ ベイズ最適化</a></li>
                            <li><a href="#-スパースなデータ">✓ スパースなデータ</a></li>
                        </ul>
                    </li>
                    <li><a href="#-バッチ正規化">✅ バッチ正規化</a></li>
                    <li><a href="#-End-to-End-Learning一気通貫学習">✅ End to End Learning（一気通貫学習）</a></li>
                </ul>
            </li>
            <li><a href="#6-4CNN畳み込みニューラルネットワーク">6-4.📘CNN（畳み込みニューラルネットワーク）</a><ul>
                    <li><a href="#-畳み込み層">✅ 畳み込み層</a></li>
                    <li><a href="#-プーリング層">✅ プーリング層</a><ul>
                            <li><a href="#-maxプーリング">✓ maxプーリング</a></li>
                            <li><a href="#-avgプーリング">✓ avgプーリング</a></li>
                            <li><a href="#-Lpプーリング">✓ Lpプーリング</a></li>
                        </ul>
                    </li>
                    <li><a href="#-全結合層">✅ 全結合層</a></li>
                    <li><a href="#-データ拡張">✅ データ拡張</a></li>
                    <li><a href="#-CNNの発展形">✅ CNNの発展形</a></li>
                </ul>
            </li>
            <li><a href="#6-5RNNリカレント-ニューラルネットワーク">6-5.📘RNN（リカレント ニューラルネットワーク）</a><ul>
                    <li><a href="#-LSTMLong-Short-Term-Memory">✅ LSTM（Long Short-Term Memory）</a></li>
                    <li><a href="#-GRUGated-Recurrent-Unit">✅ GRU（Gated Recurrent Unit）</a></li>
                    <li><a href="#-RNNの発展形">✅ RNNの発展形</a><ul>
                            <li><a href="#-Bidirectional-RNN">✓ Bidirectional RNN</a></li>
                            <li><a href="#-RNN-Encoder-Decoder">✓ RNN Encoder-Decoder</a></li>
                            <li><a href="#-Attention">✓ Attention</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#その他の応用">その他の応用</a><ul>
                    <li><a href="#-転移学習">✅ 転移学習</a></li>
                    <li><a href="#-蒸留">✅ 蒸留</a></li>
                </ul>
            </li>
            <li><a href="#6-6深層強化学習">6-6.📘深層強化学習</a><ul>
                    <li><a href="#-DQNDeep-Q-learning">✅ DQN（Deep Q-learning）</a></li>
                </ul>
            </li>
            <li><a href="#6-7深層生成モデル">6-7.📘深層生成モデル</a><ul>
                    <li><a href="#-画像生成モデル">✅ 画像生成モデル</a><ul>
                            <li><a href="#-VAEVariable-AutoEncoder">✓ VAE（Variable AutoEncoder）</a></li>
                            <li><a href="#-GAN敵対的生成ネットワーク">✓ GAN（敵対的生成ネットワーク）</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
    </li>
    <li><a href="#７ディープラーニングの研究分野">７．📘ディープラーニングの研究分野</a><ul>
            <li><a href="#7-1画像認識">7-1.📘画像認識</a><ul>
                    <li><a href="#-ILSVRCImagenet-Large-Scale-Visual-Recognition-Challenge">✅ ILSVRC（Imagenet Large Scale Visual Recognition Challenge）</a></li>
                    <li><a href="#-AlexNet">✅ AlexNet</a></li>
                    <li><a href="#-R-CNNRegional-CNN">✅ R-CNN（Regional CNN）</a></li>
                    <li><a href="#-高速RCNNfast-RCNN">✅ 高速RCNN（fast RCNN）</a></li>
                    <li><a href="#-faster-RCNN">✅ faster RCNN</a></li>
                    <li><a href="#-YOLOYou-Only-Look-at-Once">✅ YOLO（You Only Look at Once）</a></li>
                    <li><a href="#-SSDSingle-Shot-Detector">✅ SSD（Single Shot Detector）</a></li>
                    <li><a href="#-セマンティックセグメンテーション">✅ セマンティックセグメンテーション</a></li>
                    <li><a href="#-インスタンスセグメンテーション">✅ インスタンスセグメンテーション</a></li>
                    <li><a href="#-完全畳み込みネットワークFCN">✅ 完全畳み込みネットワーク（FCN）</a></li>
                    <li><a href="#-画像データの前処理">✅ 画像データの前処理</a></li>
                </ul>
            </li>
            <li><a href="#7-2自然言語処理">7-2.📘自然言語処理</a><ul>
                    <li><a href="#-関連ワード">✅ 関連ワード</a><ul>
                            <li><a href="#-言語モデル">✓ 言語モデル</a></li>
                            <li><a href="#-分散表現">✓ 分散表現</a></li>
                            <li><a href="#-構文解析">✓ 構文解析</a></li>
                            <li><a href="#-照応解析">✓ 照応解析</a></li>
                            <li><a href="#-談話解析">✓ 談話解析</a></li>
                            <li><a href="#-形態素解析">✓ 形態素解析</a></li>
                            <li><a href="#-N-gram">✓ N-gram</a></li>
                        </ul>
                    </li>
                    <li><a href="#-bag-of-words">✅ bag-of-words</a></li>
                    <li><a href="#-TF-IDFTerm-Frequency---Inverse-Document-Frequency">✅ TF-IDF（Term Frequency - Inverse Document Frequency）</a></li>
                    <li><a href="#-隠れマルコフモデル">✅ 隠れマルコフモデル</a></li>
                    <li><a href="#-word2vec">✅ word2vec</a><ul>
                            <li><a href="#-CBOWCountinuous-Bag-of-Words">✓ CBOW（Countinuous Bag-of-Words）</a></li>
                            <li><a href="#-スキップグラムSkip-gram">✓ スキップグラム（Skip-gram）</a></li>
                        </ul>
                    </li>
                    <li><a href="#-fastText">✅ fastText</a></li>
                    <li><a href="#-ELMo">✅ ELMo</a></li>
                    <li><a href="#-マルチタスク言語処理">✅ マルチタスク言語処理</a></li>
                    <li><a href="#-ニューラル画像脚注付け">✅ ニューラル画像脚注付け</a></li>
                    <li><a href="#-ニューラルチューリングマシン">✅ ニューラルチューリングマシン</a></li>
                    <li><a href="#-Tay">✅ 💻Tay</a></li>
                    <li><a href="#-BERT">✅ BERT</a></li>
                </ul>
            </li>
            <li><a href="#7-3音声処理">7-3.📘音声処理</a><ul>
                    <li><a href="#-WaveNet">✅ WaveNet</a></li>
                    <li><a href="#-それまでの音声認識">✅ それまでの音声認識</a></li>
                </ul>
            </li>
            <li><a href="#7-4ロボティクス-強化学習">7-4.📘ロボティクス （強化学習）</a><ul>
                    <li><a href="#-強化学習の課題">✅ 強化学習の課題</a></li>
                </ul>
            </li>
            <li><a href="#7-5マルチモーダル">7-5.📘マルチモーダル</a></li>
        </ul>
    </li>
    <li><a href="#８ディープラーニングの応用に向けて">８．📘ディープラーニングの応用に向けて</a><ul>
            <li><a href="#8-1産業への応用">8-1.📘産業への応用</a><ul>
                    <li><a href="#-ものづくり">✅ ものづくり</a></li>
                    <li><a href="#-モビリティ">✅ モビリティ</a></li>
                    <li><a href="#-医療">✅ 医療</a></li>
                    <li><a href="#-介護">✅ 介護</a></li>
                    <li><a href="#-インフラ防犯監視">✅ インフラ・防犯、監視</a></li>
                    <li><a href="#-サービス小売">✅ サービス・小売</a></li>
                    <li><a href="#-その他">✅ その他</a></li>
                    <li><a href="#-応用路線">✅ 応用路線</a></li>
                </ul>
            </li>
            <li><a href="#8-2法律">8-2.📘法律</a><ul>
                    <li><a href="#-法">✅ 法</a></li>
                    <li><a href="#-プライバシーバイデザイン">✅ プライバシー・バイ・デザイン</a></li>
                    <li><a href="#-データの収集">✅ データの収集</a></li>
                    <li><a href="#-日本の著作権法">✅ 日本の著作権法</a></li>
                    <li><a href="#-オープンイノベーションの弊害">✅ オープンイノベーションの弊害</a></li>
                    <li><a href="#-AIデータの利用に関する契約ガイドライン">✅ AI・データの利用に関する契約ガイドライン</a></li>
                    <li><a href="#-知的財産法">✅ 知的財産法</a></li>
                    <li><a href="#-次世代知財システム検討委員会報告書">✅ 次世代知財システム検討委員会報告書</a></li>
                    <li><a href="#-利用者保護">✅ 利用者保護</a></li>
                    <li><a href="#-ドローンでの利用参考">✅ ドローンでの利用（参考）</a><ul>
                            <li><a href="#-許可が必要になる飛行場所">✓ 許可が必要になる飛行場所</a></li>
                            <li><a href="#-承認が必要になる飛行方法">✓ 承認が必要になる飛行方法</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#8-3倫理">8-3.📘倫理</a><ul>
                    <li><a href="#-IEEE-P7000シリーズ">✅ IEEE P7000シリーズ</a></li>
                    <li><a href="#-データセットの偏り">✅ データセットの偏り</a></li>
                    <li><a href="#-カメラ画像利活用ガイド">✅ カメラ画像利活用ガイド</a></li>
                    <li><a href="#-自律型致死性兵器LAWSLethal-Autonomous-Weapon-Systems">✅ 自律型致死性兵器（LAWS：Lethal Autonomous Weapon Systems）</a></li>
                    <li><a href="#-人工知能学会９つの指針">✅ 人工知能学会　９つの指針</a></li>
                </ul>
            </li>
            <li><a href="#8-4現行の議論">8-4.📘現行の議論</a><ul>
                    <li><a href="#-日本ディープラーニング協会の見解">✅ 日本ディープラーニング協会の見解</a></li>
                    <li><a href="#-目標間のトレードオフ">✅ 目標間のトレードオフ</a></li>
                    <li><a href="#-Adversarial-ExampleAdversarial-attacks参考">✅ Adversarial Example（Adversarial attacks）　（参考）</a></li>
                    <li><a href="#-クライシスマネジメント危機管理">✅ クライシス・マネジメント（危機管理）</a></li>
                    <li><a href="#-透明性レポート">✅ 透明性レポート</a></li>
                    <li><a href="#-指針作り">✅ 指針作り</a></li>
                </ul>
            </li>
            <li><a href="#その他">その他</a><ul>
                    <li><a href="#-日本">✅ 日本</a><ul>
                            <li><a href="#-新産業構造ビジョン">✓ 新産業構造ビジョン</a></li>
                            <li><a href="#-人間中心のＡＩ社会原則及びＡＩ戦略2019有識者提案">✓ 「人間中心のＡＩ社会原則」及び「ＡＩ戦略2019(有識者提案)」</a></li>
                        </ul>
                    </li>
                    <li><a href="#-中国">✅ 中国</a><ul>
                            <li><a href="#-中国製造2025">✓ 中国製造2025</a></li>
                            <li><a href="#-インターネットプラスAI3年行動実施方案">✓ インターネットプラスAI3年行動実施方案</a></li>
                        </ul>
                    </li>
                    <li><a href="#-英国">✅ 英国</a><ul>
                            <li><a href="#-RAS2020戦略">✓ RAS2020戦略</a></li>
                        </ul>
                    </li>
                    <li><a href="#-ドイツ">✅ ドイツ</a><ul>
                            <li><a href="#-デジタル戦略2025参考">✓ デジタル戦略2025（参考）</a></li>
                        </ul>
                    </li>
                    <li><a href="#-Coursera">✅ Coursera</a></li>
                </ul>
            </li>
        </ul>
    </li>
</ul>

<h2 id="はじめに">はじめに</h2>

<ul>
<li><a href="https://www.jdla.org/certificate/general/">一般社団法人 日本ディープラーニング協会　G検定</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>G検定に向けた情報整理を行う。</li>
<li>構成は<a href="https://www.jdla.org/certificate/general/#general_No03">シラバス</a>に従い、該当項目には「📘」を付す。</li>
<li>参考図書<br />
<a href="https://www.amazon.co.jp/dp/4798157554">ディープラーニング G検定(ジェネラリスト) 公式テキスト</a></li>
<li>【参考】模擬テスト<br />
<a href="http://study-ai.com/generalist/">Study-AI G検定 模擬テスト</a></li>
<li>注意事項！

<ul>
<li>自分自身の知識の確認と整理を目的に作成したものを掲載しています。</li>
<li>この記事だけで十分な知識をつけることはできません。</li>
<li>公式テキスト等を活用し、必ず自らで学習を行うようにしてください。</li>
<li>そのうえで、テスト前のキーワード確認等にご活用ください。</li>
</ul>
</li>
</ul>


<h2 id="１人工知能AIとは人工知能の定義">１．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>（AI）とは（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>の定義）</h2>

<h3 id="AIの定義">AIの定義</h3>

<ul>
<li>専門家の間で共有されている定義はない。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>であるかどうかは「人によって違う」。</li>
<li>定義の例

<ul>
<li>「推論、認識、判断など、人間と同じ知的な処理能力を持つ機械（情報処理システム）」</li>
<li>🎩<strong>松尾豊</strong><br />
「人工的につくられた人間のような知能、ないしはそれをつくる技術」</li>
<li>🎩<strong>アーサー・サミュエル</strong><br />
「明示的にプログラムしなくても学習する能力をコンピュータに与える研究分野」</li>
<li>「周囲の状況（入力）によって行動（出力）を変えるエージェント（プログラム）」という定義もある。</li>
</ul>
</li>
</ul>


<h3 id="人工知能レベル"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>レベル</h3>

<table>
<thead>
<tr>
<th>レベル</th>
<th>説明</th>
</tr>
</thead>
<tbody>
<tr>
<td>レベル１</td>
<td>シンプルな制御プログラム。<br><strong>ルールベース</strong>。</td>
</tr>
<tr>
<td>レベル２</td>
<td>古典的な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>。<br><strong>探索・推論</strong>を行う。知識データを利用する。</td>
</tr>
<tr>
<td>レベル３</td>
<td><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a></strong>を取り入れた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>。<br>多くのデータから入力・出力関係を学習する。</td>
</tr>
<tr>
<td>レベル４</td>
<td><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a></strong>を取り入れた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>。<br>特徴量による学習を行う。</td>
</tr>
</tbody>
</table>


<h3 id="AI効果">AI効果</h3>

<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>の原理がわかると「単純な自動化である」とみなしてしまう人間の心理のこと。</p>

<h3 id="ロボットとの違い">ロボットとの違い</h3>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>では「考える」という、目に見えないものを中心に扱っている。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>ではロボットの「脳の部分」を扱っている。（脳だけ、というわけではない）</li>
<li>ロボットの研究者は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>の研究者というわけではない。</li>
</ul>


<h3 id="歴史">歴史</h3>

<h4 id="-ENIAC">✅ 💻<a class="keyword" href="http://d.hatena.ne.jp/keyword/ENIAC">ENIAC</a></h4>

<ul>
<li><strong>1946年</strong>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%E1%A5%EA">アメリ</a>カ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DA%A5%F3%A5%B7%A5%EB%A5%D0%A5%CB%A5%A2">ペンシルバニア</a>大学。</li>
<li>世界初の汎用電子式コンピュータ。</li>
</ul>


<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/6c/ENIAC_Penn1.jpg" alt="ENIAC" /></p>

<h4 id="-ダートマス会議">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C0%A1%BC%A5%C8%A5%DE%A5%B9">ダートマス</a>会議</h4>

<ul>
<li><strong>1956年</strong>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%E1%A5%EA">アメリ</a>カで開催。</li>
<li>🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A5%E7%A5%F3%A1%A6%A5%DE%A5%C3%A5%AB%A1%BC%A5%B7%A1%BC">ジョン・マッカーシー</a></strong>が初めて「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>（AI）」という言葉を使った。</li>
<li>世界初の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>プログラムといわれる💻<strong><a href="https://ja.wikipedia.org/wiki/Logic_Theorist">ロジック・セオリスト</a></strong>のデモを実施した。</li>
</ul>


<p><img src="https://miro.medium.com/max/1000/0*8MW8iP2QC_WNhmiW" alt="" /></p>

<h4 id="-第１次AIブーム">✅ 第１次AIブーム</h4>

<ul>
<li><strong>推論・探索</strong>が中心。</li>
<li><strong>トイ・プロブレム（おもちゃの問題）</strong>は解けても、現実の問題は解けないことが判明。</li>
</ul>


<p>⇒ 失望へ</p>

<h4 id="-第２次AIブーム">✅ 第２次AIブーム</h4>

<ul>
<li>💻<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%AD%A5%B9%A5%D1%A1%BC%A5%C8%A5%B7%A5%B9%A5%C6%A5%E0">エキスパートシステム</a></strong>が流行し、<strong><a href="https://www.weblio.jp/content/%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2">ナレッジエンジニア</a></strong>が必要とされた。

<blockquote><p><strong>ナレッジエンジニア</strong>とは、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>（AI）を応用したシステム構築を専門とする技術者（エンジニア）のことである。<a href="https://www.weblio.jp/content/%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2">（引用）</a></p></blockquote></li>
<li>日本<br />
💻<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%E8%B8%DE%C0%A4%C2%E5%A5%B3%A5%F3%A5%D4%A5%E5%A1%BC%A5%BF">第五世代コンピュータ</a></strong>という大型プロジェクトを推進、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%AD%A5%B9%A5%D1%A1%BC%A5%C8%A5%B7%A5%B9%A5%C6%A5%E0">エキスパートシステム</a>等に取り組んだ。</li>
<li>知識の蓄積・管理は大変！ということに気づく。

<blockquote><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%E8%B8%DE%C0%A4%C2%E5%A5%B3%A5%F3%A5%D4%A5%E5%A1%BC%A5%BF">第五世代コンピュータ</a>とは、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C4%CC%BE%A6%BB%BA%B6%C8%BE%CA">通商産業省</a>（現<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%D0%BA%D1%BB%BA%B6%C8%BE%CA">経済産業省</a>）が1982年に立ち上げた国家プロジェクトの開発目標である。<a href="https://ja.wikipedia.org/wiki/%E7%AC%AC%E4%BA%94%E4%B8%96%E4%BB%A3%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF">（引用）</a></p></blockquote></li>
</ul>


<p>⇒ 失望へ</p>

<h4 id="-第３次AIブーム">✅ 第３次AIブーム</h4>

<ul>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>・特徴表現</strong>が中心。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D3%A5%C3%A5%B0%A5%C7%A1%BC%A5%BF">ビッグデータ</a>による<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a></strong>、特徴量による<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>（深層学習）</strong>が流行。</li>
</ul>


<h2 id="２人工知能をめぐる動向">２．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>をめぐる動向</h2>

<h3 id="2-1探索推論">2-1.📘探索・推論</h3>

<h4 id="-探索木">✅ 探索木</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%FD%CD%A5%C0%E8%C3%B5%BA%F7">幅優先探索</a><br />
最短距離の解が必ずわかる。すべてを記憶するためメモリ容量が必要。<br />
<img src="https://upload.wikimedia.org/wikipedia/commons/b/bc/Breadth-first-tree.png" alt="幅優先探索" /></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%BC%A4%B5%CD%A5%C0%E8%C3%B5%BA%F7">深さ優先探索</a><br />
メモリは少なめでよいが、最短距離が必ずわかるわけではない。<br />
<img src="https://upload.wikimedia.org/wikipedia/commons/5/5d/Depth-first-tree.png" alt="深さ優先探索" /></li>
</ul>


<h4 id="-ハノイの塔">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CF%A5%CE%A5%A4">ハノイ</a>の塔</h4>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%8E%E3%82%A4%E3%81%AE%E5%A1%94">Wikipedia</a></li>
<li>以下のルールに従ってすべての円盤を右端の杭に移動させられれば完成。

<ul>
<li>3本の杭と、中央に穴の開いた大きさの異なる複数の円盤から構成される。</li>
<li>最初はすべての円盤が左端の杭に小さいものが上になるように順に積み重ねられている。</li>
<li>円盤を一回に一枚ずつどれかの杭に移動させることができるが、小さな円盤の上に大きな円盤を乗せることはできない。</li>
</ul>
</li>
</ul>


<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/60/Tower_of_Hanoi_4.gif" alt="ハノイの塔" /></p>

<h4 id="-ロボットの行動計画">✅ ロボットの行動計画</h4>

<ul>
<li>プランニング（<a href="https://ja.wikipedia.org/wiki/%E8%87%AA%E5%8B%95%E8%A8%88%E7%94%BB">Wikipedia-自動計画</a>）

<ul>
<li><strong>オフラインプランニング・静的プランニング</strong><br />
周囲の状況が既知で、その構造がよく理解されている場合に、行動の計画や戦略をあらかじめ組み立てて(計算して）おくこと。</li>
<li><strong>オンラインプランニング・動的プランニング</strong><br />
未知の環境において、周囲の状況が明らかになるにつれて行動の計画や戦略を修正すること。</li>
<li>リプランニング<br />
計画・戦略を修正すること。</li>
</ul>
</li>
<li>STRIPS

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Stanford">Stanford</a> Research Institute Problem Solver</li>
<li>自動計画に関する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>の一種。</li>
<li>前提条件、行動、結果を記述する。</li>
</ul>
</li>
<li>SHRDLU

<ul>
<li>1970年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%D5%A5%A9%A1%BC%A5%C9%C2%E7%B3%D8">スタンフォード大学</a>、🎩<strong>テリー・ウィノグラード</strong>。</li>
<li>英語の指示により画面上の積み木を動かす。</li>
<li>成果は<strong><a href="#-Cyc%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88">Cycプロジェクト</a></strong>に引き継がれている。</li>
<li><a href="https://www.youtube.com/watch?v=bo4RvYJYOzI">【Youtube】SHRDLU in Action</a><br />
<img src="https://upload.wikimedia.org/wikipedia/commons/b/bc/Shrdlu-original.jpg" alt="SHRDLU" /></li>
</ul>
</li>
</ul>


<h4 id="-ボードゲーム">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DC%A1%BC%A5%C9%A5%B2%A1%BC%A5%E0">ボードゲーム</a></h4>

<ul>
<li>1996年、💻**<a class="keyword" href="http://d.hatena.ne.jp/keyword/IBM">IBM</a> DeepBlue（ディープブルー）。「力任せの探索」だったが、チェスの世界チャンピオンを破った。

<blockquote><p>力まかせ探索（Brute-force search）またはしらみつぶし探索（Exhaustive search）は、単純だが非常に汎用的な計算機科学の問題解決法であり、全ての可能性のある解の候補を体系的に数えあげ、それぞれの解候補が問題の解となるかをチェックする方法である。（<a href="https://ja.wikipedia.org/wiki/%E5%8A%9B%E3%81%BE%E3%81%8B%E3%81%9B%E6%8E%A2%E7%B4%A2">引用</a>）</p></blockquote></li>
<li>2012年、💻<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DC%A5%F3%A5%AF%A5%E9%A1%BC%A5%BA">ボンクラーズ</a> が将棋において永世<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B4%FD%C0%BB">棋聖</a>に勝利。</li>
<li>2013年、💻ponanza が将棋において現役プロ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B4%FD%BB%CE">棋士</a>に勝利。</li>
<li>2016年、💻<strong>AlphaGo（アルファ碁）</strong>が韓国のプロ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B4%FD%BB%CE">棋士</a>に勝利。

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>が使われた。
<img src="https://tech-camp.in/note/wp-content/uploads/alphago-1024x519.png" alt="" /></li>
</ul>
</li>
<li>2017年、💻elmo が世界コンピュータ将棋選手権において ponanza に勝利。elmo 同士の対戦を行うことで学習を行った。</li>
</ul>


<h4 id="-コスト">✅ コスト</h4>

<ul>
<li>効率よく探索するため、時間や費用といった<strong>コスト</strong>の概念を取り入れている。</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%E5%A1%BC%A5%EA%A5%B9%A5%C6%A5%A3%A5%C3%A5%AF">ヒューリスティック</a>な知識</strong>を利用して探索を短縮することができる。<br />
※<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%E5%A1%BC%A5%EA%A5%B9%A5%C6%A5%A3%A5%C3%A5%AF">ヒューリスティック</a>：経験則の、試行錯誤的な</li>
</ul>


<h4 id="-Mini-Max法">✅ Mini-Max法</h4>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%9F%E3%83%8B%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E6%B3%95">Wikipedia</a></li>
<li>ゲーム戦略で利用される。</li>
<li>想定される「最大の損害」が最小になるように決断を行う戦略のこと。</li>
<li>自分の番はスコア最大、相手の番はスコア最小になるような戦略をとる。</li>
<li>この手法は全探索を行うため効率が悪い。</li>
</ul>


<h4 id="-α-β法">✅ α-β法</h4>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%AB%E3%83%95%E3%82%A1%E3%83%BB%E3%83%99%E3%83%BC%E3%82%BF%E6%B3%95">wikipedia</a></li>
<li>Mini-Max法の応用<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>。</li>
<li>読む必要のない手を打ち切ることで高速化を図っている。</li>
<li><strong>αカット</strong>は関心範囲の最小値のカット、<strong>βカット</strong>は最大値のカットを行う。</li>
</ul>


<h4 id="-モンテカルロ法">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED%CB%A1">モンテカルロ法</a></h4>

<ul>
<li>特徴：<br />
<strong>プレイアウト</strong>（ゲームを一度終局までもっていく）の結果、どの方法が一番勝率が高いかを評価する。</li>
<li>デメリット：<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D6%A5%EB%A1%BC%A5%C8%A5%D5%A5%A9%A1%BC%A5%B9">ブルートフォース</a>（力任せな方法）のため、組合せが多いと計算しきれない。</li>
</ul>


<h3 id="2-2知識表現">2-2.📘知識表現</h3>

<h4 id="-ELIZAイライザ">✅ 💻ELIZA（イライザ）</h4>

<ul>
<li>1966年、🎩<strong>ジョセフ・ワイゼンバウム</strong>。</li>
<li>「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%CC%B5%C7%BD">人工無能</a>」の元祖。精神科セラピストを演じた。</li>
<li>パターンに合致したら返答する「ルールベース」である。</li>
<li>その後開発された💻<strong>PARRY</strong>と会話した記録が残されており（<strong>RFC439</strong>）、中でも<strong>ICCC1972</strong>が有名。</li>
</ul>


<p><img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/ELIZA_conversation.jpg" alt="ELIZA" /></p>

<h5 id="-イライザ効果">✓ イライザ効果</h5>

<p>あたかも本物の人間と話しているように錯覚すること。</p>

<h4 id="-エキスパートシステム">✅ 💻<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%AD%A5%B9%A5%D1%A1%BC%A5%C8%A5%B7%A5%B9%A5%C6%A5%E0">エキスパートシステム</a></h4>

<h5 id="-DENDRAL">✓ 💻DENDRAL</h5>

<ul>
<li>1960年代、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%D5%A5%A9%A1%BC%A5%C9%C2%E7%B3%D8">スタンフォード大学</a>　🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%C9">エド</a>ワード・ファイゲンバウム</strong>。</li>
<li>未知の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CD%AD%B5%A1">有機</a>化合物を特定する。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%C1%CE%CC%CA%AC%C0%CF">質量分析</a>法で分析する。</li>
</ul>


<blockquote><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%C1%CE%CC%CA%AC%C0%CF">質量分析</a>法とは、分子をイオン化し、そのm/zを測定することによってイオンや分子の質量を測定する分析法である。（<a href="https://ja.wikipedia.org/wiki/%E8%B3%AA%E9%87%8F%E5%88%86%E6%9E%90%E6%B3%95">引用</a>）。</p></blockquote>

<h5 id="-マイシンMYCIN">✓ 💻マイシン（MYCIN）</h5>

<ul>
<li>1970年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%D5%A5%A9%A1%BC%A5%C9%C2%E7%B3%D8">スタンフォード大学</a>。</li>
<li>ルールベースで血液中の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%AF%A5%C6%A5%EA%A5%A2">バクテリア</a>の診断支援を行った。</li>
<li>正解確率の高い細菌名のリスト、信頼度、推論理由、推奨される<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%F4%CA%AA%CE%C5%CB%A1">薬物療法</a>コースを示した。</li>
<li>精度は専門医の80%に対し、69%であった。</li>
</ul>


<h4 id="-意味ネットワーク">✅ 意味ネットワーク</h4>

<ul>
<li>semantic network</li>
<li>人間の記憶の一種である<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%D5%CC%A3%B5%AD%B2%B1">意味記憶</a>の構造を表すためのモデル。</li>
<li>単語同士の意味関係をネットワークによって表現する。</li>
<li>概念を表す節（<strong>ノード</strong>）と、概念の意味関係を表す辺（<strong>エッジ</strong>）からなる、<strong>有向グラフ</strong>または<strong>無向グラフ</strong>である。</li>
</ul>


<blockquote><p><strong>無向グラフ</strong>のエッジには方向性がありません。エッジは "双方向" の関係を示します。
<strong>有向グラフ</strong>のエッジには方向性があります。エッジは "一方向" の関係を示します。（<a href="https://jp.mathworks.com/help/matlab/math/directed-and-undirected-graphs.html">引用</a>）</p></blockquote>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/305px-Semantic_Net.svg.png" alt="semantic network" /></p>

<h4 id="-Cycプロジェクト">✅ Cycプロジェクト</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/1984">1984</a>年、🎩ダグラス・レナート。</li>
<li>すべての一般知識を取り込もうという活動。</li>
<li>2001年からは<strong>OpenCyc</strong>として公開されている。</li>
<li><a href="https://www.cyc.com/">https://www.cyc.com/</a></li>
</ul>


<h4 id="-オントロジーontology">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>（ontology）</h4>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%B3%E3%83%88%E3%83%AD%E3%82%B8%E3%83%BC_(%E6%83%85%E5%A0%B1%E7%A7%91%E5%AD%A6)">wikipedia</a></li>
<li>🎩トム・グルーバーが提唱。</li>
<li>知識を体系化する方法論で、「概念化の明示的な仕様」（知識を記述するための仕様）と定義されている。</li>
<li>知識の形式表現であり、ある<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3">ドメイン</a>における概念間の関係のセットである。</li>
<li>is-a 関係（上位概念、下位概念、推移律）、part-of 関係を用いる。</li>
</ul>


<h5 id="-セマンティックウェブ">✓ <strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BB%A5%DE%A5%F3%A5%C6%A5%A3%A5%C3%A5%AF%A5%A6%A5%A7%A5%D6">セマンティックウェブ</a></strong></h5>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%82%BB%E3%83%9E%E3%83%B3%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%83%BB%E3%82%A6%E3%82%A7%E3%83%96">Wikipedia</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/W3C">W3C</a> の🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%A3%A5%E0%A1%A6%A5%D0%A1%BC%A5%CA%A1%BC%A5%BA%A1%E1%A5%EA%A1%BC">ティム・バーナーズ＝リー</a>によって提唱されたプロジェクト。</li>
<li>ウェブページの意味を扱うことができる「標準」や「ツール群」の開発により、ワールド・ワイド・ウェブの利便性を向上させようというもので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>を利用する。</li>
<li>プロジェクトの目的は、ウェブページの閲覧という行為（データ交換）に対し、意味の疎通を付け加えることにある。</li>
<li>情報リソースに意味を付与することで、コンピュータで高度な意味処理を実現したり、文書の意味に即した処理が行えるようにする。</li>
</ul>


<h5 id="-ヘビーウェイトオントロジー重量オントロジー">✓ ヘビーウェイト<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>（重量<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>）</h5>

<ul>
<li>人間が厳密にしっかりと考えて知識を記述していくアプローチ。</li>
<li>構成要素や意味的関係の正統性については、哲学的な考察が必要。</li>
</ul>


<h5 id="-ライトウェイトオントロジー軽量オントロジー">✓ ライトウェイト<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>（軽量<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>）</h5>

<ul>
<li>コンピュータにデータを読み込ませ、自動で概念間の関係性を見つけるアプローチ。</li>
<li>完全に正でなくても使えればOKと考える。</li>
<li><strong>ウェブマイニング</strong>、<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A1%BC%A5%BF%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">データマイニング</a></strong>で利用される。</li>
</ul>


<blockquote><p>ウェブマイニング（web mining）とは、ウェブサイトの構造やウェブ上のデータを利用して行う<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A1%BC%A5%BF%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">データマイニング</a>のことである。（<a href="https://www.weblio.jp/content/%E3%82%A6%E3%82%A7%E3%83%96%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0">引用</a>）</p>

<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A1%BC%A5%BF%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">データマイニング</a>（Data mining）とは、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%FD%B7%D7%B3%D8">統計学</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A5%BF%A1%BC%A5%F3%C7%A7%BC%B1">パターン認識</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>等のデータ解析の技法を大量のデータに網羅的に適用することで知識を取り出す技術のことである。（<a href="https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0">引用</a>）</p></blockquote>

<h4 id="-ワトソン">✅ 💻ワトソン</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/IBM">IBM</a> Watson</li>
<li>Question-Answering（質問応答）型。</li>
<li>2011年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%E1%A5%EA">アメリ</a>カのクイズ番組である「<a href="https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%91%E3%83%87%E3%82%A3!">ジェパディ！</a>」で優勝した。</li>
<li>ライトウェイト<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%F3%A5%C8%A5%ED%A5%B8%A1%BC">オントロジー</a>に該当する。</li>
</ul>


<p><img src="https://assets.media-platform.com/bi/dist/images/2019/11/18/5dceff793afd373944079d27-w1280.png" alt="Watson" /></p>

<h4 id="-東ロボくん">✅ 💻東ロボくん</h4>

<ul>
<li>2011年～2016年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%F1%CE%A9%BE%F0%CA%F3%B3%D8%B8%A6%B5%E6%BD%EA">国立情報学研究所</a>。</li>
<li>プロジェクトリーダーは🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%B7%B0%E6%B5%AA%BB%D2">新井紀子</a>。（著書『<a href="https://www.amazon.co.jp/dp/4492762396">AI vs.教科書が読めない子どもたち</a>』）</li>
<li>読解力に問題があり、何かしらのブレイクスルーが必要と判断され、開発は凍結された。</li>
<li>その後、人間側の読解力の問題に注目し、さまざまな活動を行っている。（<a href="https://www.ted.com/talks/noriko_arai_can_a_robot_pass_a_university_entrance_exam?language=ja">TED</a>がわかりやすい）</li>
</ul>


<h3 id="2-3機械学習">2-3.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a></h3>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D3%A5%C3%A5%B0%A5%C7%A1%BC%A5%BF">ビッグデータ</a>を活用する。</li>
<li>統計的<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>を行う。</li>
<li>応用例：<br />
レコメンデーションエンジン、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%D1%A5%E0%A5%D5%A5%A3%A5%EB%A5%BF%A1%BC">スパムフィルター</a></li>
</ul>


<h4 id="-レコメンデーションシステム">✅ 💻レコメンデーションシステム</h4>

<ul>
<li><p><strong>協調ベースフィルタリング</strong></p>

<ul>
<li><strong>ユーザーの購買履歴</strong>からおすすめを表示するアプローチ。</li>
<li>ユーザーの行動をもとにレコメンドする。</li>
</ul>
</li>
<li><p><strong>内容ベースフィルタリング</strong></p>

<ul>
<li><strong>アイテムの特徴</strong>をもとにおすすめを表示するアプローチ。</li>
<li>検索キーワードに関連する類似アイテムをレコメンドする。</li>
<li>アイテムの特長ベクトルをもとにレコメンドである。</li>
</ul>
</li>
</ul>


<h3 id="2-4深層学習ディープラーニング">2-4.📘深層学習（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>）</h3>

<ul>
<li><p><strong>単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a></strong></p>

<ul>
<li>シンプルな<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>。</li>
<li><strong>ステップ関数</strong>で表現できるが<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>では利用できない。
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/1920px-Dirac_distribution_CDF.svg.png" alt="" /><br />
<a href="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/1920px-Dirac_distribution_CDF.svg.png">https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/1920px-Dirac_distribution_CDF.svg.png</a></li>
</ul>
</li>
<li><p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a></strong></p>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>を多層にしたもの。</li>
</ul>
</li>
<li><p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%AF%A5%D7%A5%ED%A5%D1%A5%B2%A1%BC%A5%B7%A5%E7%A5%F3">バックプロパゲーション</a></strong></p>

<ul>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>学習法</strong></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の学習における<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>。</li>
</ul>
</li>
<li><p><strong>自己符号化器（オートエンコーダ）</strong></p>

<ul>
<li>入力したものと同じものを出力して学習する。</li>
</ul>
</li>
</ul>


<h4 id="-SuperVision">✅ 💻SuperVision</h4>

<ul>
<li>2012年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C8%A5%ED%A5%F3%A5%C8%C2%E7%B3%D8">トロント大学</a>、🎩<strong>ジェフリー・ヒントン</strong>。</li>
<li>ILSVRC（Imagenet Large Scale Visual Recognition Challenge）2012 で勝利した。</li>
<li>エラー率は26%台から15.3%へ劇的に改善。</li>
<li>その後、2015年に人間の認識率（約5.1%）を抜いた。</li>
<li><strong>AlexNet</strong>（畳み込み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>、CNN）を採用。</li>
<li>前年度までは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B5%A5%DD%A1%BC%A5%C8%A5%D9%A5%AF%A5%BF%A1%BC%A5%DE%A5%B7%A5%F3">サポートベクターマシン</a>が主流だったが、ここからCNNに切り替わったことになる。</li>
</ul>


<h2 id="３人工知能分野の問題">３．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>分野の問題</h2>

<h3 id="3-1トイプロブレムおもちゃの問題">3-1.📘トイプロブレム（おもちゃの問題）</h3>

<ul>
<li>ルールが決まっている問題（迷路、オセロなど）は解けても、現実世界に存在する複雑な問題は解けないという問題。</li>
</ul>


<h3 id="3-2フレーム問題">3-2.📘フレーム問題</h3>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E5%95%8F%E9%A1%8C">Wikipedia</a></li>
<li>1969年、🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A5%E7%A5%F3%A1%A6%A5%DE%A5%C3%A5%AB%A1%BC%A5%B7%A1%BC">ジョン・マッカーシー</a></strong>と🎩<strong>パトリック・ヘイズ</strong>が提唱。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>における重要な難問の一つ。</li>
<li>有限の情報処理能力しかないロボットには、現実に起こりうる問題全てに対処することができない。</li>
<li>🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C0%A5%CB%A5%A8%A5%EB%A1%A6%A5%C7%A5%CD%A5%C3%A5%C8">ダニエル・デネット</a></strong>：<br />
考えすぎて何も解決できないロボットを例示し、フレーム問題の難しさを伝えた。</li>
</ul>


<h3 id="3-3強いAI弱いAI">3-3.📘強いAI・弱いAI</h3>

<ul>
<li>🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A5%E7%A5%F3%A1%A6%A5%B5%A1%BC%A5%EB">ジョン・サール</a></strong>が提唱。</li>
<li><strong>強いAI</strong>：<br />
人間のような心、自意識を持つAI。</li>
<li><strong>弱いAI</strong>：<br />
便利な道具であればよいという考え方によるAI。</li>
</ul>


<h4 id="-汎用AI特化型AI">✅ 汎用AI、特化型AI</h4>

<ul>
<li><strong>汎用AI</strong>：<br />
フレーム問題を打ち破るAIのことで、人間のように様々な課題に対処することができる。</li>
<li><strong>特化型AI</strong>：<br />
フレーム問題を打ち破っていないAIのこと。</li>
</ul>


<h4 id="-中国語の部屋">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%E6%B9%F1%B8%EC%A4%CE%C9%F4%B2%B0">中国語の部屋</a></h4>

<ul>
<li>🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A5%E7%A5%F3%A1%A6%A5%B5%A1%BC%A5%EB">ジョン・サール</a></strong>が論文で発表した。</li>
<li>強いAIは実現不可能だという思考実験。</li>
</ul>


<blockquote><p>中国語を理解できない人を小部屋に閉じ込めて、マニュアルに従った作業をさせるという内容。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0">チューリング</a>・テストを発展させた思考実験で、意識の問題を考えるのに使われる。（<a href="https://ja.wikipedia.org/wiki/%E4%B8%AD%E5%9B%BD%E8%AA%9E%E3%81%AE%E9%83%A8%E5%B1%8B">引用</a>）</p></blockquote>

<h4 id="-ロジャーペンローズ">✅ 🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%ED%A5%B8%A5%E3%A1%BC%A1%A6%A5%DA%A5%F3%A5%ED%A1%BC%A5%BA">ロジャー・ペンローズ</a></h4>

<ul>
<li>イギリス生まれの数学者、宇宙物理学・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CD%FD%CF%C0%CA%AA%CD%FD%B3%D8">理論物理学</a>者。</li>
<li>「量子効果が絡んでいるため強いAIは実現できない」と主張した。</li>
</ul>


<h3 id="3-4身体性">3-4.📘身体性</h3>

<ul>
<li>知能の成立には身体が不可欠であるという考え方。</li>
<li>物理的な身体により外部環境との相互作用を行うことができる。</li>
<li>しかし、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>や<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a>の研究スピードでは、身体性の研究をすっ飛ばして概念獲得や意味理解ができてしまう可能性もある。</li>
</ul>


<h3 id="3-5シンボルグラウンディング問題">3-5.📘シンボル<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B0%A5%E9%A5%A6%A5%F3%A5%C7%A5%A3%A5%F3%A5%B0">グラウンディング</a>問題</h3>

<ul>
<li>🎩ス<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%A3%A1%BC">ティー</a>ブン・ハルナッド。</li>
<li>記号（シンボル）と現実世界の意味はどのようにして結びつけられるのかという問題。</li>
<li>外部世界を内部化（記号化、シンボル化）した時点で、外界との設置（クラウディング）が切れてしまうという問題。</li>
</ul>


<h4 id="-知識獲得のボトルネック">✅ 知識獲得の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DC%A5%C8%A5%EB%A5%CD%A5%C3%A5%AF">ボトルネック</a></h4>

<ul>
<li>人間が持っている知識は膨大であり、それらを獲得することは困難である。</li>
<li>特に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%AD%A5%B9%A5%D1%A1%BC%A5%C8%A5%B7%A5%B9%A5%C6%A5%E0">エキスパートシステム</a>の開発において問題となった。</li>
</ul>


<h4 id="-ニューラル機械翻訳">✅ ニューラル<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></h4>

<ul>
<li>NMT、Neural Machine Translation</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>を利用した<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>。</li>
<li>日本語の翻訳品質を飛躍的に高めた。</li>
<li>従来の方式には<strong>ルールベース<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/RMT">RMT</a>）</strong>、<strong>統計的<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>（SMT）</strong>がある。</li>
</ul>


<blockquote><p>「ルールベース<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/RMT">RMT</a>：Rule Based Machine Translation）」は、登録済みのルールを適応することで原文を分析し、訳文を出力する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>の方法です。<br />
「統計的<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a>（SMT：Statistical Base Machine Translation）」は、コンピュータに学習用の対訳データを与え、統計モデルを学習させることで訳文を出力させる方法です。（<a href="https://to-in.com/blog/2504#:~:text=%E3%83%AB%E3%83%BC%E3%83%AB%E3%83%99%E3%83%BC%E3%82%B9%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%EF%BC%88RMT%EF%BC%89,%E6%96%87%E6%B3%95%E3%80%8D%E3%81%AB%E7%BD%AE%E3%81%8D%E6%8F%9B%E3%81%88%E3%82%89%E3%82%8C%E3%81%BE%E3%81%99%E3%80%82">引用</a>）</p></blockquote>

<h5 id="-seq2seq">✓ <strong>seq2seq</strong>：</h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C6%B5%A2">再帰</a>型<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>（RNN）を使った文の生成モデル。</li>
<li>時系列データを入力し、時系列データを出力する。</li>
<li>別の言語に置き換えたり（翻訳）、質問を回答に置き換えたり（質問・回答）できる。</li>
</ul>


<h3 id="3-6特徴量設計">3-6.📘特徴量設計</h3>

<ul>
<li>モデルの性能は、注目すべきデータの特徴（<strong>特徴量</strong>）の選び方により決定づけられるが、それを人間が見つけ出すのは難しい。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>自身に発見させるアプローチを<strong>特徴表現学習</strong>という。</li>
</ul>


<h3 id="3-7チューリングテスト">3-7.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0%A5%C6%A5%B9%A5%C8">チューリングテスト</a></h3>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%83%BB%E3%83%86%E3%82%B9%E3%83%88">Ｗikipedia</a></li>
<li>🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%E9%A5%F3%A1%A6%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0">アラン・チューリング</a></strong>により考案された。</li>
<li>ある機械が知的かどうか（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>であるかどうか）を判定するためのテスト。</li>
</ul>


<h4 id="-ローブナーコンテスト">✅ ローブナーコンテスト</h4>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%BC%E3%83%96%E3%83%8A%E3%83%BC%E8%B3%9E">Wikipedia（ローブナー賞）</a></li>
<li><a href="https://aisb.org.uk/aisb-events/">Official Page</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0%A5%C6%A5%B9%A5%C8">チューリングテスト</a>の合格を目指すコンテスト。</li>
</ul>


<h3 id="3-8シンギュラリティ技術的特異点">3-8.📘シンギュラリティ（技術的<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%C3%B0%DB%C5%C0">特異点</a>）</h3>

<ul>
<li>🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%EC%A5%A4%A1%A6%A5%AB%A1%BC%A5%C4%A5%EF%A5%A4%A5%EB">レイ・カーツワイル</a>の著書で提唱された。

<ul>
<li>2029年：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>が人間よりも賢くなる</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/2045%C7%AF">2045年</a>：シンギュラリティの到来（<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/2045%C7%AF">2045年</a>問題</strong>ともいわれる）</li>
</ul>
</li>
<li>「収穫加速の法則」により「強いAI」が実現され、人間には予測不可能な変化が起こるとされている。</li>
</ul>


<h5 id="-収穫加速の法則">✓ 収穫加速の法則</h5>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E5%8F%8E%E7%A9%AB%E5%8A%A0%E9%80%9F%E3%81%AE%E6%B3%95%E5%89%87">Wikipedia</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%EC%A5%A4%A1%A6%A5%AB%A1%BC%A5%C4%A5%EF%A5%A4%A5%EB">レイ・カーツワイル</a>が提唱した経験則。</li>
<li>一つの重要な発明が他の発明と結び付くことで、次の重要な発明の登場までの期間を短縮する。これにより<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%CE%A5%D9%A1%BC%A5%B7%A5%E7%A5%F3">イノベーション</a>の速度が加速され、科学技術は直線的ではなく指数関数的に進歩するというもの。</li>
</ul>


<h5 id="-シンギュラリティに関する発言等">✓ シンギュラリティに関する発言等</h5>

<table>
<thead>
<tr>
<th> 氏名                     </th>
<th> 発言等                                               </th>
</tr>
</thead>
<tbody>
<tr>
<td> 🎩<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%EC%A5%A4%A1%A6%A5%AB%A1%BC%A5%C4%A5%EF%A5%A4%A5%EB">レイ・カーツワイル</a></strong>   </td>
<td> 「シンギュラリティは<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/2045%C7%AF">2045年</a></strong>に到来する」           </td>
</tr>
<tr>
<td> 🎩ヒューゴ・デ・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AC%A5%EA">ガリ</a>ス     </td>
<td> 「シンギュラリティは21世紀の後半に来る」             </td>
</tr>
<tr>
<td> 🎩オレン・エツィオーニ     </td>
<td> 「シンギュラリティの終末論的構想は<strong>馬鹿げている</strong>」 </td>
</tr>
<tr>
<td> 🎩ヴィーナー・ヴィンジ     </td>
<td> 「機械が人間の役に立つふりをしなくなること」         </td>
</tr>
<tr>
<td> 🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%C6%A5%A3%A1%BC%A5%D6%A5%F3%A1%A6%A5%DB%A1%BC%A5%AD%A5%F3%A5%B0">スティーブン・ホーキング</a> </td>
<td> 「AIの完成は<strong>人類の終焉</strong>を意味するかもしれない」   </td>
</tr>
<tr>
<td> 🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A1%BC%A5%ED%A5%F3%A1%A6%A5%DE%A5%B9%A5%AF">イーロン・マスク</a>         </td>
<td> 危機感を持ち非営利のAI研究組織 <strong>OpenAI</strong> を設立。<br>OpenAI Gym（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>のシミュレーション環境）を発表。   </td>
</tr>
</tbody>
</table>


<h2 id="４機械学習の具体的手法">４．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>の具体的手法</h2>

<h3 id="4-1代表的な手法">4-1.📘代表的な手法</h3>

<h4 id="-教師あり学習">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a></h4>

<h5 id="-回帰問題">✓ 回帰問題</h5>

<ul>
<li>線形回帰：

<ul>
<li>linear regression</li>
<li><a href="https://ja.wikipedia.org/wiki/%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0">Wikipedia</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%FD%B7%D7%B3%D8">統計学</a>における回帰分析の一種。</li>
<li>特徴：<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を起こしやすい。</li>
</ul>
</li>
<li>ラッソ回帰：

<ul>
<li>lasso regression</li>
<li><a href="https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%83%E3%82%BD%E5%9B%9E%E5%B8%B0">Wikipedia</a></li>
<li>直線回帰に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項の概念を加えた回帰分析。</li>
<li>最小二乗法の式に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項（<strong>L1ノルム</strong>）を加え、その最小を求めることでモデル関数を発見する。</li>
<li>Lasso：自動的に特徴量の選択が行われる。不要なパラメータを削減できる。</li>
</ul>
</li>
<li>リッジ回帰：

<ul>
<li>ridge regression</li>
<li>直線回帰に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項の概念を加えた回帰分析。</li>
<li>最小二乗法の式に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項（<strong>L2ノルム</strong>）を加え、その最小を求めることでモデル関数を発見する。</li>
<li>Ridge<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>：特徴量選択は行わないが、パラメータのノルムを小さくおさえる。（＝<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>をおさえる）</li>
</ul>
</li>
<li>参考

<ul>
<li>ノルム ： いろいろなものの「大きさ」を表す。</li>
<li><a href="https://qiita.com/nanairoGlasses/items/57515340a1bc24ffe445#%E3%83%A9%E3%83%83%E3%82%BD%E5%9B%9E%E5%B8%B0%E3%81%A8%E3%81%AF">Qiita-【機械学習】ラッソ回帰・リッジ回帰について　メモ</a></li>
</ul>
</li>
</ul>


<h5 id="-単回帰分析重回帰分析">✓ 単回帰分析・重回帰分析</h5>

<ul>
<li><strong>単回帰分析</strong>：<br />
ひとつの説明変数により、ひとつの目的変数を予測するもの。</li>
<li><strong>重回帰分析</strong>：<br />
複数の説明変数から、ひとつの目的変数を予測するもの。</li>
</ul>


<h5 id="-重回帰分析の注意事項">✓ 重回帰分析の注意事項</h5>

<ul>
<li><strong>多重共線性</strong>：<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%EA%B4%D8%B7%B8%BF%F4">相関係数</a>の絶対値が最大値に近くなる特徴量のペアを同時に説明変数に選ぶと、予測の精度が悪化する。</li>
<li>参考

<ul>
<li><a href="https://xica.net/vno4ul5p/">多重共線性とは？ 〜 概要と対応方法 〜</a></li>
</ul>
</li>
</ul>


<h5 id="-分類問題">✓ 分類問題</h5>

<ul>
<li><strong>ロジスティック回帰</strong>

<ul>
<li>logistic regression</li>
<li>重回帰分析により<strong>対数オッズ</strong>を予測し、<strong>ロジット変換（正規化）</strong>によりクラスに属する確率を求める。</li>
<li>最小化を行う関数として<strong>尤度関数（ゆうどかんすう）</strong>が用いられる。</li>
<li>用語　：　正例、負例、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>　：　２分類で利用</li>
<li>ソフトマックス関数　：　複数分類時に使用</li>
</ul>
</li>
<li><strong>ランダムフォレスト</strong>

<ul>
<li>random forest</li>
<li><strong>ブートストラッ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D7%A5%B5%A5%F3">プサン</a>プリング</strong>により、<strong>アンサンブル学習</strong>を行う。</li>
<li><strong>バギング</strong>に該当する。</li>
</ul>
</li>
<li><strong>バギング</strong>

<ul>
<li>データ全体からランダムに一部データを用いて、複数のモデルを作る（学習する）方法。並列処理になる。</li>
</ul>
</li>
<li><strong>ブースティング（boosting）</strong>

<ul>
<li>一部のデータを繰り返し抽出し、複数のモデルを学習させる。</li>
<li><strong>逐次処理</strong>のため、ランダムフォレストより時間がかかる。</li>
<li>AdaBoost、勾配ブースティング、XgBoost</li>
</ul>
</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B5%A5%DD%A1%BC%A5%C8%A5%D9%A5%AF%A5%BF%A1%BC%A5%DE%A5%B7%A5%F3">サポートベクターマシン</a></strong>

<ul>
<li>コンセプトは<strong>マージン</strong>の最大化を行うこと。</li>
<li><strong>スラック変数</strong>

<ul>
<li>誤分類を許容する工夫をする、線形分離不可能なデータのマージンを最大化する。</li>
</ul>
</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%CB%A1">カーネル法</a></strong>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB">カーネル</a>関数により高次元への<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>を行い線形分離可能にする。</li>
</ul>
</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%A5%C8%A5%EA%A5%C3%A5%AF">カーネルトリック</a></strong>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%CC%C1%FC">写像</a>の際に計算が複雑にならないように式変形するテクニック。計算量を大幅に削減する。</li>
</ul>
</li>
</ul>
</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a></strong>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%ED%A5%F3">ニューロン</a>、神経回路</li>
<li>単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>、多層<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a></li>
<li>入力層、出力層、重み、隠れ層</li>
<li>活性化関数、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>法</li>
<li>ロジスティック回帰は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の一種（単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>と数式が同じ）。</li>
</ul>
</li>
</ul>


<p>★ＴＯＤＯ：詳細化★</p>

<h4 id="-教師なし学習">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a></h4>

<h5 id="-k-means法">✓ <strong>k-means法</strong></h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF%A5%EA%A5%F3%A5%B0">クラスタリング</a>の手法。</li>
<li><strong>kNN法</strong>はクラス分類（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a>）の手法なので注意！</li>
</ul>


<h5 id="-主成分分析PCA">✓ <strong>主成分分析（PCA）</strong></h5>

<ul>
<li><strong>次元削減</strong>の手法のひとつ。</li>
<li>寄与率：各成分の重要度がわかる。</li>
<li>主成分：各成分の意味を推測できる。</li>
</ul>


<h4 id="-強化学習">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a></h4>

<ul>
<li>エージェントの目的は<strong>収益（報酬・累積報酬）</strong>を最大化する<strong>方策</strong>を獲得すること。</li>
<li>エージェントが<strong>行動</strong>を選択することで<strong>状態</strong>が変化し、最良の行動を選択する行為を繰り返す。</li>
</ul>


<h3 id="4-2データの扱い">4-2.📘データの扱い</h3>

<ul>
<li>訓練データ、テストデータ</li>
<li>訓練データ、検証データ、テストデータ・・・検証データで一度パラメータを更新し、テストデータで再評価。</li>
<li>交差検証</li>
<li>ホールドアウト検証：たとえば7対3でデータを分ける</li>
<li>k-分割交差検証：テストデータを順次入れ替える</li>
</ul>


<h4 id="-欠損値処理">✅ 欠損値処理</h4>

<h5 id="-リストワイズ法">✓ リストワイズ法</h5>

<ul>
<li>欠損があるサンプルをそのまま削除する方法。</li>
<li>欠損に偏りがある場合はデータの傾向を変えてしまうので注意が必要。</li>
</ul>


<h5 id="-回帰補完">✓ 回帰補完</h5>

<ul>
<li>欠損しているある特徴量と相関が強い他の特徴量が存在している場合に有効。</li>
</ul>


<h4 id="-カテゴリデータ">✅ カテゴリデータ</h4>

<h5 id="-マッピング">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%C3%A5%D4%A5%F3%A5%B0">マッピング</a></h5>

<p>順序を持つデータの場合、数値の辞書型データに<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%C3%A5%D4%A5%F3%A5%B0">マッピング</a>する。</p>

<h5 id="-ワンホットエンコーディング">✓ ワンホット<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%B3%A1%BC%A5%C7%A5%A3%A5%F3%A5%B0">エンコーディング</a></h5>

<p>順序を持たないデータの場合、各カテゴリごとにダミー変数を割り当てる。</p>

<h3 id="4-3応用評価指標">4-3.📘応用・評価指標</h3>

<h4 id="-混同行列">✅ 混同行列</h4>

<ul>
<li><strong>正解率</strong>（全体の精度を上げたい場合）</li>
<li><strong>適合率</strong>（<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%B6%CD%DB%C0%AD">偽陽性</a></strong>を削減したい場合）</li>
<li><strong>再現率</strong>（<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%B6%B1%A2%C0%AD">偽陰性</a></strong>を削減したい場合）</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/F%C3%CD">F値</a></strong>（適合率と再現率の調和平均）</li>
</ul>


<h4 id="-オーバーフィッティングアンダーフィッティング">✅ オーバーフィッティング、アンダーフィッティング</h4>

<h4 id="-正則化">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a></h4>

<ul>
<li>訓練誤差ではなく、汎化誤差を小さくするための手法。オーバーフィッティグを防止する。</li>
<li>L1<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>：ラッソ回帰、一部パラメータをゼロにする（スパースする）。</li>
<li>L2<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>：リッジ回帰、パラメータの大きさに応じてゼロに近づける、パラメータのノルムにペナルティを課す。</li>
<li>上記組合せ：Elastic Net</li>
</ul>


<h2 id="５ディープラーニングの概要">５．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の概要</h2>

<h3 id="5-1ニューラルネットワークとディープラーニング">5-1.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a></h3>

<h4 id="-単純パーセプトロン">✅ 単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a></h4>

<ul>
<li>線形分類しかできない。</li>
</ul>


<h4 id="-多層パーセプトロン">✅ 多層<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a></h4>

<ul>
<li>多層化することで、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>分類が出来るようになった。</li>
</ul>


<h4 id="-ディープラーニング">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a></h4>

<ul>
<li>概念としては1960年代には既に存在していた。</li>
<li>特徴

<ul>
<li>ディープ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>を用いたもので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%ED%A5%F3">ニューロン</a>をいくつもつなげている。</li>
<li>複雑な関数を近似できる。</li>
</ul>
</li>
<li>検証方法

<ul>
<li>通常はデータ量が多いため、ホールドアウト検証でよい（十分である）。</li>
</ul>
</li>
<li>問題

<ul>
<li>オーバーフィッティング（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>）しやすい。（但し、精度に特別バラつきが出やすいというわけではない。）</li>
<li>勾配消失問題を起こしやすい。</li>
<li>事前に調整すべきパラメータ数が非常に多い。</li>
</ul>
</li>
</ul>


<h4 id="-用語">✅ 用語</h4>

<ul>
<li>バッチサイズ

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>で用いるデー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>のサンプル数。</li>
</ul>
</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>

<ul>
<li>重みの更新を行っう回数。</li>
<li>デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>に含まれるデータが少なくとも１回は実行されるようにする学習回数。</li>
<li>デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>とバッチサイズが決まれば、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>は自動的に決まる。</li>
</ul>
</li>
<li>エポック

<ul>
<li>訓練データを学習に用いた回数。</li>
<li>デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>のバッチサイズ分割から<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>実行までの処理を繰り返す回数のこと。</li>
</ul>
</li>
<li>参考

<ul>
<li> <a href="https://qiita.com/kenta1984/items/bad75a37d552510e4682">&#x6A5F;&#x68B0;&#x5B66;&#x7FD2;&#xFF0F;&#x30C7;&#x30A3;&#x30FC;&#x30D7;&#x30E9;&#x30FC;&#x30CB;&#x30F3;&#x30B0;&#x306B;&#x304A;&#x3051;&#x308B;&#x30D0;&#x30C3;&#x30C1;&#x30B5;&#x30A4;&#x30BA;&#x3001;&#x30A4;&#x30C6;&#x30EC;&#x30FC;&#x30B7;&#x30E7;&#x30F3;&#x6570;&#x3001;&#x30A8;&#x30DD;&#x30C3;&#x30AF;&#x6570;&#x306E;&#x6C7A;&#x3081;&#x65B9; - Qiita</a></li>
</ul>
</li>
</ul>


<h3 id="5-2既存のニューラルネットワークにおける問題">5-2.📘既存の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>における問題</h3>

<ul>
<li>課題

<ul>
<li>隠れ層を増やすと誤差（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>）が最後まで正しく反映されない。（＝入力層付近で学習が進まなくなる）</li>
</ul>
</li>
<li>理由

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%B3%B4%D8%BF%F4">導関数</a>の最大値が0.25のため、伝播させる誤差がどんどん小さくなってしまう。（<strong>勾配消失問題</strong>）<br />
→ 対策が必要！</li>
</ul>
</li>
</ul>


<h3 id="5-3ディープラーニングのアプローチ">5-3.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>のアプローチ</h3>

<h4 id="-オートエンコーダautoencoder自己符号化器">✅ オートエンコーダ（autoencoder、自己符号化器）</h4>

<ul>
<li>🎩<strong>ジェフリー・ヒントン</strong>が提唱。</li>
<li>入力と出力が同じになる<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>。（＝正解ラベルが入力と同じ）</li>
<li>次元削減が行える。</li>
</ul>


<h4 id="-積層オートエンコーダ">✅ 積層オートエンコーダ</h4>

<ul>
<li>オートエンコーダを積み重ねて、逐次的に学習させる（<strong>事前学習</strong>）ことで重みを調整する</li>
</ul>


<h4 id="-ファインチューニング">✅ ファインチューニング</h4>

<ul>
<li>積層オートエンコーダにロジスティック回帰層（あるいは線形回帰層）を追加し、仕上げの学習を行う。</li>
</ul>


<h4 id="-深層信念ネットワーク参考">✅ 深層信念ネットワーク（<a href="https://www.kyoritsu-pub.co.jp/ai/pdf/7-9deeplearning.pdf">参考</a>）</h4>

<ul>
<li>🎩ジェフリー・ヒントンが提唱。</li>
<li><strong>確定的モデル</strong>に分類される。（深層ボルツマンマシンは<strong>確率的モデル</strong>に分類される）</li>
<li>隠れ層の数が多い<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>で、効率の良い近似学習手法を提案した。</li>
<li>具体的には、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%CA%A4%B7%B3%D8%BD%AC">教師なし学習</a>による事前学習（制限付きボルツマンマシン）により効率的な学習を実現。</li>
<li>※ボルツマンマシン（<a href="http://www.sist.ac.jp/~kanakubo/research/neuro/boltzmannmachine.html">参考</a>）<br />
ヒントンらによって開発された、確率的に動作する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>。ネットワークの動作に温度の概念を取り入れ、最初は激しく徐々に穏やかに動作する（擬似<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BE%C6%A4%AD%A4%CA%A4%DE%A4%B7%CB%A1">焼きなまし法</a>）ように工夫している。</li>
</ul>


<h4 id="-現状">✅ 現状</h4>

<ul>
<li>事前学習は計算コストが非常に高いので今は使われておらず、活性化関数を工夫することで解決している。</li>
</ul>


<h3 id="5-4CPU-と-GPU">5-4.📘CPU と <a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a></h3>

<h4 id="-CPU">✅ CPU</h4>

<ul>
<li>Central Processing Unit、中央演算処理装置</li>
</ul>


<h4 id="-GPU">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a></h4>

<ul>
<li>Graphics Processing Unit</li>
<li>リアルタイム画像処理に特化した演算装置。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/GPGPU">GPGPU</a>

<ul>
<li>General-Purpose computing on <a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a>。</li>
<li>画像以外の目的に最適化された<a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a>。</li>
</ul>
</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/NVIDIA">NVIDIA</a>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a>の開発をリード。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>には不可欠。</li>
</ul>
</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>

<ul>
<li>TPU（<a class="keyword" href="http://d.hatena.ne.jp/keyword/Tensor">Tensor</a> Processing Unit）、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%F3%A5%BD%A5%EB">テンソル</a>計算に最適化されたもの。</li>
<li>分散並列技術であるDistBeliefも<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>により提案されたものである。</li>
</ul>
</li>
</ul>


<h3 id="5-5ディープラーニングにおけるデータ量">5-5.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>におけるデータ量</h3>

<h4 id="-バーニーおじさんのルール">✅ バーニーおじさんのルール</h4>

<p>モデルのパラメータ数の10倍のデータ数が必要。</p>

<h4 id="-次元の呪い">✅ 次元の呪い</h4>

<p>データの次元が増えることにより、様々な不都合が生じる法則のこと。</p>

<h4 id="-その他の機械学習に関する定理">✅ その他の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>に関する定理</h4>

<ul>
<li><p>ノーフリーランチ定理<br />
あらゆる問題に対して万能な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>は存在しない。</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A4%DF%A4%CB%A4%AF%A4%A4%A5%A2%A5%D2%A5%EB%A4%CE%BB%D2">みにくいアヒルの子</a>定理<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>で、「普通のア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%EB">ヒル</a>」と「みにくいア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%EB">ヒル</a>」を見分けることはできない。<br />
認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している、つまり特徴を選択しなければ表現の類似度に基づく分類は不可能である、ということ。</p></li>
<li><p>モラベックの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A5%E9%A5%C9%A5%C3%A5%AF%A5%B9">パラドックス</a><br />
機械にとっては、高度な推論より１歳児レベルの知能・運動スキルを身に着ける方が難しい。</p></li>
</ul>


<h3 id="ディープラーニングのフレームワーク"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%EC%A1%BC%A5%E0%A5%EF%A1%BC%A5%AF">フレームワーク</a></h3>

<table>
<thead>
<tr>
<th><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%EC%A1%BC%A5%E0%A5%EF%A1%BC%A5%AF">フレームワーク</a>名</th>
<th>概要</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tensorflow</td>
<td><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>社が開発。<br>プログラムによりネットワークを記述する。<br>※設定ファイルによりネットワークを記述　：　Caffe, CNTK</td>
</tr>
<tr>
<td>Keras</td>
<td><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>社が開発。<br>プログラムによりネットワークを記述する。<br>※設定ファイルによりネットワークを記述　：　Caffe, CNTK</td>
</tr>
<tr>
<td>Chainer</td>
<td>Preferred Networks が開発。<br>Define-by-Runという形式を採用しており、<br>データを流しながら<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>を構築する。<br>※構築後の実行はDefine-and-Runといわれる。<br>※プログラムによりネットワークを記述する。<br>2019年12月、<strong>開発を終了しPyTorchに移行</strong>すると発表。</td>
</tr>
<tr>
<td>PyTorch</td>
<td><a href="https://ja.wikipedia.org/wiki/PyTorch">Wikipedia</a><br>Chainerから派生。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a>が開発。</td>
</tr>
</tbody>
</table>


<h3 id="ヨシュアベンジオ">🎩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E8%A5%B7%A5%E5%A5%A2">ヨシュア</a>・ベンジオ</h3>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の父のひとりといわれる。</li>
<li>人間の知識では気づくことが出来ない共通点のことを「良い表現」としている。

<ul>
<li>複数の説明変数の存在</li>
<li>時間的空間的一貫性</li>
<li>スパース性</li>
</ul>
</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>のアプローチとして以下に着目している。

<ul>
<li>説明変数の階層的構造</li>
<li>タスク間の共通要因</li>
<li>要因の依存の単純性</li>
</ul>
</li>
</ul>


<h2 id="６ディープラーニングの手法">６．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の手法</h2>

<h3 id="6-1活性化関数">6-1.📘活性化関数</h3>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>以外にもいろいろある。</li>
<li>出力層は<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a></strong>または<strong>ソフトマックス関数</strong>で確率を表現する必要がある（制約事項）、しかし隠れ層は工夫ができる。</li>
<li><strong>ソフトマックス関数</strong>：各ユニットの出力の総和を１に正規化する機能がある</li>
</ul>


<h4 id="-tanh関数ハイパボリックタンジェント関数双曲線正接関数">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/tanh">tanh</a>関数（ハイパボリック<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%F3%A5%B8%A5%A7%A5%F3%A5%C8">タンジェント</a>関数）：双曲線<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C0%DC">正接</a>関数</h4>

<ul>
<li>シグモイドの値の範囲は0～1だが、この関数は-1～1である。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>のMAX値について、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>の 0.25 に対し、この関数は 1 になるため<strong>勾配が消失しづらい</strong>。</li>
</ul>


<h4 id="-ReLU関数Rectified-Linear-Unit正規化線形関数">✅ ReLU関数（Rectified Linear Unit）：正規化線形関数</h4>

<ul>
<li>特徴

<ul>
<li>現在、最もよく使われている。</li>
<li>xが1より大きい場合、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値が1になるため、<strong>勾配消失しにくい</strong>。</li>
<li>xが0以下の場合は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値が0になるため、学習がうまくいかない場合もある。</li>
</ul>
</li>
<li>派生

<ul>
<li>Leaky ReLU関数 0以下でもわずかな傾きを持たせることで<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値を0にしない。</li>
<li>Parametric ReLU 、 Randomized ReLU などもある</li>
<li>どれが一番よいと一概には言えない。</li>
</ul>
</li>
</ul>


<h4 id="-過学習">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a></h4>

<ul>
<li>訓練誤差は小さいが、汎化誤差が大きい状態。</li>
</ul>


<h3 id="6-2学習率の最適化">6-2.📘学習率の最適化</h3>

<ul>
<li><strong>損失関数</strong>を最小にすることが目標。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%D0%C8%F9%CA%AC">偏微分</a>）により最小を求めたいが、多次元なので難しい。（計算量が多くなってしまう）</li>
</ul>


<h4 id="-勾配降下法">✅ 勾配降下法</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>値（傾き）を下っていくことで最適化する。パラメータごとに行う。</li>
<li>ハイパーパラメータ

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C6%A5%EC%A1%BC%A5%B7%A5%E7%A5%F3">イテレーション</a>：繰り返し計算の数</li>
<li>学習率：ハイパーパラメータ、勾配に沿って一度にどれくらい下るか</li>
</ul>
</li>
<li>具体例

<ul>
<li>バッチ勾配降下法</li>
<li>ミニバッチ勾配降下法：学習データから複数（バッチサイズ）を選択し誤差を計算＆パラメータ更新</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B3%CE%CE%A8%C5%AA%B8%FB%C7%DB%B9%DF%B2%BC%CB%A1">確率的勾配降下法</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/SGD">SGD</a>）：学習データから１つを選択し誤差を計算＆パラメータ更新</li>
</ul>
</li>
</ul>


<h4 id="-勾配降下法の問題と改善">✅ 勾配降下法の問題と改善</h4>

<ul>
<li><strong>局所最適解</strong>にはまり、<strong>大域最適解</strong>が求められない場合がある。</li>
<li>学習率の値を大きくすることで抜け出せるが、適宜値を小さくしていく必要がある。</li>
<li>２次元の場合は<strong>停留点</strong>、３次元の場合は<strong>鞍点（あんてん）</strong>にはまることもある。</li>
<li>はまった状態を<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D7%A5%E9%A5%C8%A1%BC">プラトー</a></strong>という。次元が高いほど発生しやすい。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D7%A5%E9%A5%C8%A1%BC">プラトー</a>を抜け出す方法として<strong>モーメンタム、AdaGrad、Adadelta、RMSprop、Adam</strong>などがある。<br />
現在は<strong>RMSprop、Adam</strong>が利用される。（<a href="https://postd.cc/optimizing-gradient-descent/">参考</a>）</li>
</ul>


<h5 id="-モーメンタムMomentum慣性">✓ モーメンタム（Momentum、慣性）</h5>

<ul>
<li>以前に適用した勾配の方向を、現在のパラメータ更新にも影響させる。（慣性を効かせる）</li>
</ul>


<h5 id="-AdaGrad">✓ AdaGrad</h5>

<ul>
<li>学習率をパラメータに適応させることで自動的に学習率を調整する。</li>
<li>稀なパラメータに対しては大きな更新、頻繁なパラメータに対しては小さな更新を行う。</li>
<li>具体的には、勾配を二乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量（学習率）を小さくする。</li>
<li>課題　：　更新量が飽和したパラメータは更新されなくなる。</li>
</ul>


<h5 id="-Adadelta">✓ Adadelta</h5>

<ul>
<li>AdaGradの発展形</li>
<li>急速かつ単調な学習率の低下防止をはかったモデル。</li>
</ul>


<h5 id="-RMSprop">✓ RMSprop</h5>

<ul>
<li>AdaGradの発展形</li>
<li>急速かつ単調な学習率の低下防止をはかったモデル。</li>
<li>Adadeltaと同時期に提唱された、ほぼ同様の内容。</li>
<li>指数<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%DC%C6%B0%CA%BF%B6%D1">移動平均</a>を蓄積することにより解決をはかったモデル。</li>
</ul>


<h5 id="-Adam">✓ Adam</h5>

<ul>
<li>それぞれのパラメータに対し学習率を計算し適応させるモデル。</li>
<li>勾配の平均と分散をオンラインで推定した値を利用する。</li>
</ul>


<h3 id="6-3更なるテクニック">6-3.📘更なるテクニック</h3>

<p>更に精度を高めるためのテクニックがある。</p>

<h4 id="-ドロップアウト">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%ED%A5%C3%A5%D7%A5%A2%A5%A6%A5%C8">ドロップアウト</a></h4>

<ul>
<li>ランダムに<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%ED%A5%F3">ニューロン</a>を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%ED%A5%C3%A5%D7%A5%A2%A5%A6%A5%C8">ドロップアウト</a>させることで、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>のオーバーフィッティング対策を行う。</li>
<li>これにより、アンサンブル学習を行っているのと同じような状況になる。</li>
</ul>


<h4 id="-early-stopping">✅ early stopping</h4>

<ul>
<li>学習を早めに打ち切ることで、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>のオーバーフィッティング対策を行う。</li>
<li>どんな手法でも使えるため、非常に強力である。</li>
</ul>


<h4 id="-データの正規化重みの初期化">✅ データの正規化・重みの初期化</h4>

<h5 id="-データの正規化">✓ データの正規化</h5>

<p>データの途中処理ではなく、始めの工夫も必要かつ有効である。</p>

<ul>
<li><p>正規化（Normalization、≒Scaling）<br />
スケールを合わせることで、学習時の収束を早める。<br />
一番簡単なのは各特徴量を ０～１ の範囲に変換すること。（LASSOなど）</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>（Regularization）<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>の回避を目的とする。<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>項を追加することで、値の偏りを防止する。</p></li>
<li><p>標準化<br />
標準<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%D1%CA%AC">積分</a>布（平均０、分散１）にする。</p></li>
<li><p>白色化<br />
各特徴量を無相関化したうえで標準化する、計算コストが高い</p></li>
<li><p>局所<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%F3%A5%C8%A5%E9">コントラ</a>スト正規化<br />
減算正規化と除算正規化の処理を行う。画像処理で利用される。</p></li>
</ul>


<h5 id="-重みの初期化">✓ 重みの初期化</h5>

<ul>
<li>ディープ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>では伝播を経て分布が崩れるため、上記手法が有効に働かない場合がある。</li>
<li>重みの初期値を工夫することで解決をはかることができる。</li>
<li>乱数にネットワークの大きさを合わせた適当な係数をかけることにより、データ分布の崩れにくい初期値が考案されている。

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>　→　<strong>Xavierの初期値</strong></li>
<li>ReLU関数　→　<strong>Heの初期値</strong></li>
</ul>
</li>
</ul>


<h5 id="-ベイズ最適化">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a>最適化</h5>

<ul>
<li>ハイパーパラメータを含めた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C7%C5%AC%B2%BD%CC%E4%C2%EA">最適化問題</a>とすることで、効率的なチューニングができる。</li>
</ul>


<h5 id="-スパースなデータ">✓ スパースなデータ</h5>

<ul>
<li>疎なデータ。スパース性を用いて計算量を削減するといった工夫がなされる。</li>
</ul>


<h4 id="-バッチ正規化">✅ バッチ正規化</h4>

<ul>
<li>各層に伝わってきたデータを、その層でまた正規化するアプローチ。</li>
<li>データの正規化、重みの初期化と比較し、より直接的な手法となる。</li>
<li>非常に強力な手法で学習がうまくいきやすく、オーバーフィッティングしにくい。</li>
<li>学習が進むにつれて入力が変化する<strong>内部共変量シフト</strong>に対応することができる。（出力の分布の偏りを抑制する）</li>
<li>内部共変量シフト：<br />
入力の分布が学習の途中で大きく変わってしまう問題。</li>
</ul>


<h4 id="-End-to-End-Learning一気通貫学習">✅ End to End Learning（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%EC%B5%A4%C4%CC%B4%D3">一気通貫</a>学習）</h4>

<ul>
<li>入力から出力までを一括で行う、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>における重要な方法論。</li>
<li>以前は処理を分割していた（せざるを得なかった）が、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>により一括処理ができるようになった。</li>
</ul>


<h3 id="6-4CNN畳み込みニューラルネットワーク">6-4.📘CNN（畳み込み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>）</h3>

<ul>
<li>特徴

<ul>
<li>画像（２次元）をそのまま入力にできる。</li>
<li>人間がもつ視覚野の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%C0%B7%D0%BA%D9%CB%A6">神経細胞</a>（単純型細胞 S細胞、複雑型細胞 C細胞）を模している。</li>
<li>順伝播型<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の一種で、時系列データの分析でも使える。</li>
</ul>
</li>
<li>ネオコグニトロン

<ul>
<li>🎩<strong>福島邦彦</strong>が考案。</li>
<li>上記を組み込んだ最初のモデルで多層構造になっている。</li>
<li>学習方法は <strong>add-if silent</strong>であり 、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>（勾配計算）を用いない。</li>
</ul>
</li>
<li>LeNet

<ul>
<li>その後の1998年、🎩<strong>ヤン・ルカン</strong>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a>に招かれた研究者、「MNIST」の作成者）によって考案されたモデル。</li>
<li>ネオコグニトロンと基本的には同じ。</li>
<li><strong>畳み込み層</strong>と<strong>プーリング層（サブサンプリング層）</strong>による複数組合せ構造。</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>法</strong>が使われる。</li>
</ul>
</li>
</ul>


<h4 id="-畳み込み層">✅ 畳み込み層</h4>

<ul>
<li><strong>フィルタ（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB">カーネル</a>）</strong>により画像の特徴を抽出する操作。</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%C8%A5%E9%A5%A4%A5%C9">ストライド</a></strong>：フィルタを移動させる刻み。</li>
<li>フィルタを通して特徴マップを得る、フィルタの各値が重みにあたる。</li>
<li>畳み込みは<strong>移動不変性</strong>の獲得に貢献、位置ずれの強いモデルが作れる。</li>
<li>パラメータ数は全結合層よりも少ない。<strong>重み共有</strong>により有用な特徴量を画像の位置によって大きく変化させないためである。</li>
</ul>


<h4 id="-プーリング層">✅ プーリング層</h4>

<ul>
<li>決められた演算を行うだけの層。（ダウンサンプリング、サブサンプリング）</li>
<li>そのため、学習すべきパラメータはない。</li>
</ul>


<h5 id="-maxプーリング">✓ maxプーリング</h5>

<ul>
<li>２×２ごとに画像（特徴マップ）の最大値を抽出していく。</li>
</ul>


<h5 id="-avgプーリング">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/avg">avg</a>プーリング</h5>

<ul>
<li>平均値をとる。平均プーリング。</li>
</ul>


<h5 id="-Lpプーリング">✓ Lpプーリング</h5>

<ul>
<li>周りの値をp乗してその<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%B8%BD%E0%CA%D0%BA%B9">標準偏差</a>をとる。</li>
</ul>


<h4 id="-全結合層">✅ 全結合層</h4>

<ul>
<li>分類のためには出力を１次元にする必要があ。全結合層によりデータをフラットにする。</li>
<li>最近の傾向：<br />
全結合層を用いない方法が増えており、１つの特徴マップに１つのクラスを対応させる Global Average Pooling がほとんどになっている。</li>
</ul>


<h4 id="-データ拡張">✅ データ拡張</h4>

<ul>
<li>課題：<br />
同じ物体でも「明るさ」「角度」「大きさ」などにより見え方が異なる。</li>
<li>対応：<br />
データ拡張（データの水増し）を行う。<br />
→　ずらす、反転、拡大・縮小、回転、歪め、切り取り、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%F3%A5%C8%A5%E9">コントラ</a>スト変更 など</li>
<li>注意点：<br />
データ拡張により意味の変わってしまう画像がある。（ex.いいねマークを逆さまにすると違う意味）</li>
</ul>


<h4 id="-CNNの発展形">✅ CNNの発展形</h4>

<ul>
<li><p><strong>AlexNet</strong>の場合（基準として）<br />
（畳み込み＋プーリング)×３層 の構造をとる。</p></li>
<li><p>VGG（<strong>VGG16</strong>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%B5%BB%D5%A4%A2%A4%EA%B3%D8%BD%AC">教師あり学習</a>），<strong>GoogLeNet</strong><br />
AlexNetよりも深いモデルになっている。</p></li>
<li><p>課題①<br />
層を深くすると計算が大変</p></li>
<li><p>工夫①</p>

<ul>
<li>小さなサイズの畳み込みフィルタにより次元（計算量）を削減する。</li>
<li><strong>GoogLeNet</strong>　：　Inceptionモジュールというブロックを構成することで、並列計算を行いやすくする。</li>
<li><strong>VGG16</strong>　：　2014年、GoogleNetに劣らない精度をたたき出した。オックスフォード大学による。</li>
</ul>
</li>
<li><p>課題②<br />
超深層になると誤差の逆伝播がしづらくなるため、逆に性能が落ちる。</p></li>
<li><p>工夫②<br />
<strong>Skip Connection</strong>　：　層を飛び越えた結合を加える。</p></li>
<li><p><strong>ResNet</strong><br />
Skip Connection を導入したモデル、伝播しやすくアンサンブル学習にもなる。<br />
入力層から出力層まで伝播する値と入力層の値を足し合わせたモデルである。<br />
入力層まで勾配値がきちんと伝わるようになり、1000 層といったかなり深い構造でも学習が可能となった。<br />
2015 年の ILSVRC では人間の成績を上回る成果をあげている。</p></li>
<li><p>ILSVRCのモデル推移<br />
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/494282/19918227-7887-d697-f4e2-7602c64adbe9.png" alt="image.png" />
<a href="http://image-net.org/challenges/talks_2017/ILSVRC2017_overview.pdf">http://image-net.org/challenges/talks_2017/ILSVRC2017_overview.pdf</a></p></li>
</ul>


<h3 id="6-5RNNリカレント-ニューラルネットワーク">6-5.📘RNN（リカレント <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>）</h3>

<ul>
<li><p>特徴</p>

<ul>
<li>時間情報を反映できるモデル。隠れ層に時間情報（過去の情報）を持たせることができる。</li>
<li>特徴は<strong>前回の中間層の状態</strong>を隠れ層に入力する<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C6%B5%A2">再帰</a>構造</strong>を取り入れたこと。</li>
<li><strong>BackPropagation Through-Time(BPTT)</strong> ： 時間軸に沿って誤差を反映していく。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>でもよく用いられる。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C6%B5%A2">再帰</a>型<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>で、<strong>閉路</strong>がある。</li>
</ul>
</li>
<li><p>課題　（<a href="https://qiita.com/t_Signull/items/21b82be280b46f467d1b">参考</a>、<a href="http://sagantaf.hatenablog.com/entry/2019/06/04/225239">参考</a>）</p>

<ul>
<li>勾配消失問題</li>
<li>入力重み衝突、出力重み衝突　：　重みが上下して精度が上がらない問題</li>
<li>ネットワークにループ構造が含まれるため、中間層が１層でも勾配消失問題が起こる。</li>
</ul>
</li>
<li><p>解決策<br />
LSTM手法を使う。</p></li>
</ul>


<h4 id="-LSTMLong-Short-Term-Memory">✅ LSTM（Long Short-Term Memory）</h4>

<ul>
<li>時系列データにおいては<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%D5%A5%A1%A5%AF%A5%C8%A5%B9%A5%BF%A5%F3%A5%C0%A1%BC%A5%C9">デファクトスタンダード</a>。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google%CB%DD%CC%F5">Google翻訳</a>でも利用されている。</li>
<li>🎩ユルゲン・シュミットフーバーと、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B1%A5%D7%A5%E9%A1%BC">ケプラー</a>大学の🎩ゼップ・ホフレイターによる提案。</li>
<li>過去から未来に向けて学習し、遠い過去の情報でも出力に反映できる。</li>
<li>活性化関数の工夫ではなく、隠れ層の構造を変えることで解決する。</li>
<li>LSTMブロック機構を適用

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/CEC">CEC</a>（Constant Error Carousel）　：　誤差を内部にとどまらせ勾配消失を防ぐセル。</li>
<li>ゲート　：　入力、出力、忘却の３つ。</li>
<li>各重み衝突に対応しつつ、誤差過剰を防止する忘却を持たせる。</li>
</ul>
</li>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5">機械翻訳</a></strong>や<strong>画像からのキャプション生成（画像の説明文生成）</strong>などにも利用できる。</li>
<li>課題

<ul>
<li>ゲートが多いため計算量が多い</li>
</ul>
</li>
</ul>


<h4 id="-GRUGated-Recurrent-Unit">✅ GRU（Gated Recurrent Unit）</h4>

<ul>
<li>LSTMの計算量を少なくした手法。</li>
<li>リセットゲート、更新ゲートからなる。</li>
</ul>


<h4 id="-RNNの発展形">✅ RNNの発展形</h4>

<h5 id="-Bidirectional-RNN">✓ Bidirectional RNN</h5>

<ul>
<li>未来から過去方向にも学習できるモデル。</li>
</ul>


<h5 id="-RNN-Encoder-Decoder">✓ RNN Encoder-Decoder</h5>

<ul>
<li><p>他モデルの問題<br />
入力は時系列だが出力が一時点になってしまう。</p></li>
<li><p>特徴<br />
出力も時系列である（sequence-to sequence）。<br />
モデルはエンコーダと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0">デコーダ</a>からなる。</p></li>
</ul>


<h5 id="-Attention">✓ Attention</h5>

<ul>
<li><p>他モデルの問題<br />
どの時点の情報がどれだけ影響力を持っているかまではわからない。</p></li>
<li><p>特徴<br />
時間の重みをネットワークに組み込んでいる。</p></li>
<li><p><strong>Attention GAN</strong><br />
文章から画像を生成することができる。</p></li>
</ul>


<h3 id="その他の応用">その他の応用</h3>

<h4 id="-転移学習">✅ 転移学習</h4>

<ul>
<li>学習済みのモデルを用いて追加学習を行う。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を抑制することが出来る。</li>
</ul>


<h4 id="-蒸留">✅ 蒸留</h4>

<ul>
<li>学習済みの大規模モデルの入力と出力を使って新たに学習させる方法。</li>
<li>少ない計算資源で従来と同程度のモデルを作ることが出来る。</li>
</ul>


<h3 id="6-6深層強化学習">6-6.📘深層<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a></h3>

<h4 id="-DQNDeep-Q-learning">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>（Deep Q-learning）</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>の手法である<strong>Q学習</strong>と<strong>深層学習</strong>の組合せ。CNNの一種である。</li>
<li>Q関数（＝行動価値関数）の最大化を目指す。</li>
<li><a href="https://www.youtube.com/watch?v=TmPfTpjtdgg">DeepMind ブロック崩し</a>で採用された。</li>
<li>改良モデル：Double <a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>, Dueling Network, Categorical <a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>, Rainbow</li>
<li>応用事例：AlophaGo（アルファ碁）</li>
</ul>


<h3 id="6-7深層生成モデル">6-7.📘深層生成モデル</h3>

<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は生成タスクにも応用されている。</p>

<h4 id="-画像生成モデル">✅ 画像生成モデル</h4>

<h5 id="-VAEVariable-AutoEncoder">✓ VAE（Variable AutoEncoder）</h5>

<ul>
<li>変分オートエンコーダ、変分自己符号化器</li>
<li>変分<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a>推定法の一種。</li>
<li>入力を統計分布に変換（平均と分散を表現）する。</li>
<li>ランダムサンプリングしたものをデコードすると新しいデータが生成できる。</li>
</ul>


<h5 id="-GAN敵対的生成ネットワーク">✓ GAN（敵対的生成ネットワーク）</h5>

<ul>
<li>🎩<strong>イアン・グッドフェロー</strong>が提唱。</li>
<li>２種類のネットワーク（ジェネレータ：生成、ディスクリミネータ：識別）で競わせる。</li>
<li>画像生成への応用が顕著である。</li>
<li>これ自体はモデルでなく<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A1%BC%A5%AD%A5%C6%A5%AF%A5%C1%A5%E3">アーキテクチャ</a>を指す。</li>
<li>これを実装したモデルが<strong>DCGAN（Deep Convolutional GAN）</strong>。</li>
<li>🎩<strong>ヤン・ルカン</strong>は「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>において、この１０年で最もおもしろいア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%C7%A5%A2">イデア</a>」とコメント</li>
</ul>


<h2 id="７ディープラーニングの研究分野">７．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の研究分野</h2>

<h3 id="7-1画像認識">7-1.📘画像認識</h3>

<h4 id="-ILSVRCImagenet-Large-Scale-Visual-Recognition-Challenge">✅ ILSVRC（Imagenet Large Scale Visual Recognition Challenge）</h4>

<ul>
<li>画像認識の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%F3%A5%DA%A5%C6%A5%A3%A5%B7%A5%E7%A5%F3">コンペティション</a>、課題は位置課題、検出課題の２つ。</li>
<li>Imagenet

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%D5%A5%A9%A1%BC%A5%C9%C2%E7%B3%D8">スタンフォード大学</a>がインターネットから収集した画像群。</li>
<li>1400万枚を超える画像を収録したデータベース。</li>
<li>物体名は２万種以上。</li>
</ul>
</li>
</ul>


<h4 id="-AlexNet">✅ AlexNet</h4>

<ul>
<li>2012年、ILSVRCで優勝したSuperVisionでのモデル。</li>
<li>特徴は、ReLU、SRN、データ拡張、２枚の<a class="keyword" href="http://d.hatena.ne.jp/keyword/GPU">GPU</a>利用。</li>
<li>パラメータ数は６千万個にものぼった。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>のパラメータは多い）</li>
</ul>


<h4 id="-R-CNNRegional-CNN">✅ R-CNN（Regional CNN）</h4>

<ul>
<li><p>関心領域の切り出し（一課題）は従来の手法を用いて行う。<br />
※ <strong>バンディングボックス</strong>（物体検出。関心領域を表す矩形領域のこと）を求める回帰問題となる。</p></li>
<li><p>検出課題についてはCNNを用いる。</p></li>
<li>上記組合せは、時間のかかる手法である。</li>
</ul>


<h4 id="-高速RCNNfast-RCNN">✅ 高速RCNN（fast RCNN）</h4>

<ul>
<li>関心領域の切り出しと物体認識を高速に行う手法。</li>
<li>最初から最後まで深層学習でできるようになった。</li>
</ul>


<h4 id="-faster-RCNN">✅ faster RCNN</h4>

<ul>
<li>高速RCNNが改良され、ほぼ実時間で処理できるようになったモデル。</li>
<li>１６フレーム／秒程度で処理可能。</li>
</ul>


<h4 id="-YOLOYou-Only-Look-at-Once">✅ YOLO（You Only Look at Once）</h4>

<ul>
<li>検出と識別を同時に行うことで、遅延時間の短縮を実現したモデル。<br />
<a href="https://qiita.com/mdo4nt6n/items/68dcda71e90321574a2b">参考（YOLOの歴史）</a></li>
</ul>


<h4 id="-SSDSingle-Shot-Detector">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/SSD">SSD</a>（Single Shot Detector）</h4>

<ul>
<li>YOLOより高速である。</li>
<li>Faster RCNNと同等の精度を実現。</li>
</ul>


<h4 id="-セマンティックセグメンテーション">✅ セマンティックセグメンテーション</h4>

<ul>
<li>R-CNNのような矩形切り出しではなく、より詳細（画素単位）な領域分割を得るモデル。</li>
<li>完全畳み込みネットワーク（FCN）のモデルがあり、すべての層が畳み込み層で構成される。（単体では画像認識を行えない）</li>
<li>同じカテゴリに属する物体はすべて同一ラベルになる。</li>
</ul>


<h4 id="-インスタンスセグメンテーション">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%B9%A5%BF%A5%F3%A5%B9">インスタンス</a>セグメンテーション</h4>

<ul>
<li>同じカテゴリに属する物体でもすべて別ラベルにできる。</li>
</ul>


<h4 id="-完全畳み込みネットワークFCN">✅ 完全畳み込みネットワーク（FCN）</h4>

<p>全ての層が畳み込み層。</p>

<h4 id="-画像データの前処理">✅ 画像データの前処理</h4>

<ul>
<li>リサイズ、トリミング</li>
<li>グレースケール化：<br />
カラー画像を白黒画像に変換して計算量を削減する。</li>
<li>平滑化：<br />
細かいノイズの影響を除去する。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D2%A5%B9%A5%C8%A5%B0%A5%E9%A5%E0">ヒストグラム</a>平均：<br />
画素ごとの明るさをスケーリングする。</li>
</ul>


<h3 id="7-2自然言語処理">7-2.📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a></h3>

<h4 id="-関連ワード">✅ 関連ワード</h4>

<h5 id="-言語モデル">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a></h5>

<ul>
<li>「単語の意味は、その周辺の単語によって決まる」という<a href="https://qiita.com/g-k/items/69afa87c73654af49d36">分布仮説</a>がある。</li>
</ul>


<h5 id="-分散表現">✓ 分散表現</h5>

<ul>
<li>記号を計算機上で扱うための方法論。</li>
<li><a href="https://sites.google.com/site/iwanamidatascience/vol2/word-embedding">単語を高次元の実数ベクトルで表現する技術。</a></li>
<li><a href="https://qiita.com/g-k/items/69afa87c73654af49d36">単語を固定長のベクトルで表現する。</a></li>
</ul>


<h5 id="-構文解析">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF">構文解析</a></h5>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90">構文解析</a></li>
<li>文章（テキスト文字列）を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>に切分け、その間の関連（修飾-被修飾など）といったような<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%FD%B8%EC%CF%C0">統語論</a>的（構文論的）な関係を図式化するなどして明確にする（解析する）手続き。</li>
</ul>


<h5 id="-照応解析">✓ 照応解析</h5>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E7%85%A7%E5%BF%9C%E8%A7%A3%E6%9E%90">照応解析</a></li>
<li>照応詞（代名詞や指示詞など）の指示対象を推定したり、省略された名詞句（ゼロ代名詞）を補完する処理のこと。</li>
</ul>


<h5 id="-談話解析">✓ 談話解析</h5>

<ul>
<li><a href="http://www-haradalb.it.aoyama.ac.jp/dia.html">談話解析</a></li>
<li>文章中の文と文の間の役割的関係や話題の推移を明らかにするものである。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF">構文解析</a>、意味解析などの１文内の言語要素を対象にした解析とは異なる。</li>
</ul>


<h5 id="-形態素解析">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a></h5>

<ul>
<li><a href="https://ja.wikipedia.org/wiki/%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90">形態素解析</a></li>
<li>文を単語に分解し品詞を特定する。</li>
<li>日本語は英語のようにスペースで区切られていない。<a href="https://qiita.com/AwaJ/items/98123d1d3a9bbb6e3e3d#%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90">分析のためには、単語を区切る必要がある。</a></li>
</ul>


<h5 id="-N-gram">✓ <a class="keyword" href="http://d.hatena.ne.jp/keyword/N-gram">N-gram</a></h5>

<ul>
<li><a href="https://qiita.com/kazmaw/items/4df328cba6429ec210fb">単語ではなく、文字数で分割する手法</a>。</li>
<li><a href="https://qiita.com/AwaJ/items/98123d1d3a9bbb6e3e3d#ngram">形態素解析よりも単純で、任意の連続したN文字単位で区切る。</a></li>
</ul>


<h4 id="-bag-of-words">✅ bag-of-words</h4>

<ul>
<li>文章に単語が含まれているかどうかを考えて、テキストデータを数値化（ベクトル化）する。</li>
<li><a href="https://qiita.com/AwaJ/items/98123d1d3a9bbb6e3e3d#bag-of-words">文の構成などは考えず、単語の出現のみに注目する。</a></li>
</ul>


<h4 id="-TF-IDFTerm-Frequency---Inverse-Document-Frequency">✅ TF-IDF（Term Frequency - Inverse Document Frequency）</h4>

<ul>
<li>文章に含まれる単語の重要度を特徴量とする。</li>
<li><a href="https://qiita.com/AwaJ/items/5937665d5a4152cc24cf">文書の中から、その文書の特徴語を抽出する時に使う値。</a></li>
<li>TF：<a href="https://qiita.com/AwaJ/items/5937665d5a4152cc24cf#tf">単語の文書内の出現頻度。</a></li>
<li>IDF：<a href="https://qiita.com/AwaJ/items/5937665d5a4152cc24cf#idf">ある単語が出てくる文書頻度の逆数。文書中に多く使われるほど、特徴語にはなりにくいという考え方。</a></li>
</ul>


<h4 id="-隠れマルコフモデル">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B1%A3%A4%EC%A5%DE%A5%EB%A5%B3%A5%D5%A5%E2%A5%C7%A5%EB">隠れマルコフモデル</a></h4>

<ul>
<li>HMM、Hidden Markov Model</li>
<li>直前の結果のみから次の結果が確率的に求まるという「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%B3%A5%D5%C0%AD">マルコフ性</a>」を仮定して、事象をモデル化する手法。</li>
</ul>


<h4 id="-word2vec">✅ word2vec</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%AF%A5%C8%A5%EB%B6%F5%B4%D6%A5%E2%A5%C7%A5%EB">ベクトル空間モデル</a>、単語埋め込みモデルともいわれる。</li>
<li>2013年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>により開発。

<ul>
<li><a href="https://qiita.com/kenta1984/items/6dc327c31b6c36e66863">日本語モデルは東北大学や企業が公開している。</a></li>
</ul>
</li>
<li>中間層の活性値を単語の意味ベクトルとみなす。

<ul>
<li><a href="https://qiita.com/g-k/items/69afa87c73654af49d36">中間層の活性化関数の「重み」を分散表現とする。</a></li>
</ul>
</li>
<li><a href="https://qiita.com/kenta1984/items/6dc327c31b6c36e66863">王様－男性＋女性＝女王　のような計算ができる、というのが有名</a>。</li>
<li><strong>CBOW</strong>と<strong>スキップグラム</strong>の２つの手法がある。</li>
</ul>


<h5 id="-CBOWCountinuous-Bag-of-Words">✓ CBOW（Countinuous Bag-of-Words）</h5>

<ul>
<li><a href="https://qiita.com/g-k/items/69afa87c73654af49d36#cbow%E3%83%A2%E3%83%87%E3%83%AB">周辺の単語を与えて、ある単語を予測する。</a></li>
</ul>


<h5 id="-スキップグラムSkip-gram">✓ スキップグラム（Skip-gram）</h5>

<ul>
<li><a href="https://qiita.com/g-k/items/69afa87c73654af49d36#skip-gram%E3%83%A2%E3%83%87%E3%83%AB">ある単語を与えて、その周辺の単語を予測する。</a></li>
<li>CBOWでのコンテクストとターゲットを逆転させたようなモデル。</li>
</ul>


<h4 id="-fastText">✅ fastText</h4>

<ul>
<li>🎩トマス・ミコロフらが開発。</li>
<li>単語表現に文字の情報も含めることができる。</li>
<li>訓練データにない単語が作れるようになる。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Wikipedia">Wikipedia</a>と<a href="http://commoncrawl.org/">Common Crawl</a>による１５７言語の<a href="https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md">訓練データ</a>がある</li>
</ul>


<h4 id="-ELMo">✅ ELMo</h4>

<ul>
<li>文章表現を得るモデル。</li>
</ul>


<h4 id="-マルチタスク言語処理">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>言語処理</h4>

<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF">マルチタスク</a>学習は単一のモデルで複数の課題を解く<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>の手法。<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC">自然言語</a>では品詞づけ・文節判定・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%B8%A4%EA%BC%F5%A4%B1">係り受け</a>・文意関係(補強・反対・普通)・文関係の度合いを同時に学習させる。<br />
<a href="https://ai-kenkyujo.com/term/multitask-learning/">参考 AI研究所</a></p>

<h4 id="-ニューラル画像脚注付け">✅ ニューラル画像脚注付け</h4>

<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/NIC">NIC</a>、Neural Image Captioning。<br />
画像認識モデルの全結合直下層の情報を、言語生成用リカレント<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>の中間層の初期値として用いる。</p>

<h4 id="-ニューラルチューリングマシン">✅ ニューラル<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0%A5%DE%A5%B7%A5%F3">チューリングマシン</a></h4>

<ul>
<li>Neural <a class="keyword" href="http://d.hatena.ne.jp/keyword/Turing%20Machine">Turing Machine</a>：NTM</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C1%A5%E5%A1%BC%A5%EA%A5%F3%A5%B0%A5%DE%A5%B7%A5%F3">チューリングマシン</a>を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>により実現する試み。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC">微分</a>可能であり、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C7%B5%DE%B9%DF%B2%BC%CB%A1">最急降下法</a>による効率的な学習が可能。</li>
</ul>


<h4 id="-Tay">✅ 💻Tay</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Microsoft">Microsoft</a>社によるチャットボット。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Twitter">Twitter</a>上で不適切な誘導を受け、不適切な行動を繰り返しサービスが停止された。</li>
<li><a href="https://gigazine.net/news/20160325-tay-microsoft-flaming-twitter/">Gigazine-Microsoftの人工知能が「クソフェミニストは地獄で焼かれろ」「ヒトラーは正しかった」など問題発言連発で炎上し活動停止</a></li>
</ul>


<h4 id="-BERT">✅ BERT</h4>

<ul>
<li>Bidirectional Encoder Representations from Transformers。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a> AI Languageの研究者が最新論文で発表した。</li>
<li>参考

<ul>
<li><a href="https://ainow.ai/2019/05/21/167211/">BERT&#x89E3;&#x8AAC;&#xFF1A;&#x81EA;&#x7136;&#x8A00;&#x8A9E;&#x51E6;&#x7406;&#x306E;&#x305F;&#x3081;&#x306E;&#x6700;&#x5148;&#x7AEF;&#x8A00;&#x8A9E;&#x30E2;&#x30C7;&#x30EB; | AI&#x5C02;&#x9580;&#x30CB;&#x30E5;&#x30FC;&#x30B9;&#x30E1;&#x30C7;&#x30A3;&#x30A2; AINOW</a></li>
</ul>
</li>
</ul>


<h3 id="7-3音声処理">7-3.📘音声処理</h3>

<h4 id="-WaveNet">✅ WaveNet</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/DeepMind">DeepMind</a>社により開発。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%B9%E7%C0%AE">音声合成</a>と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>ができる。</li>
<li>自然な発話により、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%B9%E7%C0%AE">音声合成</a>のブレイクスルーとして注目された。</li>
</ul>


<h4 id="-それまでの音声認識">✅ それまでの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a></h4>

<ul>
<li>1990年代では、<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B1%A3%A4%EC%A5%DE%A5%EB%A5%B3%A5%D5%A5%E2%A5%C7%A5%EB">隠れマルコフモデル</a>（HMM）</strong>による音の判別モデルと、<strong>Nグラム法</strong>による語と語のつながりを判別する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C0%B8%EC%A5%E2%A5%C7%A5%EB">言語モデル</a>でできていた。</li>
</ul>


<h3 id="7-4ロボティクス-強化学習">7-4.📘ロボティクス （<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>）</h3>

<ul>
<li><p>動作制御には<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED%CB%A1">モンテカルロ法</a></strong>や<strong>Q学習</strong>が応用されている。</p></li>
<li><p><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a>（Deep Q Networks）</strong>
アタリのゲームに対して応用された。</p></li>
<li><p>アルファ碁
<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED">モンテカルロ</a>木探索</strong>で成果を挙げた。</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%D5%A5%A1%B8%EB%A5%BC%A5%ED">アルファ碁ゼロ</a>
<strong>セルフプレイ</strong>により学習を進め、アルファ碁を凌駕した。</p></li>
<li><p>RAINBOWモデル
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>の性能を改善するための３つのモデルをすべて適用したもの。</p>

<ul>
<li>方策ベース</li>
<li>状態価値関数（価値ベース）

<ul>
<li>Q学習、SARSA（<a href="https://qiita.com/shionhonda/items/ec05aade07b5bea78081#%E6%96%B9%E7%AD%96%E3%83%99%E3%83%BC%E3%82%B9%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0">参考</a>）</li>
</ul>
</li>
<li>モデルベース</li>
</ul>
</li>
</ul>


<h4 id="-強化学習の課題">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a>の課題</h4>

<ul>
<li><p>学習時間</p>

<ul>
<li>理論的には無限に学習できるが、実際は有限なため損耗し学習継続が困難になることがある。</li>
</ul>
</li>
<li><p>マルチエージェント応用</p>

<ul>
<li>複数のエージェントで相互学習を開始すると、初期段階での知識が不十分なため学習過程において不安定化が見られる。</li>
<li>対応のため、<strong>逆<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC">強化学習</a></strong>や<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/DQN">DQN</a></strong>などが適用されている。</li>
</ul>
</li>
</ul>


<h3 id="7-5マルチモーダル">7-5.📘マルチモーダル</h3>

<ul>
<li>五感や体性感覚（平衡感覚、空間感覚など）の複数の感覚情報を組み合わせて処理すること。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>においては、複数の異なる情報を用いて学習することを、<strong>マルチモーダル学習</strong>という。</li>
</ul>


<h2 id="８ディープラーニングの応用に向けて">８．📘<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>の応用に向けて</h2>

<h3 id="8-1産業への応用">8-1.📘産業への応用</h3>

<h4 id="-ものづくり">✅ ものづくり</h4>

<ul>
<li><p>自動車ギヤ不良検出<br />
良品データの特徴を抽出し、その差分から不良品を検出する。（武蔵精密工業/ABEJA）</p></li>
<li><p>射出成形機の予防<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%DD%C1%B4">保全</a><br />
熟練技術者の知見を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>に応用し、安定生産を目指す。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A1%A5%CA%A5%C3%A5%AF">ファナック</a>/Preffered Networks）</p></li>
<li><p>バラ積み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D4%A5%C3%A5%AD%A5%F3%A5%B0">ピッキング</a><br />
ロボットに求められる作業レベルは高度化。複雑な作業の実現へ。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A1%A5%CA%A5%C3%A5%AF">ファナック</a>/Prefered Networks、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%C2%C0%EE%C5%C5%B5%A1">安川電機</a>/ク<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%ED%A5%B9%A5%B3%A5%F3">ロスコン</a>パス）</p></li>
<li><p>不良品検出<br />
食品製造ラインでの不良検出を行う。（キューピー/ブレインパッド）</p></li>
</ul>


<h4 id="-モビリティ">✅ モビリティ</h4>

<ul>
<li>自動運転

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%E2%B3%D5%B4%B1%CB%BC">内閣官房</a>IT総合戦略室等、2020年<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%B5%BF%CD">無人</a>自動走行による移動サービス。</li>
<li>2022年高速道路でのトラック隊列走行の商用化を目指す。</li>
<li>あわせて各種検討が行われている。（安全基準、交通ルール、保険等の責任関係、制度設計）</li>
</ul>
</li>
<li><p><a href="http://qa.jaf.or.jp/mechanism/structure/16.htm"><strong>自動運転レベル</strong></a></p>

<table>
<thead>
<tr>
<th>レベル</th>
<th>概要</th>
</tr>
</thead>
<tbody>
<tr>
<td>レベル０</td>
<td>自動運転化なし</td>
</tr>
<tr>
<td>レベル１</td>
<td>運転支援</td>
</tr>
<tr>
<td>レベル２</td>
<td>部分運転自動化</td>
</tr>
<tr>
<td>レベル３</td>
<td>条件付運転自動化</td>
</tr>
<tr>
<td>レベル４</td>
<td>高度運転自動化</td>
</tr>
<tr>
<td>レベル５</td>
<td>完全自動運転</td>
</tr>
</tbody>
</table>
</li>
<li><p>ロボットタクシー</p>

<ul>
<li>移動サービス（ロボットタクシー）の開発が進められている。</li>
</ul>
</li>
</ul>


<h4 id="-医療">✅ 医療</h4>

<ul>
<li><p>診断支援</p>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%E2%BB%EB%B6%C0">内視鏡</a>画像における<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%DF%A4%AC%A4%F3">胃がん</a>検出、CNN活用（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CD%AD%CC%C0">有明</a>病院/AIメディカルサービス）</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C2%E7%C4%B2%C6%E2%BB%EB%B6%C0">大腸内視鏡</a>検査、発見率98%（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%F1%CE%A9%A4%AC%A4%F3%B8%A6%B5%E6%A5%BB%A5%F3%A5%BF%A1%BC">国立がん研究センター</a>等）</li>
<li>網膜はく離判定、AUC98%（ツカザキ病院眼科/Rist）</li>
</ul>
</li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%CF%CC%F4">創薬</a><br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%CF%CC%F4">創薬</a>生産性の向上（エクサウィザーズ/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%FE%C5%D4%C2%E7%B3%D8">京都大学</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CD%FD%B2%BD%B3%D8%B8%A6%B5%E6%BD%EA">理化学研究所</a>）</p></li>
<li><p>ゲノム</p>

<ul>
<li>遺伝子の解析、推定結果の理由を説明、衣料分野では説明責任が問われる。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D9%BB%CE%C4%CC%B8%A6%B5%E6%BD%EA">富士通研究所</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D9%BB%CE%C4%CC">富士通</a>）</li>
<li>がん罹患者の個人別最適化衣料（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%F1%CE%A9%A4%AC%A4%F3%B8%A6%B5%E6%A5%BB%A5%F3%A5%BF%A1%BC">国立がん研究センター</a>/Preferred Networks 等）</li>
<li>ゲノム医科学用スーパーコンピュータ利用、計算資源の確保と共用により研究を効率化（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%FC%CB%DC%B0%E5%CE%C5%B8%A6%B5%E6%B3%AB%C8%AF%B5%A1%B9%BD">日本医療研究開発機構</a>）</li>
</ul>
</li>
</ul>


<h4 id="-介護">✅ 介護</h4>

<ul>
<li>着衣介助（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%E5%BD%A3%B9%A9%B6%C8%C2%E7%B3%D8">九州工業大学</a>）</li>
<li>介護<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%C1%A5%F3">コーチン</a>グ、コミュニケーション等の指導（エクサウィザーズ）</li>
</ul>


<h4 id="-インフラ防犯監視">✅ インフラ・防犯、監視</h4>

<ul>
<li><p>コン<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%EA%A1%BC%A5%C8">クリート</a>ひび割れ検出<br />
５年に１回の近接目視点検に対応。CNNを応用し80%以上の精度。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/NEDO">NEDO</a>等）</p></li>
<li><p>舗装道路損傷判断<br />
路面のわだち掘れとヒビ割れを同時に検出。専門技術者と同等のレベル。（福田道路、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C6%FC%CB%DC%C5%C5%B5%A4">日本電気</a>）<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%DE%A1%BC%A5%C8%A5%D5%A5%A9%A5%F3">スマートフォン</a>画像から損傷状態を判別（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%E9%CD%D5%BB%D4">千葉市</a>等）</p></li>
<li><p>橋梁内部損傷<br />
目視だけでは判断が難しい。センサーによる振動データ解析から損傷を推定。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D9%BB%CE%C4%CC">富士通</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%D9%BB%CE%C4%CC%B8%A6%B5%E6%BD%EA">富士通研究所</a>）</p></li>
<li><p>送電線点検<br />
異常画像の収集が困難。GANによる画像生成で解決をはかる取組み。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%EC%BC%C7%A5%C7%A5%B8%A5%BF%A5%EB%A5%BD%A5%EA%A5%E5%A1%BC%A5%B7%A5%E7%A5%F3%A5%BA">東芝デジタルソリューションズ</a>）</p></li>
<li><p>地質評価<br />
CNNにより岩盤強度を特定。マルチスペクトル画像を活用。（安藤ハザマ）</p></li>
<li><p>屋内型混合廃棄物選別<br />
廃棄物の判別を自動化。選別作業15人を2人まで削減。8時間から24時間化へ。（シタラ興産）</p></li>
<li><p>困っている方の検知<br />
カメラ映像による挙動から困っている方の自動検知。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BB%B0%C9%A9%C3%CF%BD%EA">三菱地所</a>、ALSOK等）</p></li>
</ul>


<h4 id="-サービス小売">✅ サービス・小売</h4>

<ul>
<li><p>タクシー需要予測<br />
Stacked denoising Autoencoder（SdA）を使用し、需要を92.9%の精度で予測（<a class="keyword" href="http://d.hatena.ne.jp/keyword/NTT%A5%C9%A5%B3%A5%E2">NTTドコモ</a>）</p></li>
<li><p>商業施設の来店者分析<br />
来店者数、年齢・性別判定。店舗スタッフの人員体制最適化等に活用。（パルコ、ABEJA）</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%B5%BF%CD">無人</a>コンビニ<br />
天井に取り付けたカメラで来店者を特定。商品状態を管理する小型カメラで商品を手にしたことを検知。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C5%EC%C6%FC%CB%DC%CE%B9%B5%D2%C5%B4%C6%BB">東日本旅客鉄道</a>、サインポスト）</p></li>
<li><p>双腕型マルチモーダルロボット<br />
マルチモーダルAIロボットにより、人が人に作業を教えるようにロボットに学習させる。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%F3%A5%BD%A1%BC">デンソー</a>ウェーブ等）</p></li>
</ul>


<h4 id="-その他">✅ その他</h4>

<ul>
<li><p>物量画像判別<br />
荷物の寸法や破損状況などを自動判別。（鈴与、佐川急便、Automagi、<a class="keyword" href="http://d.hatena.ne.jp/keyword/NTT%A5%C7%A1%BC%A5%BF">NTTデータ</a>）</p></li>
<li><p>倉庫運用最適化<br />
CNNモデルにより、倉庫内ピックアップルートの最適化。（Zalando（ベルリン））</p></li>
<li><p>収穫・仕分け<br />
果梗（かこう）の認識に応用。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A5%CA%A5%BD%A5%CB%A5%C3%A5%AF">パナソニック</a>）</p></li>
<li><p>農薬散布<br />
害虫の多い箇所にピンポイントで農薬散布。ドローン画像による解析。農薬量を1/10以下へ。（オプティム）</p></li>
<li><p>株価予測<br />
時系列解析により短期的な予測を実施。（AlpacaJapan）</p></li>
<li><p>不正取引検知<br />
オンラインバンキングでの不正検知における誤検知を大幅に改善。（Danske Bank/TERADATA）</p></li>
<li><p>講義動画内の文字検知<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%C7%A5%A3">スタディ</a>サプリの講義動画からテキストを検知し、検索対象にする。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%EA%A5%AF%A5%EB%A1%BC%A5%C8">リクルート</a>テク<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CE%A5%ED">ノロ</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A1%BC">ジー</a>ズ）</p></li>
<li><p>採点支援<br />
記述式解答への対応として、文字認識率を向上。（EduLab）</p></li>
<li><p>ユーザーコメント分析<br />
インコニコ動画等における不適切なコメントを検知。LSTMモデル。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%EF%A5%F3%A5%B4">ドワンゴ</a>）</p></li>
<li><p>画像商品検索<br />
Image Search を開発。類似商品の検索を可能に。（Alibaba）</p></li>
<li><p>レコメンド<br />
キョウチョウフィルタリングにより、類似曲をレコメンド。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/Spotify">Spotify</a>）</p></li>
<li><p>出品者監視<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%E9%A5%AF%A5%DE">ラクマ</a>において、近視出品物の監視。類似画像検出。（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B3%DA%C5%B7">楽天</a>）</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a><br />
ヤフー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%BB%C0%BC%C7%A7%BC%B1">音声認識</a>サービスYJVOICEで応用。DNN-HMM hybrid 音響モデルを活用。誤り率が改善。（ヤフー）</p></li>
<li><p>チャットボット<br />
顧客対応の24時間化等で利用されている。</p></li>
</ul>


<h4 id="-応用路線">✅ 応用路線</h4>

<ul>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a> 社・<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a> 社<br />
言語データによる RNN や映像データからの概念・知識理解を目指す。</p></li>
<li><p>UC Berkeley<br />
実世界を対象に研究を進め知識理解を目指す。</p></li>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/DeepMind">DeepMind</a> 社<br />
🎩<strong>デミス・ハサビス</strong>により設立。<br />
オンライン空間上でできることをターゲットにして知識理解を目指す。</p></li>
</ul>


<h3 id="8-2法律">8-2.📘法律</h3>

<h4 id="-法">✅ 法</h4>

<ul>
<li>制約になり得るが、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%CE%A5%D9%A1%BC%A5%B7%A5%E7%A5%F3">イノベーション</a>の自由を支えるものでもある。</li>
</ul>


<h4 id="-プライバシーバイデザイン">✅ プライバシー・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%A4%A1%A6%A5%C7%A5%B6%A5%A4%A5%F3">バイ・デザイン</a></h4>

<ul>
<li>Privacy by Design：PbD</li>
<li>仕様検討段階からプライバシー侵害の予防を指向する。</li>
<li>他に、セキュリティ・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%A4%A1%A6%A5%C7%A5%B6%A5%A4%A5%F3">バイ・デザイン</a>　や　バリュー・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%A4%A1%A6%A5%C7%A5%B6%A5%A4%A5%F3">バイ・デザイン</a>　がある。</li>
</ul>


<h4 id="-データの収集">✅ データの収集</h4>

<p>以下を考慮する必要がある。</p>

<ol>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%F8%BA%EE%B8%A2%CB%A1">著作権法</a></li>
<li>不正防止競争防止法</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C4%BF%CD%BE%F0%CA%F3%CA%DD%B8%EE%CB%A1">個人情報保護法</a></li>
<li>個別の契約</li>
<li>その他の理由</li>
</ol>


<p>成果（データ）をラボの外に出さなくても問題になるケースがある。（取得自体が問題になるケースも）</p>

<h4 id="-日本の著作権法">✅ 日本の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%F8%BA%EE%B8%A2%CB%A1">著作権法</a></h4>

<ul>
<li>日本では「情報解析を行うために著作物を複製してもよい」とされており、<strong>世界的に見ても先進的</strong>である。</li>
</ul>


<h4 id="-オープンイノベーションの弊害">✅ オープン<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%CE%A5%D9%A1%BC%A5%B7%A5%E7%A5%F3">イノベーション</a>の弊害</h4>

<ul>
<li>複数企業による研究開発が進んでいるが、トラブルも散見される。</li>
<li>認識のズレやプロジェクト管理の甘さから高額訴訟に至るケースもある。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B9%A5%C6%A5%E0%B3%AB%C8%AF">システム開発</a>の協力義務を念頭に、プロジェクトを注意深く推進することが求められる。</li>
</ul>


<h4 id="-AIデータの利用に関する契約ガイドライン">✅ <a href="https://www.meti.go.jp/press/2018/06/20180615001/20180615001.html">AI・データの利用に関する契約ガイドライン</a></h4>

<ul>
<li>2018年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%D0%BA%D1%BB%BA%B6%C8%BE%CA">経済産業省</a>が策定。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B3%AB%C8%AF%A5%D7%A5%ED%A5%BB%A5%B9">開発プロセス</a>は ①アセスメント、②PoC、③開発、④追加学習 の４段階。</li>
<li>契約類型は３つ、データ提供型、データ創出型、データ共用型。</li>
</ul>


<h4 id="-知的財産法">✅ 知的財産法</h4>

<p>一定の条件を満たせば知的財産として保護される。<br />
事前にケースを整理しておくとよい。</p>

<h4 id="-次世代知財システム検討委員会報告書">✅ 次世代<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%CE%BA%E2">知財</a>システム検討委員会報告書</h4>

<ul>
<li><a href="http://www.kantei.go.jp/jp/singi/titeki2/tyousakai/kensho_hyoka_kikaku/index.html">次世代知財システム検討委員会</a>による。</li>
<li><a href="https://www.kantei.go.jp/jp/singi/titeki2/tyousakai/kensho_hyoka_kikaku/2016/jisedai_tizai/hokokusho.pdf">報告書</a>として取り纏められている。</li>
</ul>


<h4 id="-利用者保護">✅ 利用者保護</h4>

<ul>
<li>当初目的以外でデータ利用する場合は再度レビューを行うこと。</li>
<li>利用目的はできる限り特定すること（<strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%C4%BF%CD%BE%F0%CA%F3%CA%DD%B8%EE%CB%A1">個人情報保護法</a></strong> 15条1項）</li>
<li>利用目的変更では事前の本人同意が必要（16条1項）</li>
<li>本人の通知と公表を行う（18条1項）</li>
<li>個人データの漏洩防止など安全管理措置を講じること（20条）</li>
<li>従業員の監督義務（21条）、委託先の監督義務（22条）</li>
<li>データ内容の正確性の確保などに関する努力義務（19条）</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/EU%B0%EC%C8%CC%A5%C7%A1%BC%A5%BF%CA%DD%B8%EE%B5%AC%C2%A7">EU一般データ保護規則</a>（<a class="keyword" href="http://d.hatena.ne.jp/keyword/GDPR">GDPR</a>）にも注意。</li>
</ul>


<h4 id="-ドローンでの利用参考">✅ ドローンでの利用（<a href="https://viva-drone.com/drone-premission-online-dips-mlit-go-jp/">参考</a>）</h4>

<h5 id="-許可が必要になる飛行場所">✓ 許可が必要になる飛行場所</h5>

<ul>
<li>空港周辺</li>
<li>150m以上の上空</li>
<li>人家の密集地域（人口集中地区、DID地区）</li>
</ul>


<h5 id="-承認が必要になる飛行方法">✓ 承認が必要になる飛行方法</h5>

<ul>
<li>夜間飛行</li>
<li>目視外飛行</li>
<li>第<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BB%B0%BC%D4">三者</a>やその所有物（家や車）の30m未満の距離での飛行</li>
<li>催し場所での飛行</li>
<li>危険物の輸送</li>
<li>物件投下</li>
</ul>


<h3 id="8-3倫理">8-3.📘倫理</h3>

<h4 id="-IEEE-P7000シリーズ">✅ <a class="keyword" href="http://d.hatena.ne.jp/keyword/IEEE">IEEE</a> P7000シリーズ</h4>

<ul>
<li>「倫理的に調和された設計」レポート。</li>
<li>倫理的な設計を技術段階、開発段階に取り込む試み。</li>
</ul>


<h4 id="-データセットの偏り">✅ デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>の偏り</h4>

<ul>
<li>デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>によっては偏り・過少代表・過大代表などが生じる。</li>
<li>データベースに登録されていないことによる偏りも生じる可能性がある。</li>
<li>現実世界の偏りが増幅されることで、問題が生じる場合がある。</li>
</ul>


<h4 id="-カメラ画像利活用ガイド">✅ <a href="https://www.meti.go.jp/press/2017/03/20180330005/20180330005.html">カメラ画像利活用ガイド</a></h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%D0%BA%D1%BB%BA%B6%C8%BE%CA">経済産業省</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C1%ED%CC%B3%BE%CA">総務省</a>、IOT推進コンソーシアムによる。</li>
<li>企業が配慮すべきことをまとめている。</li>
</ul>


<h4 id="-自律型致死性兵器LAWSLethal-Autonomous-Weapon-Systems">✅ 自律型致死性兵器（LAWS：Lethal Autonomous Weapon Systems）</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>などにより完全に自律した殺傷能力を持つ兵器のこと。</li>
<li>現段階では存在しないが、専門家間で協議が続いている。</li>
<li>一連の会議において、「LAWSの定義」、「人間の関与」等が議論された。</li>
<li><a href="https://www.mod.go.jp/msdf/navcol/SSG/topics-column/071.html">参考</a></li>
</ul>


<h4 id="-人工知能学会９つの指針">✅ <a href="http://ai-elsi.org/wp-content/uploads/2017/02/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E5%AD%A6%E4%BC%9A%E5%80%AB%E7%90%86%E6%8C%87%E9%87%9D.pdf">人工知能学会　９つの指針</a></h4>

<ol>
<li>人類への貢献</li>
<li>法規制の遵守</li>
<li>他者のプライバシーの尊重</li>
<li>公正性</li>
<li>安全性</li>
<li>誠実な振る舞い</li>
<li>社会に対する責任</li>
<li>社会との対話と自己研鑽</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>への倫理遵守の要請</li>
</ol>


<h3 id="8-4現行の議論">8-4.📘現行の議論</h3>

<h4 id="-日本ディープラーニング協会の見解">✅ 日本<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>協会の見解</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>は決して万能なわけではない。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>以外の手法を使う方が有効な場合もある。<br />
→　<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>自体が目的化してはならない。</li>
<li>ex.ワシントンDC「IMPACT」<br />
教師のスコアリングにより解雇を行ったが、現場のニーズや実情に合致していなかった。</li>
</ul>


<h4 id="-目標間のトレードオフ">✅ 目標間の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C8%A5%EC%A1%BC%A5%C9%A5%AA%A5%D5">トレードオフ</a></h4>

<ul>
<li><strong><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%A8%C4%B4%A5%D5%A5%A3%A5%EB%A5%BF%A5%EA%A5%F3%A5%B0">協調フィルタリング</a></strong>により、<strong>フィルタ・バブル</strong>（好みの情報にしか触れられなくなる）が生じる。</li>
<li>個別性と社会性の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C8%A5%EC%A1%BC%A5%C9%A5%AA%A5%D5">トレードオフ</a>になる。</li>
<li><strong>FAT</strong>（Fairness, Accoutability, and Transparency：公平性・説明責任・透明性）という研究領域やコミュニティがある。</li>
</ul>


<h4 id="-Adversarial-ExampleAdversarial-attacks参考">✅ Adversarial Example（Adversarial attacks）　（<a href="https://qiita.com/deaikei/items/ecbf2e796e771bf7113f">参考</a>）</h4>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0">ディープラーニング</a>における重要な課題の一つ。</li>
<li>分類器に対する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%C8%BC%E5%C0%AD">脆弱性</a>攻撃のようなもの。</li>
<li>学習済みのディープ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>モデルを欺くように人工的に作られたサンプルで、人の目には判別できない程度のノイズを加えることで作為的に分類器の判断を誤らせる。</li>
<li><strong>絶対的に安全な技術はない</strong>ことを認識しておくこと。</li>
</ul>


<h4 id="-クライシスマネジメント危機管理">✅ クライシス・マネジメント（危機管理）</h4>

<ul>
<li><strong>火消し</strong>（危機を最小限に抑える）、<strong>復旧</strong>（再発防止）が主眼。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A8%A5%B9">エス</a>カレーションの仕組みづくりが重要。防災訓練を行うこと。</li>
<li>危機管理マニュアルの有効性を検証する。</li>
</ul>


<h4 id="-透明性レポート">✅ 透明性レポート</h4>

<ul>
<li>プライバシーヤセキュリティについては、積極的に社会と対話する必要がある。</li>
<li>いくつかの個別企業では<strong>透明性レポート</strong>を公開している。</li>
</ul>


<h4 id="-指針作り">✅ 指針作り</h4>

<ul>
<li><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a></p>

<ul>
<li>AI技術開発の原則を公開、「<a href="https://www.blog.google/technology/ai/ai-principles/">AI at Google: our principles</a>」。</li>
</ul>
</li>
<li><p><strong>Partnership on AI（PAI）</strong></p>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Amazon">Amazon</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Facebook">Facebook</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/IBM">IBM</a>、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Microsoft">Microsoft</a>などで組織された。</li>
<li>AIにおける公平性、透明性、責任などへの取組みを提示。</li>
</ul>
</li>
<li><p><strong>ア<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%ED%A5%DE">シロマ</a>AI原則</strong></p>

<ul>
<li>2017年2月、世界中のAI研究者らが集まり発表。</li>
<li>AIの短期的、長期的な課題について公開。</li>
<li>「AIによる軍拡競争は避けるべきである」ことが明示された。</li>
</ul>
</li>
</ul>


<h3 id="その他">その他</h3>

<h4 id="-日本">✅ 日本</h4>

<h5 id="-新産業構造ビジョン">✓ 新産業構造ビジョン</h5>

<h5 id="-人間中心のＡＩ社会原則及びＡＩ戦略2019有識者提案">✓ 「人間中心のＡＩ社会原則」及び「ＡＩ戦略2019(<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CD%AD%BC%B1%BC%D4">有識者</a>提案)」</h5>

<ul>
<li><a href="https://www.mhlw.go.jp/content/10601000/000502267.pdf">参考</a></li>
</ul>


<h4 id="-中国">✅ 中国</h4>

<h5 id="-中国製造2025">✓ 中国製造2025</h5>

<ul>
<li>2025年までの中国製造業発展のロードマップ。</li>
<li>AI技術に関する取組み強化が明言されている。</li>
<li>ドイツの<strong>インダストリー4.0</strong>の影響を受けて作成されたと言われている。</li>
</ul>


<h5 id="-インターネットプラスAI3年行動実施方案">✓ インターネットプラスAI3年行動実施方案</h5>

<ul>
<li>2016年、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>産業の促進に向けてインターネットプラスAI3年行動実施方案が発表された。</li>
<li>AI技術を重点領域で活用することで世界に通用するトップ企業を育成することを目的としている。</li>
</ul>


<h4 id="-英国">✅ 英国</h4>

<h5 id="-RAS2020戦略">✓ RAS2020戦略</h5>

<ul>
<li>2015年3月、政府はロボット工学・自律システム（RAS）分野の発展を支援すると表明。</li>
</ul>


<h4 id="-ドイツ">✅ ドイツ</h4>

<h5 id="-デジタル戦略2025参考">✓ デジタル戦略2025（<a href="https://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h29/html/nc277350.html">参考</a>）</h5>

<ul>
<li>2017年3月、ツィプリス大臣は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CF%A2%CB%AE%C0%AF%C9%DC">連邦政府</a>が2016年3月に策定した「デジタル戦略2025」を発表。</li>
<li>2025年までにドイツがいかにしてデジタル化を具体化していくか取り組むべき10の施策について提案している。</li>
</ul>


<h4 id="-Coursera">✅ Coursera</h4>

<ul>
<li>🎩<strong>アンドリュー・ング（Andrew Ng）</strong>による。（「GoogleBrain」にも携わり、Baidu研究所に勤務する）</li>
<li>初級から上級までAIに関する講義が行われている。</li>
</ul>
